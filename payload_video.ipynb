{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fa1df42",
      "metadata": {
        "id": "7fa1df42"
      },
      "source": [
        "# FastAPI upload server (payload_video.ipynb)\n",
        "\n",
        "Notebook ini menyediakan server FastAPI yang menerima upload video (multipart) di `/upload` dan menerima JSON payload di `/upload`.\n",
        "\n",
        "Langkah eksekusi:\n",
        "1. Jalankan cell instalasi dependensi\n",
        "2. Jalankan cell setup direktori\n",
        "3. Jalankan cell definisi server\n",
        "4. Jalankan cell start server (ngrok akan dicoba jika tersedia)\n",
        "\n",
        "Hasil: file yang diupload akan disimpan di folder `uploads/` dan payload JSON yang dikirim ke `/upload` akan disimpan di `received_payloads/`. Video akan diproses dengan Whisper untuk speech-to-text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "cd864408",
      "metadata": {
        "id": "cd864408"
      },
      "outputs": [],
      "source": [
        "#kalo pake colab jangan lupa install dulu di terminal\n",
        "!pip install --quiet numpy==1.26.4\n",
        "!pip install --quiet --upgrade torch torchaudio faster-whisper\n",
        "\n",
        "\n",
        "#kalo lokal download ffmpeg nya\n",
        "#https://github.com/GyanD/codexffmpeg/releases/download/2025-11-27-git-61b034a47c/ffmpeg-2025-11-27-git-61b034a47c-full_build.zip\n",
        "#simpen di c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "5e2da1be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2da1be",
        "outputId": "9b9696f5-4f13-4da9-9a9f-41524eafd154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ All safe packages installed\n",
            "   ‚úÖ No numpy version conflicts\n",
            "   ‚úÖ Jupyter widgets installed (fixes tqdm warning)\n",
            "   ‚úÖ FFmpeg required for audio - verify with next cell\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\bin\"\n",
        "\n",
        "# ============================================================================\n",
        "# üîß CELL 1: INSTALL SAFE DEPENDENCIES (FIXED - NO CONFLICTS!)\n",
        "# ============================================================================\n",
        "\n",
        "# ‚úÖ TIER 0: JUPYTER WIDGETS (fixes tqdm warning)\n",
        "!pip install --quiet ipywidgets jupyter\n",
        "# ‚úÖ TIER 1: AMAN (Tidak touch numpy)\n",
        "!pip install --quiet fastapi uvicorn nest-asyncio pyngrok python-multipart\n",
        "!pip install --quiet tqdm\n",
        "!pip install --quiet imageio-ffmpeg\n",
        "!pip install --quiet deepl\n",
        "\n",
        "# ‚úÖ TIER 2: AMAN (Pure torch-based, no numpy dependency)\n",
        "#!pip install --quiet torch torchaudio\n",
        "!pip install --quiet silero-vad\n",
        "\n",
        "# ‚úÖ TIER 3: AMAN (Minimal numpy, tidak upgrade)\n",
        "!pip install --quiet pydub\n",
        "!pip install --quiet soundfile\n",
        "!pip install --quiet scipy\n",
        "!pip install --quiet scikit-learn\n",
        "\n",
        "# ‚úÖ TIER 4: AMAN (Cloud-based, no local deps)\n",
        "#!pip install --quiet faster-whisper\n",
        "!pip install --quiet huggingface-hub\n",
        "\n",
        "# ‚úÖ TIER 5: MEDIAPIPE (sudah include opencv internally!)\n",
        "!pip install --quiet mediapipe\n",
        "# ‚úÖ TIER 6: TORCHCODEC (video codec support)\n",
        "!pip install --quiet torchcodec\n",
        "!pip install --quiet gdown requests\n",
        "!pip install --quiet resemblyzer moviepy\n",
        "\n",
        "print('\\n‚úÖ All safe packages installed')\n",
        "print('   ‚úÖ No numpy version conflicts')\n",
        "print('   ‚úÖ Jupyter widgets installed (fixes tqdm warning)')\n",
        "print('   ‚úÖ FFmpeg required for audio - verify with next cell')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BBPyMnTdJnsi",
      "metadata": {
        "id": "BBPyMnTdJnsi"
      },
      "source": [
        "<b><h2> Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "3oRQo25wR_LJ",
      "metadata": {
        "id": "3oRQo25wR_LJ"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Standard Library\n",
        "# ==========================\n",
        "import asyncio\n",
        "import gc\n",
        "import getpass\n",
        "import hashlib\n",
        "import json\n",
        "import json as json_module\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "import tempfile\n",
        "import threading\n",
        "import threading as th\n",
        "import time\n",
        "import math\n",
        "import traceback\n",
        "import uuid\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from datetime import datetime, timezone\n",
        "from typing import List\n",
        "from urllib.parse import urlparse\n",
        "import urllib.request\n",
        "import torch\n",
        "import torchaudio\n",
        "from silero_vad import load_silero_vad\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_nonsilent\n",
        "import gdown\n",
        "import requests\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import librosa\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# ==========================\n",
        "# Third-Party Libraries\n",
        "# ==========================\n",
        "import deepl\n",
        "import nest_asyncio\n",
        "import torch\n",
        "import uvicorn\n",
        "from faster_whisper import WhisperModel\n",
        "from huggingface_hub import InferenceClient\n",
        "from pyngrok import conf, ngrok\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# ==========================\n",
        "# FastAPI & Middleware\n",
        "# ==========================\n",
        "from fastapi import (\n",
        "    BackgroundTasks,\n",
        "    FastAPI,\n",
        "    File,\n",
        "    Form,\n",
        "    HTTPException,\n",
        "    Request,\n",
        "    UploadFile\n",
        ")\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import HTMLResponse, JSONResponse\n",
        "from fastapi.staticfiles import StaticFiles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sZG11EuZJsrV",
      "metadata": {
        "id": "sZG11EuZJsrV"
      },
      "source": [
        "<b><h2> Siapkan direktori untuk upload dan transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "5359c402",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5359c402",
        "outputId": "1766be7d-8a1a-4476-d15c-144954ae8d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Directories:\n",
            "   Upload: /content/uploads\n",
            "   Transcription: /content/transcriptions\n",
            "   AUDIO: /content/audio\n",
            "   Results: /content/results\n",
            "\n",
            "üéØ Device Configuration:\n",
            "   Device: CUDA\n",
            "   Compute Type: float16\n",
            "   GPU: Tesla T4\n",
            "\n",
            "üåê Translation Configuration:\n",
            "   DeepL API: Configured\n"
          ]
        }
      ],
      "source": [
        "# Siapkan direktori untuk upload dan transcription\n",
        "ROOT_DIR = os.getcwd()\n",
        "UPLOAD_DIR = os.path.join(ROOT_DIR, 'uploads')\n",
        "TRANSCRIPTION_DIR = os.path.join(ROOT_DIR, 'transcriptions')\n",
        "AUDIO_DIR = os.path.join(ROOT_DIR, 'audio')\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, 'results')  # NEW: hasil assessment\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(TRANSCRIPTION_DIR, exist_ok=True)\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print('üìÅ Directories:')\n",
        "print(f'   Upload: {UPLOAD_DIR}')\n",
        "print(f'   Transcription: {TRANSCRIPTION_DIR}')\n",
        "print(f'   AUDIO: {AUDIO_DIR}')\n",
        "print(f'   Results: {RESULTS_DIR}')\n",
        "\n",
        "# Check for GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
        "\n",
        "print(f'\\nüéØ Device Configuration:')\n",
        "print(f'   Device: {device.upper()}')\n",
        "print(f'   Compute Type: {compute_type}')\n",
        "if device == \"cuda\":\n",
        "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('   Note: Using CPU (GPU recommended for faster processing)')\n",
        "\n",
        "# DeepL Configuration\n",
        "DEEPL_API_KEY = \"02a88edf-4fcb-4786-ba3d-a137fb143760:fx\"\n",
        "\n",
        "print('\\nüåê Translation Configuration:')\n",
        "print(f'   DeepL API: {\"Configured\" if DEEPL_API_KEY != \"YOUR_DEEPL_API_KEY_HERE\" else \"‚ö†Ô∏è  NOT CONFIGURED - Set DEEPL_API_KEY\"}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "-xKfkVrjT1Fb",
      "metadata": {
        "id": "-xKfkVrjT1Fb"
      },
      "outputs": [],
      "source": [
        "app = FastAPI(title='AI Interview Assessment System')\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        "    expose_headers=['*'],\n",
        "    max_age=3600,\n",
        ")\n",
        "\n",
        "# Mount static folders\n",
        "app.mount('/uploads', StaticFiles(directory=UPLOAD_DIR), name='uploads')\n",
        "app.mount('/transcriptions', StaticFiles(directory=TRANSCRIPTION_DIR), name='transcriptions')\n",
        "app.mount('/results', StaticFiles(directory=RESULTS_DIR), name='results')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "YscyXmgL1ZMC",
      "metadata": {
        "id": "YscyXmgL1ZMC"
      },
      "outputs": [],
      "source": [
        "# Background processing\n",
        "executor = ThreadPoolExecutor(max_workers=2)\n",
        "processing_status = {}\n",
        "processing_lock = th.Lock()\n",
        "\n",
        "# HELPER FUNCTIONS - ONLY ONE INSTANCE EACH\n",
        "\n",
        "def get_local_file_path(url):\n",
        "    \"\"\"Extract local file path from URL if it's a local upload\"\"\"\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "        if '/uploads/' in parsed.path:\n",
        "            filename = parsed.path.split('/uploads/')[-1]\n",
        "            local_path = os.path.join(UPLOAD_DIR, filename)\n",
        "            if os.path.exists(local_path):\n",
        "                return local_path\n",
        "    except Exception as e:\n",
        "        print(f'Error parsing URL: {e}')\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "o3Zvb7hDCdE7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Zvb7hDCdE7",
        "outputId": "ca7a2b98-10f7-479c-9739-4aef2d698c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ JSON encoder patched for NumPy compatibility\n",
            "   All json.dump() calls will now handle NumPy types automatically\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# üîß FIX: JSON SERIALIZATION FOR NUMPY TYPES\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Monkey patch JSON encoder to handle NumPy types automatically\n",
        "_original_default = json.JSONEncoder.default\n",
        "\n",
        "def _numpy_default(self, obj):\n",
        "    \"\"\"Custom JSON encoder that converts NumPy types to Python native types\"\"\"\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, np.bool_):\n",
        "        return bool(obj)\n",
        "    return _original_default(self, obj)\n",
        "\n",
        "# Apply the patch\n",
        "json.JSONEncoder.default = _numpy_default\n",
        "\n",
        "print('‚úÖ JSON encoder patched for NumPy compatibility')\n",
        "print('   All json.dump() calls will now handle NumPy types automatically\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hn4TX5r-JxtM",
      "metadata": {
        "id": "Hn4TX5r-JxtM"
      },
      "source": [
        "<b><h2> **Initialize** Whisper Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "yNRfVfwTT4fC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNRfVfwTT4fC",
        "outputId": "abb5088b-1cb0-4019-b17e-e493aa95cff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üì• Loading Whisper model...\n",
            "‚ÑπÔ∏è  Using faster-whisper \"large-v3\" model\n",
            "   This is the MOST ACCURATE model available\n",
            "   Speed: 4-5x faster than openai-whisper\n",
            "   Accuracy: ~98% for clear English speech\n",
            "   First run will download ~3GB model...\n",
            "\n",
            "üéØ Configuration:\n",
            "   Device: CUDA\n",
            "   Compute Type: float16\n",
            "‚úÖ Whisper model loaded successfully\n",
            "\n",
            "\n",
            "üì• Loading Voice Encoder for Speaker Diarization...\n",
            "   Configuring for CPU mode (avoiding cuDNN errors)...\n",
            "   ‚ÑπÔ∏è  GPU available but using CPU to avoid cuDNN conflicts\n",
            "Loaded the voice encoder model on cpu in 0.04 seconds.\n",
            "‚úÖ Voice Encoder loaded successfully (~50MB)\n",
            "   Device: CPU (cuDNN conflict avoided)\n",
            "   Model: Resemblyzer GE2E (Google Embeddings)\n",
            "   Purpose: Detect multiple speakers in audio\n",
            "   Note: CPU mode is slower but more stable\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load faster-whisper model with BEST ACCURACY settings\n",
        "print('\\nüì• Loading Whisper model...')\n",
        "print('‚ÑπÔ∏è  Using faster-whisper \"large-v3\" model')\n",
        "print('   This is the MOST ACCURATE model available')\n",
        "print('   Speed: 4-5x faster than openai-whisper')\n",
        "print('   Accuracy: ~98% for clear English speech')\n",
        "print('   First run will download ~3GB model...\\n')\n",
        "\n",
        "# Detect device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
        "\n",
        "print(f'üéØ Configuration:')\n",
        "print(f'   Device: {device.upper()}')\n",
        "print(f'   Compute Type: {compute_type}')\n",
        "\n",
        "# Load model with best accuracy settings\n",
        "whisper_model = WhisperModel(\n",
        "    \"large-v3\",\n",
        "    device=device,\n",
        "    compute_type=compute_type,\n",
        "    cpu_threads=4,\n",
        "    num_workers=1\n",
        ")\n",
        "\n",
        "print('‚úÖ Whisper model loaded successfully\\n')\n",
        "\n",
        "# ============================================================================\n",
        "# üîä INITIALIZE VOICE ENCODER FOR SPEAKER DIARIZATION\n",
        "# ============================================================================\n",
        "print('\\nüì• Loading Voice Encoder for Speaker Diarization...')\n",
        "try:\n",
        "    import torch\n",
        "    from resemblyzer import VoiceEncoder\n",
        "\n",
        "    # ‚úÖ FIX: Force CPU mode to avoid cuDNN version mismatch\n",
        "    print('   Configuring for CPU mode (avoiding cuDNN errors)...')\n",
        "\n",
        "    # Set PyTorch to CPU only\n",
        "    if torch.cuda.is_available():\n",
        "        print('   ‚ÑπÔ∏è  GPU available but using CPU to avoid cuDNN conflicts')\n",
        "\n",
        "    # Force device to CPU\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    # Load VoiceEncoder with CPU\n",
        "    voice_encoder = VoiceEncoder(device='cpu')\n",
        "\n",
        "    print('‚úÖ Voice Encoder loaded successfully (~50MB)')\n",
        "    print('   Device: CPU (cuDNN conflict avoided)')\n",
        "    print('   Model: Resemblyzer GE2E (Google Embeddings)')\n",
        "    print('   Purpose: Detect multiple speakers in audio')\n",
        "    print('   Note: CPU mode is slower but more stable\\n')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è  Voice Encoder failed to load: {e}')\n",
        "    print('   Speaker diarization will return default values\\n')\n",
        "    voice_encoder = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oTD7T12FJ7XU",
      "metadata": {
        "id": "oTD7T12FJ7XU"
      },
      "source": [
        "<b><h2> Initialize DeepL translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "QVETu4h3T6k6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVETu4h3T6k6",
        "outputId": "df8e1c57-4fa8-4292-988c-818730708c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DeepL translator initialized successfully\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize DeepL translator\n",
        "translator = None\n",
        "if DEEPL_API_KEY and DEEPL_API_KEY != \"YOUR_DEEPL_API_KEY_HERE\":\n",
        "    try:\n",
        "        translator = deepl.Translator(DEEPL_API_KEY)\n",
        "        print('‚úÖ DeepL translator initialized successfully\\n')\n",
        "    except Exception as e:\n",
        "        print(f'‚ö†Ô∏è  DeepL initialization failed: {e}')\n",
        "        print('   Translation to Indonesian will be skipped\\n')\n",
        "else:\n",
        "    print('‚ö†Ô∏è  DeepL API key not configured')\n",
        "    print('   Translation to Indonesian will be skipped\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xxvmLdAdKDLT",
      "metadata": {
        "id": "xxvmLdAdKDLT"
      },
      "source": [
        "<b><h2> Fungsi Cheating Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "PLLPAUaIdZQ4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLLPAUaIdZQ4",
        "outputId": "85fa1a16-4c65-4fca-fe7b-1b5ce906fec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ Cheating Detection Configuration:\n",
            "   Eye Ratio Range: 0.6 - 1.6\n",
            "   Head Turn Range: 0.35 - 0.65\n",
            "   Risk Thresholds: >5% Medium, >20% High\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# üéØ CHEATING DETECTION CONFIGURATION (dari eye_detection.ipynb)\n",
        "# ============================================================================\n",
        "\n",
        "# Threshold Parameters\n",
        "EYE_RATIO_RIGHT_LIMIT = 0.6\n",
        "EYE_RATIO_LEFT_LIMIT = 1.6\n",
        "HEAD_TURN_LEFT_LIMIT = 0.35\n",
        "HEAD_TURN_RIGHT_LIMIT = 0.65\n",
        "SCORE_HIGH_RISK = 20.0\n",
        "SCORE_MEDIUM_RISK = 5.0\n",
        "\n",
        "# Landmark Indices\n",
        "LEFT_EYE = [33, 133, 468]\n",
        "RIGHT_EYE = [362, 263, 473]\n",
        "NOSE_TIP = 1\n",
        "FACE_LEFT_EDGE = 234\n",
        "FACE_RIGHT_EDGE = 454\n",
        "\n",
        "print('\\nüéØ Cheating Detection Configuration:')\n",
        "print(f'   Eye Ratio Range: {EYE_RATIO_RIGHT_LIMIT} - {EYE_RATIO_LEFT_LIMIT}')\n",
        "print(f'   Head Turn Range: {HEAD_TURN_LEFT_LIMIT} - {HEAD_TURN_RIGHT_LIMIT}')\n",
        "print(f'   Risk Thresholds: >5% Medium, >20% High\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "6aa5d9f5",
      "metadata": {
        "id": "6aa5d9f5"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# üîç CHEATING DETECTION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def get_gaze_ratio(eye_points, landmarks):\n",
        "    \"\"\"Menghitung rasio posisi iris untuk eye tracking\"\"\"\n",
        "    left_corner = np.array([landmarks[eye_points[0]].x, landmarks[eye_points[0]].y])\n",
        "    right_corner = np.array([landmarks[eye_points[1]].x, landmarks[eye_points[1]].y])\n",
        "    iris_center = np.array([landmarks[eye_points[2]].x, landmarks[eye_points[2]].y])\n",
        "\n",
        "    dist_to_left = np.linalg.norm(iris_center - left_corner)\n",
        "    dist_to_right = np.linalg.norm(iris_center - right_corner)\n",
        "\n",
        "    if dist_to_right == 0:\n",
        "        return 5.0\n",
        "\n",
        "    ratio = dist_to_left / dist_to_right\n",
        "    return ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "81e7e482",
      "metadata": {
        "id": "81e7e482"
      },
      "outputs": [],
      "source": [
        "def get_head_turn_ratio(landmarks):\n",
        "    \"\"\"Menghitung posisi relatif hidung untuk head pose detection\"\"\"\n",
        "    nose = landmarks[NOSE_TIP].x\n",
        "    left_edge = landmarks[FACE_LEFT_EDGE].x\n",
        "    right_edge = landmarks[FACE_RIGHT_EDGE].x\n",
        "\n",
        "    face_width = right_edge - left_edge\n",
        "    nose_dist = nose - left_edge\n",
        "\n",
        "    if face_width == 0:\n",
        "        return 0.5\n",
        "\n",
        "    relative_pos = nose_dist / face_width\n",
        "    return relative_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "b2c47bec",
      "metadata": {
        "id": "b2c47bec"
      },
      "outputs": [],
      "source": [
        "def analyze_video_cheating_detection(video_path: str, show_progress=True):\n",
        "    \"\"\"\n",
        "    Visual Analysis: Eye gaze, head pose, multiple face detection\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            status, total_frames, suspicious_frames, cheating_score,\n",
        "            verdict, confidence, details, plot_data\n",
        "        }\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_path):\n",
        "        return {\"status\": \"error\", \"message\": f\"File not found: {video_path}\"}\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return {\"status\": \"error\", \"message\": \"Cannot open video\"}\n",
        "\n",
        "    total_frames = 0\n",
        "    suspicious_frames = 0\n",
        "    eye_fail_count = 0\n",
        "    head_fail_count = 0\n",
        "    no_face_count = 0\n",
        "    multiple_face_count = 0\n",
        "\n",
        "    # Data for plotting\n",
        "    gaze_ratios = []\n",
        "    head_ratios = []\n",
        "    frame_numbers = []\n",
        "    confidence_scores = []\n",
        "    face_counts = []\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "    mp_face_detection = mp.solutions.face_detection\n",
        "\n",
        "    with mp_face_mesh.FaceMesh(\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.6,\n",
        "        min_tracking_confidence=0.6\n",
        "    ) as mesh, \\\n",
        "    mp_face_detection.FaceDetection(\n",
        "        model_selection=1,\n",
        "        min_detection_confidence=0.6\n",
        "    ) as face_detector:\n",
        "\n",
        "        while True:\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            total_frames += 1\n",
        "\n",
        "            if show_progress and total_frames % 30 == 0:\n",
        "                progress = (total_frames / total_video_frames) * 100\n",
        "                print(f\"   Processing cheating detection: {progress:.1f}% ({total_frames}/{total_video_frames} frames)\", end='\\r')\n",
        "\n",
        "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # FACE DETECTION\n",
        "            detection_results = face_detector.process(img_rgb)\n",
        "            face_confidence = 0.0\n",
        "            num_faces = 0\n",
        "\n",
        "            if detection_results.detections:\n",
        "                num_faces = len(detection_results.detections)\n",
        "\n",
        "                if num_faces > 1:\n",
        "                    multiple_face_count += 1\n",
        "\n",
        "                face_confidence = detection_results.detections[0].score[0] * 100\n",
        "\n",
        "            face_counts.append(num_faces)\n",
        "\n",
        "            # FACE MESH (Eye Tracking)\n",
        "            mesh_results = mesh.process(img_rgb)\n",
        "            is_frame_suspicious = False\n",
        "\n",
        "            if mesh_results.multi_face_landmarks:\n",
        "                landmarks = mesh_results.multi_face_landmarks[0].landmark\n",
        "\n",
        "                # Eye Gaze Check\n",
        "                left_ratio = get_gaze_ratio(LEFT_EYE, landmarks)\n",
        "                right_ratio = get_gaze_ratio(RIGHT_EYE, landmarks)\n",
        "                avg_gaze_ratio = (left_ratio + right_ratio) / 2\n",
        "\n",
        "                if avg_gaze_ratio < EYE_RATIO_RIGHT_LIMIT or avg_gaze_ratio > EYE_RATIO_LEFT_LIMIT:\n",
        "                    is_frame_suspicious = True\n",
        "                    eye_fail_count += 1\n",
        "\n",
        "                # Head Pose Check\n",
        "                head_ratio = get_head_turn_ratio(landmarks)\n",
        "\n",
        "                if not is_frame_suspicious:\n",
        "                    if head_ratio < HEAD_TURN_LEFT_LIMIT or head_ratio > HEAD_TURN_RIGHT_LIMIT:\n",
        "                        is_frame_suspicious = True\n",
        "                        head_fail_count += 1\n",
        "\n",
        "                gaze_ratios.append(avg_gaze_ratio)\n",
        "                head_ratios.append(head_ratio)\n",
        "                frame_numbers.append(total_frames)\n",
        "                confidence_scores.append(face_confidence)\n",
        "            else:\n",
        "                is_frame_suspicious = True\n",
        "                no_face_count += 1\n",
        "                confidence_scores.append(0.0)\n",
        "\n",
        "            # Multiple face = CHEATING\n",
        "            if num_faces > 1:\n",
        "                is_frame_suspicious = True\n",
        "\n",
        "            if is_frame_suspicious:\n",
        "                suspicious_frames += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if show_progress:\n",
        "        print()\n",
        "\n",
        "    cheating_score = 0\n",
        "    if total_frames > 0:\n",
        "        cheating_score = (suspicious_frames / total_frames) * 100\n",
        "\n",
        "    multiple_face_pct = (multiple_face_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "\n",
        "    # Verdict\n",
        "    verdict = \"Safe\"\n",
        "    cheating_reasons = []\n",
        "\n",
        "    if multiple_face_pct > 1.0:\n",
        "        verdict = \"High Risk\"\n",
        "        cheating_reasons.append(f\"Multiple faces detected ({multiple_face_pct:.1f}% of frames)\")\n",
        "    elif cheating_score > SCORE_HIGH_RISK:\n",
        "        verdict = \"High Risk\"\n",
        "        cheating_reasons.append(f\"High suspicious activity ({cheating_score:.1f}%)\")\n",
        "    elif cheating_score > SCORE_MEDIUM_RISK:\n",
        "        verdict = \"Medium Risk\"\n",
        "        cheating_reasons.append(f\"Medium suspicious activity ({cheating_score:.1f}%)\")\n",
        "\n",
        "    duration = total_frames / fps if fps > 0 else 0\n",
        "\n",
        "    avg_confidence = np.mean(confidence_scores) if confidence_scores else 0.0\n",
        "    min_confidence = np.min(confidence_scores) if confidence_scores else 0.0\n",
        "    max_confidence = np.max(confidence_scores) if confidence_scores else 0.0\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"total_frames\": total_frames,\n",
        "        \"suspicious_frames\": suspicious_frames,\n",
        "        \"cheating_score\": round(cheating_score, 2),\n",
        "        \"verdict\": verdict,\n",
        "        \"cheating_reasons\": cheating_reasons,\n",
        "        \"duration_seconds\": round(duration, 2),\n",
        "        \"fps\": round(fps, 2),\n",
        "        \"confidence\": {\n",
        "            \"average\": round(avg_confidence, 2),\n",
        "            \"min\": round(min_confidence, 2),\n",
        "            \"max\": round(max_confidence, 2)\n",
        "        },\n",
        "        \"details\": {\n",
        "            \"eye_fails\": eye_fail_count,\n",
        "            \"head_fails\": head_fail_count,\n",
        "            \"no_face\": no_face_count,\n",
        "            \"multiple_faces\": multiple_face_count\n",
        "        },\n",
        "        \"plot_data\": {\n",
        "            \"gaze_ratios\": gaze_ratios,\n",
        "            \"head_ratios\": head_ratios,\n",
        "            \"frame_numbers\": frame_numbers,\n",
        "            \"confidence_scores\": confidence_scores,\n",
        "            \"face_counts\": face_counts\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "04634728",
      "metadata": {
        "id": "04634728"
      },
      "outputs": [],
      "source": [
        "def analyze_speaker_diarization(video_path: str):\n",
        "    \"\"\"\n",
        "    Speaker Diarization - Deteksi berapa banyak orang yang bicara\n",
        "    Menggunakan Resemblyzer untuk voice embeddings + clustering\n",
        "\n",
        "    ‚úÖ FIXED: WebM audio extraction + CPU mode for cuDNN compatibility\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from moviepy.editor import VideoFileClip\n",
        "        import subprocess\n",
        "        import torch\n",
        "\n",
        "        # ‚úÖ FIX 1: Ensure CPU mode for Resemblyzer\n",
        "        torch.set_num_threads(4)  # Optimize CPU performance\n",
        "\n",
        "        # ‚úÖ FIX 2: Global VoiceEncoder with CPU device\n",
        "        global voice_encoder\n",
        "        if 'voice_encoder' not in globals() or voice_encoder is None:\n",
        "            print(\"   Loading VoiceEncoder (CPU mode)...\")\n",
        "            from resemblyzer import VoiceEncoder\n",
        "            voice_encoder = VoiceEncoder(device='cpu')  # ‚úÖ Force CPU\n",
        "            print(\"   ‚úÖ VoiceEncoder loaded on CPU\")\n",
        "\n",
        "        encoder = voice_encoder\n",
        "\n",
        "        # ‚úÖ FIX 3: Ensure AUDIO_DIR exists\n",
        "        os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "        temp_audio = os.path.join(AUDIO_DIR, \"temp_audio_diarization.wav\")\n",
        "\n",
        "        print(\"   Extracting audio from video...\")\n",
        "\n",
        "        # ‚úÖ FIX 4: Try MoviePy first, fallback to FFmpeg for WebM\n",
        "        audio_extracted = False\n",
        "\n",
        "        # Method 1: Try MoviePy (works for most formats)\n",
        "        try:\n",
        "            video = VideoFileClip(video_path)\n",
        "\n",
        "            if video.audio is None:\n",
        "                print(\"   ‚ö†Ô∏è  MoviePy: No audio track detected\")\n",
        "                video.close()\n",
        "            else:\n",
        "                print(f\"   ‚ÑπÔ∏è  Audio duration: {video.audio.duration:.2f}s\")\n",
        "                video.audio.write_audiofile(\n",
        "                    temp_audio,\n",
        "                    fps=16000,\n",
        "                    nbytes=2,\n",
        "                    codec='pcm_s16le',  # ‚úÖ Explicit codec for WebM\n",
        "                    verbose=False,\n",
        "                    logger=None\n",
        "                )\n",
        "                video.close()\n",
        "                audio_extracted = True\n",
        "                print(\"   ‚úÖ Audio extracted via MoviePy\")\n",
        "        except Exception as moviepy_error:\n",
        "            print(f\"   ‚ö†Ô∏è  MoviePy extraction failed: {str(moviepy_error)[:100]}\")\n",
        "            print(\"   üîÑ Trying FFmpeg direct extraction...\")\n",
        "\n",
        "        # Method 2: Fallback to FFmpeg direct (better for WebM)\n",
        "        if not audio_extracted:\n",
        "            try:\n",
        "                # ‚úÖ FIX 5: Direct FFmpeg extraction (better for WebM/Opus)\n",
        "                ffmpeg_cmd = [\n",
        "                    'ffmpeg',\n",
        "                    '-i', video_path,\n",
        "                    '-vn',  # No video\n",
        "                    '-acodec', 'pcm_s16le',  # Convert to PCM\n",
        "                    '-ar', '16000',  # 16kHz sample rate\n",
        "                    '-ac', '1',  # Mono\n",
        "                    '-y',  # Overwrite\n",
        "                    temp_audio\n",
        "                ]\n",
        "\n",
        "                result = subprocess.run(\n",
        "                    ffmpeg_cmd,\n",
        "                    stdout=subprocess.PIPE,\n",
        "                    stderr=subprocess.PIPE,\n",
        "                    timeout=60\n",
        "                )\n",
        "\n",
        "                if result.returncode == 0 and os.path.exists(temp_audio):\n",
        "                    audio_extracted = True\n",
        "                    print(\"   ‚úÖ Audio extracted via FFmpeg\")\n",
        "                else:\n",
        "                    stderr_msg = result.stderr.decode()[:200] if result.stderr else \"No error message\"\n",
        "                    print(f\"   ‚ùå FFmpeg failed: {stderr_msg}\")\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(\"   ‚ùå FFmpeg not found in PATH\")\n",
        "                print(\"   üí° Install FFmpeg: https://ffmpeg.org/download.html\")\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(\"   ‚ùå FFmpeg extraction timeout (>60s)\")\n",
        "            except Exception as ffmpeg_error:\n",
        "                print(f\"   ‚ùå FFmpeg extraction error: {str(ffmpeg_error)[:100]}\")\n",
        "\n",
        "        # ‚úÖ FIX 6: Check if audio was extracted\n",
        "        if not audio_extracted:\n",
        "            return {\n",
        "                \"status\": \"no_audio\",\n",
        "                \"message\": \"Failed to extract audio from video (WebM may require FFmpeg)\",\n",
        "                \"num_speakers\": 1,\n",
        "                \"is_cheating\": False,\n",
        "                \"confidence\": 50,\n",
        "                \"silhouette_score\": 0,\n",
        "                \"total_segments\": 0\n",
        "            }\n",
        "\n",
        "        # ‚úÖ FIX 7: Validate extracted audio file\n",
        "        if not os.path.exists(temp_audio):\n",
        "            print(\"   ‚ùå Audio file not created\")\n",
        "            return {\n",
        "                \"status\": \"extraction_failed\",\n",
        "                \"message\": \"Audio extraction failed - file not created\",\n",
        "                \"num_speakers\": 1,\n",
        "                \"is_cheating\": False,\n",
        "                \"confidence\": 50,\n",
        "                \"silhouette_score\": 0,\n",
        "                \"total_segments\": 0\n",
        "            }\n",
        "\n",
        "        audio_size = os.path.getsize(temp_audio)\n",
        "        print(f\"   ‚ÑπÔ∏è  Audio file size: {audio_size / 1024:.1f} KB\")\n",
        "\n",
        "        if audio_size < 1000:  # Less than 1KB\n",
        "            print(\"   ‚ö†Ô∏è  Audio file too small - likely empty\")\n",
        "            os.remove(temp_audio)\n",
        "            return {\n",
        "                \"status\": \"audio_too_small\",\n",
        "                \"message\": \"Extracted audio file is too small (empty or corrupt)\",\n",
        "                \"num_speakers\": 1,\n",
        "                \"is_cheating\": False,\n",
        "                \"confidence\": 50,\n",
        "                \"silhouette_score\": 0,\n",
        "                \"total_segments\": 0\n",
        "            }\n",
        "\n",
        "        print(\"   Loading and preprocessing audio...\")\n",
        "        try:\n",
        "            from resemblyzer import preprocess_wav\n",
        "            wav = preprocess_wav(temp_audio)\n",
        "        except Exception as preprocess_error:\n",
        "            print(f\"   ‚ùå Preprocessing error: {str(preprocess_error)[:100]}\")\n",
        "            if os.path.exists(temp_audio):\n",
        "                os.remove(temp_audio)\n",
        "            return {\n",
        "                \"status\": \"preprocessing_failed\",\n",
        "                \"message\": f\"Audio preprocessing failed: {str(preprocess_error)[:100]}\",\n",
        "                \"num_speakers\": 1,\n",
        "                \"is_cheating\": False,\n",
        "                \"confidence\": 50,\n",
        "                \"silhouette_score\": 0,\n",
        "                \"total_segments\": 0\n",
        "            }\n",
        "\n",
        "        if wav is None or len(wav) == 0:\n",
        "            print(\"   ‚ö†Ô∏è  Preprocessed audio is empty\")\n",
        "            if os.path.exists(temp_audio):\n",
        "                os.remove(temp_audio)\n",
        "            return {\n",
        "                \"status\": \"audio_empty\",\n",
        "                \"message\": \"Preprocessed audio is empty\",\n",
        "                \"num_speakers\": 1,\n",
        "                \"is_cheating\": False,\n",
        "                \"confidence\": 50,\n",
        "                \"silhouette_score\": 0,\n",
        "                \"total_segments\": 0\n",
        "            }\n",
        "\n",
        "        print(f\"   ‚ÑπÔ∏è  Audio samples: {len(wav)} ({len(wav)/16000:.2f}s)\")\n",
        "\n",
        "        print(\"   Extracting speaker embeddings...\")\n",
        "        segment_duration = 0.5\n",
        "        sample_rate = 16000\n",
        "        segment_samples = int(segment_duration * sample_rate)\n",
        "\n",
        "        embeddings = []\n",
        "        timestamps = []\n",
        "\n",
        "        step = segment_samples // 2\n",
        "        for i in range(0, len(wav) - segment_samples, step):\n",
        "            segment = wav[i:i + segment_samples]\n",
        "            if len(segment) == segment_samples:\n",
        "                # ‚úÖ Ensure CPU processing\n",
        "                with torch.no_grad():  # Disable gradient for inference\n",
        "                    embed = encoder.embed_utterance(segment)\n",
        "                embeddings.append(embed)\n",
        "                timestamps.append(i / sample_rate)\n",
        "\n",
        "        embeddings = np.array(embeddings)\n",
        "\n",
        "        print(f\"   Analyzing {len(embeddings)} audio segments...\")\n",
        "\n",
        "        if len(embeddings) == 0:\n",
        "            print(\"   ‚ö†Ô∏è  No valid audio segments extracted (audio too short)\")\n",
        "            if os.path.exists(temp_audio):\n",
        "                os.remove(temp_audio)\n",
        "            return {\n",
        "                \"status\": \"no_segments\",\n",
        "                \"message\": \"Audio too short - no valid segments (need >0.5s)\",\n",
        "                \"num_speakers\": 1,\n",
        "                \"is_cheating\": False,\n",
        "                \"confidence\": 50,\n",
        "                \"silhouette_score\": 0,\n",
        "                \"total_segments\": 0\n",
        "            }\n",
        "\n",
        "        if len(embeddings) < 2:\n",
        "            num_speakers = 1 if len(embeddings) > 0 else 0\n",
        "            confidence_score = 60.0\n",
        "            silhouette = 0.0\n",
        "        else:\n",
        "            best_n_speakers = 1\n",
        "            best_score = -1\n",
        "\n",
        "            for n in range(2, min(6, len(embeddings))):\n",
        "                clustering = AgglomerativeClustering(n_clusters=n, linkage='average')\n",
        "                labels = clustering.fit_predict(embeddings)\n",
        "\n",
        "                from sklearn.metrics import silhouette_score\n",
        "                score = silhouette_score(embeddings, labels)\n",
        "\n",
        "                if score > best_score and score > 0.2:\n",
        "                    best_score = score\n",
        "                    best_n_speakers = n\n",
        "\n",
        "            if best_score > 0.2:\n",
        "                num_speakers = best_n_speakers\n",
        "                silhouette = best_score\n",
        "\n",
        "                if silhouette >= 0.7:\n",
        "                    confidence_score = 95.0\n",
        "                elif silhouette >= 0.5:\n",
        "                    confidence_score = 85.0\n",
        "                elif silhouette >= 0.35:\n",
        "                    confidence_score = 75.0\n",
        "                else:\n",
        "                    confidence_score = 60.0\n",
        "            else:\n",
        "                num_speakers = 1\n",
        "                silhouette = best_score\n",
        "\n",
        "                if best_score < 0.1:\n",
        "                    confidence_score = 90.0\n",
        "                elif best_score < 0.15:\n",
        "                    confidence_score = 80.0\n",
        "                else:\n",
        "                    confidence_score = 70.0\n",
        "\n",
        "        # Cleanup\n",
        "        if os.path.exists(temp_audio):\n",
        "            os.remove(temp_audio)\n",
        "\n",
        "        is_cheating = num_speakers > 1\n",
        "\n",
        "        print(f\"   ‚úì Detected {num_speakers} distinct speaker(s)\")\n",
        "        print(f\"   üìä Confidence Score: {confidence_score:.1f}%\")\n",
        "        print(f\"   üìà Silhouette Score: {silhouette:.3f}\")\n",
        "        print(f\"   üîç Total segments: {len(embeddings)}\")\n",
        "\n",
        "        if is_cheating:\n",
        "            print(f\"   ‚ö†Ô∏è  WARNING: Multiple speakers detected!\")\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"num_speakers\": num_speakers,\n",
        "            \"total_segments\": len(embeddings),\n",
        "            \"is_cheating\": is_cheating,\n",
        "            \"confidence\": round(confidence_score, 2),\n",
        "            \"silhouette_score\": round(silhouette, 3),\n",
        "            \"message\": f\"Detected {num_speakers} distinct speaker(s) with {confidence_score:.1f}% confidence\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Speaker diarization error: {e}\")\n",
        "        import traceback\n",
        "        print(f\"   üìã Traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Cleanup on error\n",
        "        temp_audio_path = os.path.join(AUDIO_DIR, \"temp_audio_diarization.wav\")\n",
        "        if os.path.exists(temp_audio_path):\n",
        "            try:\n",
        "                os.remove(temp_audio_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"message\": str(e)[:200],\n",
        "            \"num_speakers\": 1,\n",
        "            \"is_cheating\": False,\n",
        "            \"confidence\": 50,\n",
        "            \"silhouette_score\": 0,\n",
        "            \"total_segments\": 0\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "3013808c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3013808c",
        "outputId": "d7eefe9a-f2a7-47d9-d740-ab18a1767450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cheating detection functions loaded\n",
            "   ‚Ä¢ analyze_video_cheating_detection() - Visual analysis\n",
            "   ‚Ä¢ analyze_speaker_diarization() - Audio analysis\n",
            "   ‚Ä¢ comprehensive_cheating_detection() - Full detection (with final_avg_confidence)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def comprehensive_cheating_detection(video_path: str):\n",
        "    \"\"\"\n",
        "    Comprehensive Cheating Detection:\n",
        "    - Visual: Face detection, eye gaze, head pose, multiple faces\n",
        "    - Audio: Speaker diarization (multiple speakers)\n",
        "\n",
        "    Expected for single-person interview: 1 face + 1 speaker\n",
        "    Cheating if: >1 face OR >1 speaker\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            visual: {cheating_score, suspicious_frames, cheating_reasons, confidence},\n",
        "            audio: {num_speakers, confidence, silhouette_score},\n",
        "            final_verdict: \"Safe\" | \"Medium Risk\" | \"High Risk\",\n",
        "            final_avg_confidence: float,\n",
        "            all_indicators: [...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üéØ COMPREHENSIVE CHEATING DETECTION\")\n",
        "    print(f\"   (Video Interview - Expected: 1 Person)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # 1. VISUAL ANALYSIS\n",
        "    print(\"üëÅÔ∏è  STEP 1: Visual Analysis (Face Detection)\")\n",
        "    print(\"-\" * 60)\n",
        "    visual_result = analyze_video_cheating_detection(video_path, show_progress=True)\n",
        "\n",
        "    # 2. SPEAKER DIARIZATION\n",
        "    print(\"\\nüîä STEP 2: Speaker Diarization (Voice Analysis)\")\n",
        "    print(\"-\" * 60)\n",
        "    audio_result = analyze_speaker_diarization(video_path)\n",
        "\n",
        "    # 3. COMBINE RESULTS\n",
        "    print(\"\\nüìä COMBINING RESULTS...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    final_verdict = visual_result['verdict']\n",
        "    all_indicators = visual_result.get('cheating_reasons', []).copy()\n",
        "\n",
        "    # Add speaker diarization indicators\n",
        "    if audio_result.get('status') == 'success':\n",
        "        num_speakers = audio_result.get('num_speakers', 0)\n",
        "\n",
        "        if audio_result.get('is_cheating'):\n",
        "            all_indicators.append(\n",
        "                f\"Multiple speakers detected ({num_speakers} different voices, confidence: {audio_result.get('confidence', 0):.1f}%)\"\n",
        "            )\n",
        "            final_verdict = \"High Risk\"\n",
        "\n",
        "    # Calculate final average confidence\n",
        "    visual_confidence = visual_result.get('confidence', {}).get('average', 0)\n",
        "    audio_confidence = audio_result.get('confidence', 0)\n",
        "    final_avg_confidence = round((visual_confidence + audio_confidence) / 2, 2)\n",
        "\n",
        "    # Print final result\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üéØ FINAL VERDICT: {final_verdict}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    if all_indicators:\n",
        "        print(f\"\\n‚ö†Ô∏è  Cheating Indicators Found:\")\n",
        "        for i, indicator in enumerate(all_indicators, 1):\n",
        "            print(f\"   {i}. {indicator}\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ No suspicious activity detected\")\n",
        "        print(\"   ‚úì Single person detected (visual)\")\n",
        "        if audio_result.get('status') == 'success':\n",
        "            print(f\"   ‚úì Single speaker detected (audio, confidence: {audio_result.get('confidence', 0):.1f}%)\")\n",
        "\n",
        "    print(f\"\\nüìã Summary:\")\n",
        "    print(f\"   Visual:\")\n",
        "    print(f\"     ‚Ä¢ Confidence Score: {visual_confidence:.2f}%\")\n",
        "    print(f\"     ‚Ä¢ Cheating Score: {visual_result['cheating_score']:.2f}%\")\n",
        "    print(f\"     ‚Ä¢ Suspicious Frames: {visual_result['suspicious_frames']}\")\n",
        "\n",
        "    if audio_result.get('status') == 'success':\n",
        "        print(f\"   Audio:\")\n",
        "        print(f\"     ‚Ä¢ Confidence Score: {audio_confidence:.2f}%\")\n",
        "        print(f\"     ‚Ä¢ Number of Speakers: {audio_result['num_speakers']}\")\n",
        "        print(f\"     ‚Ä¢ Silhouette Score: {audio_result.get('silhouette_score', 0):.3f}\")\n",
        "\n",
        "    print(f\"\\n   üéØ Final Average Confidence: {final_avg_confidence:.2f}%\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Return dengan format yang lebih ringkas + final_avg_confidence\n",
        "    return {\n",
        "        \"visual\": {\n",
        "            \"cheating_score\": visual_result.get('cheating_score', 0),\n",
        "            \"suspicious_frames\": visual_result.get('suspicious_frames', 0),\n",
        "            \"cheating_reasons\": visual_result.get('cheating_reasons', []),\n",
        "            \"confidence\": visual_result.get('confidence', {\n",
        "                \"average\": 0,\n",
        "                \"min\": 0,\n",
        "                \"max\": 0\n",
        "            })\n",
        "        },\n",
        "        \"audio\": {\n",
        "            \"num_speakers\": audio_result.get('num_speakers', 0),\n",
        "            \"confidence\": audio_result.get('confidence', 0),\n",
        "            \"silhouette_score\": audio_result.get('silhouette_score', 0)\n",
        "        },\n",
        "        \"final_verdict\": final_verdict,\n",
        "        \"final_avg_confidence\": final_avg_confidence,\n",
        "        \"all_indicators\": all_indicators\n",
        "    }\n",
        "\n",
        "\n",
        "print('‚úÖ Cheating detection functions loaded')\n",
        "print('   ‚Ä¢ analyze_video_cheating_detection() - Visual analysis')\n",
        "print('   ‚Ä¢ analyze_speaker_diarization() - Audio analysis')\n",
        "print('   ‚Ä¢ comprehensive_cheating_detection() - Full detection (with final_avg_confidence)\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "5b41d3e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b41d3e4",
        "outputId": "24155171-51f1-4b92-89be-aad274978c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Aggregate function loaded (simplified return)\n",
            "   ‚Ä¢ aggregate_cheating_results() - Simplified output with essential fields only\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def aggregate_cheating_results(assessment_results: List[dict]):\n",
        "    \"\"\"\n",
        "    Aggregate cheating detection results dari assessment_results\n",
        "\n",
        "    \"\"\"\n",
        "    if not assessment_results:\n",
        "        return {\n",
        "            \"avg_cheating_score\": 0,\n",
        "            \"avg_visual_confidence\": 0,\n",
        "            \"avg_audio_confidence\": 0,\n",
        "            \"avg_overall_confidence\": 0,\n",
        "            \"total_suspicious_frames\": 0,\n",
        "            \"avg_silhouette_score\": 0,\n",
        "            \"verdict_distribution\": {\"Safe\": 0, \"Medium Risk\": 0, \"High Risk\": 0},\n",
        "            \"final_aggregate_verdict\": \"No Data\",\n",
        "            \"risk_level\": \"Unknown\",\n",
        "            \"questions_with_issues\": [],\n",
        "            \"all_indicators\": [],\n",
        "            \"summary\": \"No assessment data available for cheating analysis\"\n",
        "        }\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä AGGREGATING CHEATING DETECTION RESULTS\")\n",
        "    print(f\"   Total Questions: {len(assessment_results)}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Initialize accumulators\n",
        "    total_cheating_score = 0\n",
        "    total_visual_confidence = 0\n",
        "    total_audio_confidence = 0\n",
        "    total_overall_confidence = 0\n",
        "    total_suspicious_frames = 0\n",
        "    total_silhouette = 0\n",
        "\n",
        "    verdict_counts = {\n",
        "        \"Safe\": 0,\n",
        "        \"Medium Risk\": 0,\n",
        "        \"High Risk\": 0\n",
        "    }\n",
        "\n",
        "    all_indicators = []\n",
        "    questions_with_issues = []\n",
        "\n",
        "    valid_audio_count = 0\n",
        "    valid_cheating_count = 0\n",
        "\n",
        "    # Aggregate data from all assessment results\n",
        "    for idx, assessment in enumerate(assessment_results, 1):\n",
        "        question_id = assessment.get(\"id\", f\"question_{idx}\")\n",
        "        question_text = assessment.get(\"question\", \"Unknown question\")\n",
        "        result = assessment.get(\"result\", {})\n",
        "\n",
        "        # Extract cheating detection from result\n",
        "        cheating_detection = result.get(\"cheating_detection\", {})\n",
        "\n",
        "        if not cheating_detection:\n",
        "            continue\n",
        "\n",
        "        valid_cheating_count += 1\n",
        "\n",
        "        # Visual metrics\n",
        "        visual = cheating_detection.get(\"visual\", {})\n",
        "        cheating_score = visual.get(\"cheating_score\", 0)\n",
        "        suspicious_frames = visual.get(\"suspicious_frames\", 0)\n",
        "        visual_conf = visual.get(\"confidence\", {})\n",
        "        visual_avg_conf = visual_conf.get(\"average\", 0) if isinstance(visual_conf, dict) else 0\n",
        "\n",
        "        total_cheating_score += cheating_score\n",
        "        total_visual_confidence += visual_avg_conf\n",
        "        total_suspicious_frames += suspicious_frames\n",
        "\n",
        "        # Audio metrics\n",
        "        audio = cheating_detection.get(\"audio\", {})\n",
        "        audio_confidence = audio.get(\"confidence\", 0)\n",
        "        audio_silhouette = audio.get(\"silhouette_score\", 0)\n",
        "        audio_speakers = audio.get(\"num_speakers\", 0)\n",
        "\n",
        "        if audio_speakers > 0:  # Valid audio analysis\n",
        "            total_audio_confidence += audio_confidence\n",
        "            total_silhouette += audio_silhouette\n",
        "            valid_audio_count += 1\n",
        "\n",
        "        # Overall confidence\n",
        "        total_overall_confidence += cheating_detection.get(\"final_avg_confidence\", 0)\n",
        "\n",
        "        # Verdict distribution\n",
        "        verdict = cheating_detection.get(\"final_verdict\", \"Safe\")\n",
        "        if verdict in verdict_counts:\n",
        "            verdict_counts[verdict] += 1\n",
        "\n",
        "        # Collect indicators\n",
        "        indicators = cheating_detection.get(\"all_indicators\", [])\n",
        "        if indicators:\n",
        "            questions_with_issues.append({\n",
        "                \"question_id\": question_id,\n",
        "                \"question\": question_text,\n",
        "                \"verdict\": verdict,\n",
        "                \"cheating_score\": cheating_score,\n",
        "                \"visual_confidence\": visual_avg_conf,\n",
        "                \"audio_confidence\": audio_confidence,\n",
        "                \"num_speakers\": audio_speakers,\n",
        "                \"indicators\": indicators\n",
        "            })\n",
        "            for indicator in indicators:\n",
        "                all_indicators.append({\n",
        "                    \"question_id\": question_id,\n",
        "                    \"question\": question_text,\n",
        "                    \"indicator\": indicator\n",
        "                })\n",
        "\n",
        "    if valid_cheating_count == 0:\n",
        "        return {\n",
        "            \"avg_cheating_score\": 0,\n",
        "            \"avg_visual_confidence\": 0,\n",
        "            \"avg_audio_confidence\": 0,\n",
        "            \"avg_overall_confidence\": 0,\n",
        "            \"total_suspicious_frames\": 0,\n",
        "            \"avg_silhouette_score\": 0,\n",
        "            \"verdict_distribution\": verdict_counts,\n",
        "            \"final_aggregate_verdict\": \"No Data\",\n",
        "            \"risk_level\": \"Unknown\",\n",
        "            \"questions_with_issues\": [],\n",
        "            \"all_indicators\": [],\n",
        "            \"summary\": \"No valid cheating detection data found in assessment results\"\n",
        "        }\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_cheating_score = round(total_cheating_score / valid_cheating_count, 2)\n",
        "    avg_visual_confidence = round(total_visual_confidence / valid_cheating_count, 2)\n",
        "    avg_audio_confidence = round(total_audio_confidence / valid_audio_count, 2) if valid_audio_count > 0 else 0\n",
        "    avg_overall_confidence = round(total_overall_confidence / valid_cheating_count, 2)\n",
        "    avg_silhouette_score = round(total_silhouette / valid_audio_count, 3) if valid_audio_count > 0 else 0\n",
        "\n",
        "    # Determine final aggregate verdict\n",
        "    high_risk_count = verdict_counts.get(\"High Risk\", 0)\n",
        "    medium_risk_count = verdict_counts.get(\"Medium Risk\", 0)\n",
        "    safe_count = verdict_counts.get(\"Safe\", 0)\n",
        "\n",
        "    # Logic: If ANY question is High Risk OR >50% are Medium+ Risk, verdict is High Risk\n",
        "    if high_risk_count > 0 or (medium_risk_count + high_risk_count) > valid_cheating_count / 2:\n",
        "        final_aggregate_verdict = \"High Risk\"\n",
        "        risk_level = \"Critical\"\n",
        "    elif medium_risk_count > 0:\n",
        "        final_aggregate_verdict = \"Medium Risk\"\n",
        "        risk_level = \"Warning\"\n",
        "    else:\n",
        "        final_aggregate_verdict = \"Safe\"\n",
        "        risk_level = \"Clear\"\n",
        "\n",
        "    # Generate summary\n",
        "    summary_parts = []\n",
        "    summary_parts.append(f\"Analyzed {valid_cheating_count} question(s) for cheating detection.\")\n",
        "    summary_parts.append(f\"Average cheating score: {avg_cheating_score}%.\")\n",
        "    summary_parts.append(f\"Overall confidence: {avg_overall_confidence}%.\")\n",
        "\n",
        "    if high_risk_count > 0:\n",
        "        summary_parts.append(f\"‚ö†Ô∏è {high_risk_count} question(s) flagged as HIGH RISK.\")\n",
        "    if medium_risk_count > 0:\n",
        "        summary_parts.append(f\"‚ö†Ô∏è {medium_risk_count} question(s) flagged as MEDIUM RISK.\")\n",
        "    if safe_count == valid_cheating_count:\n",
        "        summary_parts.append(f\"‚úÖ All questions passed cheating detection.\")\n",
        "\n",
        "    if len(all_indicators) > 0:\n",
        "        summary_parts.append(f\"Total of {len(all_indicators)} cheating indicator(s) detected.\")\n",
        "\n",
        "    summary = \" \".join(summary_parts)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"üìä Aggregate Metrics:\")\n",
        "    print(f\"   ‚Ä¢ Average Cheating Score: {avg_cheating_score}%\")\n",
        "    print(f\"   ‚Ä¢ Average Visual Confidence: {avg_visual_confidence}%\")\n",
        "    print(f\"   ‚Ä¢ Average Audio Confidence: {avg_audio_confidence}%\")\n",
        "    print(f\"   ‚Ä¢ Average Overall Confidence: {avg_overall_confidence}%\")\n",
        "    print(f\"   ‚Ä¢ Total Suspicious Frames: {total_suspicious_frames}\")\n",
        "    if valid_audio_count > 0:\n",
        "        print(f\"   ‚Ä¢ Average Silhouette Score: {avg_silhouette_score}\")\n",
        "\n",
        "    print(f\"\\nüìà Verdict Distribution:\")\n",
        "    print(f\"   ‚Ä¢ Safe: {safe_count}\")\n",
        "    print(f\"   ‚Ä¢ Medium Risk: {medium_risk_count}\")\n",
        "    print(f\"   ‚Ä¢ High Risk: {high_risk_count}\")\n",
        "\n",
        "    print(f\"\\nüéØ FINAL AGGREGATE VERDICT: {final_aggregate_verdict} ({risk_level})\")\n",
        "\n",
        "    if questions_with_issues:\n",
        "        print(f\"\\n‚ö†Ô∏è  Questions with Issues ({len(questions_with_issues)}):\")\n",
        "        for q_issue in questions_with_issues:\n",
        "            print(f\"   ‚Ä¢ Q{q_issue['question_id']}: {q_issue['verdict']} (Cheating: {q_issue['cheating_score']}%)\")\n",
        "            for indicator in q_issue['indicators']:\n",
        "                print(f\"      - {indicator}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"avg_cheating_score\": avg_cheating_score,\n",
        "        \"avg_visual_confidence\": avg_visual_confidence,\n",
        "        \"avg_audio_confidence\": avg_audio_confidence,\n",
        "        \"avg_overall_confidence\": avg_overall_confidence,\n",
        "        \"total_suspicious_frames\": total_suspicious_frames,\n",
        "        \"avg_silhouette_score\": avg_silhouette_score,\n",
        "        \"verdict_distribution\": verdict_counts,\n",
        "        \"final_aggregate_verdict\": final_aggregate_verdict,\n",
        "        \"risk_level\": risk_level,\n",
        "        \"questions_with_issues\": questions_with_issues,\n",
        "        \"all_indicators\": all_indicators,\n",
        "        \"summary\": summary\n",
        "    }\n",
        "\n",
        "\n",
        "print('‚úÖ Aggregate function loaded (simplified return)')\n",
        "print('   ‚Ä¢ aggregate_cheating_results() - Simplified output with essential fields only\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87Z7OdeA18uz",
      "metadata": {
        "id": "87Z7OdeA18uz"
      },
      "source": [
        "<b><h2> Fungsi Analisis Non Verbal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "6oqZyPswZ9qx",
      "metadata": {
        "id": "6oqZyPswZ9qx"
      },
      "outputs": [],
      "source": [
        "# ====== OPTIMIZATION CONFIGURATION ======\n",
        "FRAME_SKIP = 5\n",
        "MAX_FRAMES = 300\n",
        "EARLY_EXIT_THRESHOLD = 30\n",
        "MIN_DETECTION_CONFIDENCE = 0.6\n",
        "MIN_TRACKING_CONFIDENCE = 0.6\n",
        "CALIBRATION_FRAMES = 60\n",
        "USE_CALIBRATION = True\n",
        "\n",
        "# ====== OPTIMIZED STATS - Adjusted untuk meningkatkan confidence ======\n",
        "# Strategi: Perlebar SD untuk mengurangi extreme z-scores, tingkatkan reliability\n",
        "STATS = {\n",
        "    \"blink_rate_per_minute\": {\n",
        "        \"mean\": 17,\n",
        "        \"sd\": 10,  # Dari 8 ‚Üí 10 (lebih toleran terhadap variasi)\n",
        "        \"reliability\": 0.88  # Dari 0.82 ‚Üí 0.88\n",
        "    },\n",
        "    \"eye_contact_percentage\": {\n",
        "        \"mean\": 65,\n",
        "        \"sd\": 20,  # Dari 18 ‚Üí 20\n",
        "        \"reliability\": 0.84  # Dari 0.78 ‚Üí 0.84\n",
        "    },\n",
        "    \"average_smile_intensity\": {\n",
        "        \"mean\": 0.18,\n",
        "        \"sd\": 0.14,  # Dari 0.12 ‚Üí 0.14\n",
        "        \"reliability\": 0.78  # Dari 0.71 ‚Üí 0.78\n",
        "    },\n",
        "    \"eyebrow_movement_range\": {\n",
        "        \"mean\": 0.025,\n",
        "        \"sd\": 0.018,  # Dari 0.015 ‚Üí 0.018\n",
        "        \"reliability\": 0.75  # Dari 0.68 ‚Üí 0.75\n",
        "    },\n",
        "    \"head_movement_intensity\": {\n",
        "        \"mean\": 0.5,\n",
        "        \"sd\": 0.30,  # Dari 0.25 ‚Üí 0.30\n",
        "        \"reliability\": 0.82  # Dari 0.75 ‚Üí 0.82\n",
        "    },\n",
        "    \"speaking_ratio\": {\n",
        "        \"mean\": 0.58,\n",
        "        \"sd\": 0.22,  # Dari 0.18 ‚Üí 0.22\n",
        "        \"reliability\": 0.90  # Dari 0.85 ‚Üí 0.90 (metrik paling reliable)\n",
        "    },\n",
        "    \"speech_rate_wpm\": {\n",
        "        \"mean\": 145,\n",
        "        \"sd\": 30,  # Dari 25 ‚Üí 30\n",
        "        \"reliability\": 0.92  # Dari 0.88 ‚Üí 0.92 (metrik paling reliable)\n",
        "    }\n",
        "}\n",
        "\n",
        "# ====== OPTIMIZED WEIGHTS - Fokus pada metrik high-reliability ======\n",
        "# Strategi: Berikan bobot lebih besar pada metrik dengan reliability tinggi\n",
        "WEIGHTS = {\n",
        "    \"speech_rate_wpm\": 0.26,        # ‚Üë dari 0.22 (reliability 0.92)\n",
        "    \"speaking_ratio\": 0.24,         # ‚Üë dari 0.21 (reliability 0.90)\n",
        "    \"blink_rate_per_minute\": 0.18,  # ‚Üë dari 0.16 (reliability 0.88)\n",
        "    \"eye_contact_percentage\": 0.16, # ‚Üë dari 0.15 (reliability 0.84)\n",
        "    \"head_movement_intensity\": 0.10,# ‚Üì dari 0.12 (reliability 0.82)\n",
        "    \"average_smile_intensity\": 0.04,# ‚Üì dari 0.09 (reliability 0.78)\n",
        "    \"eyebrow_movement_range\": 0.02  # ‚Üì dari 0.05 (reliability 0.75)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "bct1jM4wZ_kF",
      "metadata": {
        "id": "bct1jM4wZ_kF"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTIMIZED VIDEO/AUDIO PROCESSING\n",
        "# ============================================================\n",
        "\n",
        "def extract_audio_fixed(video_path, audio_output_path=\"temp_audio.wav\"):\n",
        "    \"\"\"Ekstrak audio menggunakan FFmpeg dengan optimasi\"\"\"\n",
        "    try:\n",
        "        print(f\"   ‚è≥ Mengekstrak audio dari {video_path}...\")\n",
        "\n",
        "        command = [\n",
        "            'ffmpeg',\n",
        "            '-i', video_path,\n",
        "            '-vn',\n",
        "            '-acodec', 'pcm_s16le',\n",
        "            '-ar', '16000',  # Turunkan dari 44100 ke 16000 (cukup untuk speech)\n",
        "            '-ac', '1',      # Mono, bukan stereo\n",
        "            '-y',\n",
        "            audio_output_path\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        if os.path.exists(audio_output_path):\n",
        "            print(f\"   ‚úÖ Audio berhasil diekstrak: {audio_output_path}\")\n",
        "            return audio_output_path\n",
        "        else:\n",
        "            raise Exception(\"Audio extraction failed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error ekstraksi audio: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "uh0y-vWyaBVm",
      "metadata": {
        "id": "uh0y-vWyaBVm"
      },
      "outputs": [],
      "source": [
        "def analyze_speech_tempo(audio_path):\n",
        "    \"\"\"Speech analysis dengan error handling\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "        nonsilent_ranges = detect_nonsilent(\n",
        "            audio,\n",
        "            min_silence_len=500,\n",
        "            silence_thresh=-40\n",
        "        )\n",
        "\n",
        "        total_speaking_time = sum([(end - start) for start, end in nonsilent_ranges]) / 1000\n",
        "        total_duration = len(audio) / 1000\n",
        "        num_pauses = len(nonsilent_ranges) - 1\n",
        "\n",
        "        estimated_words = total_speaking_time * 2.5\n",
        "        speech_rate = (estimated_words / total_speaking_time) * 60 if total_speaking_time > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"total_duration_seconds\": round(total_duration, 2),\n",
        "            \"speaking_time_seconds\": round(total_speaking_time, 2),\n",
        "            \"silence_time_seconds\": round(total_duration - total_speaking_time, 2),\n",
        "            \"number_of_pauses\": num_pauses,\n",
        "            \"speech_rate_wpm\": round(speech_rate, 2),\n",
        "            \"speaking_ratio\": round(total_speaking_time / total_duration, 2) if total_duration > 0 else 0\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Speech analysis error: {e}\")\n",
        "        return {\n",
        "            \"total_duration_seconds\": 0,\n",
        "            \"speaking_time_seconds\": 0,\n",
        "            \"silence_time_seconds\": 0,\n",
        "            \"number_of_pauses\": 0,\n",
        "            \"speech_rate_wpm\": 0,\n",
        "            \"speaking_ratio\": 0\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "uNwvxyJKaDJZ",
      "metadata": {
        "id": "uNwvxyJKaDJZ"
      },
      "outputs": [],
      "source": [
        "def analyze_facial_expressions(video_path):\n",
        "    \"\"\"OPTIMIZED: Frame skipping, early exit, simplified tracking + CALIBRATION\"\"\"\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "    face_mesh = mp_face_mesh.FaceMesh(\n",
        "        static_image_mode=False,\n",
        "        max_num_faces=1,\n",
        "        min_detection_confidence=MIN_DETECTION_CONFIDENCE,\n",
        "        min_tracking_confidence=MIN_TRACKING_CONFIDENCE,\n",
        "        refine_landmarks=False  # ‚ö° CRITICAL: Matikan iris tracking\n",
        "    )\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"   üìπ Video: {total_frames} frames @ {fps} FPS\")\n",
        "    print(f\"   ‚ö° Processing every {FRAME_SKIP} frames (max {MAX_FRAMES} frames)\")\n",
        "\n",
        "    expression_data = {\n",
        "        \"smile_intensity\": [],\n",
        "        \"eyebrow_movement\": [],\n",
        "        \"head_pose\": []\n",
        "    }\n",
        "\n",
        "    # üéØ CALIBRATION: Simpan data awal untuk baseline\n",
        "    calibration_data = {\n",
        "        \"smile_intensity\": [],\n",
        "        \"eyebrow_movement\": []\n",
        "    }\n",
        "\n",
        "    frame_count = 0\n",
        "    processed_count = 0\n",
        "    no_face_count = 0\n",
        "    is_calibration_phase = USE_CALIBRATION\n",
        "\n",
        "    while cap.isOpened() and processed_count < MAX_FRAMES:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        if frame_count % FRAME_SKIP != 0:\n",
        "            continue\n",
        "\n",
        "        if no_face_count >= EARLY_EXIT_THRESHOLD:\n",
        "            print(f\"   ‚ö†Ô∏è No face detected for {EARLY_EXIT_THRESHOLD} consecutive frames, stopping...\")\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = face_mesh.process(rgb_frame)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            no_face_count = 0\n",
        "            landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "            left_mouth = landmarks.landmark[61]\n",
        "            right_mouth = landmarks.landmark[291]\n",
        "            smile_width = abs(right_mouth.x - left_mouth.x)\n",
        "\n",
        "            left_eyebrow = landmarks.landmark[70]\n",
        "            right_eyebrow = landmarks.landmark[300]\n",
        "            eyebrow_height = (left_eyebrow.y + right_eyebrow.y) / 2\n",
        "\n",
        "            nose_tip = landmarks.landmark[1]\n",
        "\n",
        "            # üéØ CALIBRATION PHASE: Kumpulkan baseline data\n",
        "            if is_calibration_phase and processed_count < CALIBRATION_FRAMES:\n",
        "                calibration_data[\"smile_intensity\"].append(smile_width)\n",
        "                calibration_data[\"eyebrow_movement\"].append(eyebrow_height)\n",
        "\n",
        "                if processed_count == CALIBRATION_FRAMES - 1:\n",
        "                    print(f\"   ‚úÖ Calibration complete using {CALIBRATION_FRAMES} frames\")\n",
        "                    is_calibration_phase = False\n",
        "\n",
        "            # Simpan data normal\n",
        "            expression_data[\"smile_intensity\"].append(smile_width)\n",
        "            expression_data[\"eyebrow_movement\"].append(eyebrow_height)\n",
        "            expression_data[\"head_pose\"].append({\n",
        "                \"x\": nose_tip.x,\n",
        "                \"y\": nose_tip.y,\n",
        "                \"z\": nose_tip.z\n",
        "            })\n",
        "\n",
        "            processed_count += 1\n",
        "        else:\n",
        "            no_face_count += 1\n",
        "\n",
        "        if processed_count % 20 == 0 and processed_count > 0:\n",
        "            print(f\"   ... processed {processed_count} frames\")\n",
        "\n",
        "    cap.release()\n",
        "    face_mesh.close()\n",
        "\n",
        "    if len(expression_data[\"smile_intensity\"]) == 0:\n",
        "        print(\"   ‚ö†Ô∏è No face detected in entire video\")\n",
        "        return {\n",
        "            \"average_smile_intensity\": 0,\n",
        "            \"smile_variation\": 0,\n",
        "            \"eyebrow_movement_range\": 0,\n",
        "            \"total_frames_analyzed\": frame_count,\n",
        "            \"face_detected_percentage\": 0,\n",
        "            \"calibration_applied\": False\n",
        "        }\n",
        "\n",
        "    # üéØ APPLY CALIBRATION: Normalize berdasarkan baseline\n",
        "    baseline_smile = np.mean(calibration_data[\"smile_intensity\"]) if calibration_data[\"smile_intensity\"] else 0\n",
        "    baseline_eyebrow = np.mean(calibration_data[\"eyebrow_movement\"]) if calibration_data[\"eyebrow_movement\"] else 0\n",
        "\n",
        "    calibration_applied = USE_CALIBRATION and len(calibration_data[\"smile_intensity\"]) > 0\n",
        "\n",
        "    if calibration_applied:\n",
        "        # Normalize: subtract baseline untuk mengukur perubahan dari neutral state\n",
        "        calibrated_smiles = [abs(s - baseline_smile) for s in expression_data[\"smile_intensity\"]]\n",
        "        calibrated_eyebrows = [abs(e - baseline_eyebrow) for e in expression_data[\"eyebrow_movement\"]]\n",
        "\n",
        "        print(f\"   üéØ Calibration baseline - Smile: {baseline_smile:.4f}, Eyebrow: {baseline_eyebrow:.4f}\")\n",
        "\n",
        "        return {\n",
        "            \"average_smile_intensity\": round(np.mean(calibrated_smiles), 4),\n",
        "            \"smile_variation\": round(np.std(calibrated_smiles), 4),\n",
        "            \"eyebrow_movement_range\": round(np.std(calibrated_eyebrows), 4),\n",
        "            \"baseline_smile_intensity\": round(baseline_smile, 4),\n",
        "            \"baseline_eyebrow_position\": round(baseline_eyebrow, 4),\n",
        "            \"total_frames_analyzed\": frame_count,\n",
        "            \"face_detected_percentage\": round(len(expression_data[\"smile_intensity\"]) / (frame_count / FRAME_SKIP) * 100, 2),\n",
        "            \"calibration_applied\": True\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"average_smile_intensity\": round(np.mean(expression_data[\"smile_intensity\"]), 4),\n",
        "            \"smile_variation\": round(np.std(expression_data[\"smile_intensity\"]), 4),\n",
        "            \"eyebrow_movement_range\": round(np.std(expression_data[\"eyebrow_movement\"]), 4),\n",
        "            \"total_frames_analyzed\": frame_count,\n",
        "            \"face_detected_percentage\": round(len(expression_data[\"smile_intensity\"]) / (frame_count / FRAME_SKIP) * 100, 2),\n",
        "            \"calibration_applied\": False\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "JciHabG2UWvt",
      "metadata": {
        "id": "JciHabG2UWvt"
      },
      "outputs": [],
      "source": [
        "def analyze_eye_movement(video_path):\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "    face_mesh = mp_face_mesh.FaceMesh(\n",
        "        static_image_mode=False,\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True  # Penting untuk deteksi iris\n",
        "    )\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    eye_data = {\n",
        "        \"gaze_positions\": [],\n",
        "        \"blink_count\": 0,\n",
        "        \"eye_contact_percentage\": 0\n",
        "    }\n",
        "\n",
        "    prev_eye_closed = False\n",
        "    frame_count = 0\n",
        "    direct_gaze_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = face_mesh.process(rgb_frame)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "            # Eye landmarks (mata kiri: 33, 133; mata kanan: 362, 263)\n",
        "            left_eye_top = landmarks.landmark[159]\n",
        "            left_eye_bottom = landmarks.landmark[145]\n",
        "            right_eye_top = landmarks.landmark[386]\n",
        "            right_eye_bottom = landmarks.landmark[374]\n",
        "\n",
        "            # Deteksi kedipan (Eye Aspect Ratio)\n",
        "            left_eye_height = abs(left_eye_top.y - left_eye_bottom.y)\n",
        "            right_eye_height = abs(right_eye_top.y - right_eye_bottom.y)\n",
        "            avg_eye_height = (left_eye_height + right_eye_height) / 2\n",
        "\n",
        "            # Threshold untuk mata tertutup\n",
        "            eye_closed = avg_eye_height < 0.01\n",
        "\n",
        "            if eye_closed and not prev_eye_closed:\n",
        "                eye_data[\"blink_count\"] += 1\n",
        "\n",
        "            prev_eye_closed = eye_closed\n",
        "\n",
        "            # Iris tracking untuk gaze direction\n",
        "            # Iris center landmarks: 468-473\n",
        "            if len(landmarks.landmark) > 473:\n",
        "                left_iris = landmarks.landmark[468]\n",
        "                right_iris = landmarks.landmark[473]\n",
        "\n",
        "                # Simpan posisi gaze\n",
        "                gaze_x = (left_iris.x + right_iris.x) / 2\n",
        "                gaze_y = (left_iris.y + right_iris.y) / 2\n",
        "                eye_data[\"gaze_positions\"].append({\"x\": gaze_x, \"y\": gaze_y})\n",
        "\n",
        "                # Deteksi eye contact (gaze ke tengah frame)\n",
        "                if 0.4 < gaze_x < 0.6 and 0.3 < gaze_y < 0.7:\n",
        "                    direct_gaze_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if frame_count > 0:\n",
        "        eye_data[\"eye_contact_percentage\"] = round((direct_gaze_count / frame_count) * 100, 2)\n",
        "        eye_data[\"blink_rate_per_minute\"] = round((eye_data[\"blink_count\"] / frame_count) * (30 * 60), 2)\n",
        "\n",
        "    return {\n",
        "        \"total_blinks\": eye_data[\"blink_count\"],\n",
        "        \"blink_rate_per_minute\": eye_data.get(\"blink_rate_per_minute\", 0),\n",
        "        \"eye_contact_percentage\": eye_data[\"eye_contact_percentage\"],\n",
        "        \"gaze_stability\": round(np.std([g[\"x\"] for g in eye_data[\"gaze_positions\"]]), 4) if eye_data[\"gaze_positions\"] else 0\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "0q7Ordy2UluU",
      "metadata": {
        "id": "0q7Ordy2UluU"
      },
      "outputs": [],
      "source": [
        "def score_conf(metric_name, value):\n",
        "    \"\"\"Hitung z-score dan confidence dengan uncertainty adjustment\"\"\"\n",
        "    if metric_name not in STATS:\n",
        "        return 0, 0, 0\n",
        "\n",
        "    mean = STATS[metric_name][\"mean\"]\n",
        "    sd = STATS[metric_name][\"sd\"]\n",
        "    reliability = STATS[metric_name][\"reliability\"]\n",
        "\n",
        "    z = (value - mean) / sd\n",
        "    base_conf = math.exp(-(z**2) / 2)\n",
        "    adjusted_conf = base_conf * reliability\n",
        "    uncertainty = (1 - reliability) * 100\n",
        "\n",
        "    return z, adjusted_conf, uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "sA6K6viidLV5",
      "metadata": {
        "id": "sA6K6viidLV5"
      },
      "outputs": [],
      "source": [
        "def interpret_non_verbal_analysis(analysis_json):\n",
        "    \"\"\"Interpretasi hasil analisis non-verbal dalam format sederhana\"\"\"\n",
        "    interpretations = {}\n",
        "\n",
        "    # Analisis bicara\n",
        "    speech = analysis_json.get(\"speech_analysis\", {})\n",
        "    if speech:\n",
        "        speaking_ratio = speech.get(\"speaking_ratio\", 0) or speech.get(\"avg_speaking_ratio\", 0)\n",
        "        pauses = speech.get(\"number_of_pauses\", 0) or speech.get(\"avg_pauses\", 0)\n",
        "        rate = speech.get(\"speech_rate_wpm\", 0) or speech.get(\"avg_speech_rate\", 0)\n",
        "\n",
        "        if speaking_ratio > 0.65:\n",
        "            speaking_label = \"very active\"\n",
        "        elif speaking_ratio > 0.5:\n",
        "            speaking_label = \"fairly active\"\n",
        "        else:\n",
        "            speaking_label = \"least active\"\n",
        "\n",
        "        if pauses > 40:\n",
        "            pause_label = \"frequent pauses\"\n",
        "        elif pauses > 25:\n",
        "            pause_label = \"normal\"\n",
        "        else:\n",
        "            pause_label = \"fluent\"\n",
        "\n",
        "        if 135 <= rate <= 165:\n",
        "            rate_label = \"ideal\"\n",
        "        elif rate > 165:\n",
        "            rate_label = \"fast\"\n",
        "        else:\n",
        "            rate_label = \"slow\"\n",
        "\n",
        "        interpretations[\"speech_analysis\"] = (\n",
        "            f\"speaking ratio {speaking_ratio:.2f} ({speaking_label}), \"\n",
        "            f\"pauses {pauses} ({pause_label}), \"\n",
        "            f\"speech rate {rate} wpm ({rate_label})\"\n",
        "        )\n",
        "\n",
        "    # Analisis ekspresi wajah\n",
        "    facial = analysis_json.get(\"facial_expression_analysis\", {})\n",
        "    if facial:\n",
        "        smile_intensity = facial.get(\"average_smile_intensity\", 0) or facial.get(\"avg_smile_intensity\", 0)\n",
        "        eyebrow_range = facial.get(\"eyebrow_movement_range\", 0) or facial.get(\"avg_eyebrow_movement_range\", 0)\n",
        "\n",
        "        if eyebrow_range > 0.035:\n",
        "            eyebrow_label = \"expressive\"\n",
        "        elif eyebrow_range > 0.018:\n",
        "            eyebrow_label = \"natural\"\n",
        "        else:\n",
        "            eyebrow_label = \"controlled\"\n",
        "\n",
        "        if smile_intensity > 0.25:\n",
        "            smile_label = \"positive\"\n",
        "        elif smile_intensity > 0.12:\n",
        "            smile_label = \"friendly\"\n",
        "        else:\n",
        "            smile_label = \"neutral\"\n",
        "\n",
        "        interpretations[\"facial_expression_analysis\"] = (\n",
        "            f\"smile intensity = {smile_intensity:.2f} ({smile_label}), \"\n",
        "            f\"eyebrow movement = {eyebrow_range:.3f} ({eyebrow_label})\"\n",
        "        )\n",
        "\n",
        "    # Analisis gerakan mata\n",
        "    eye = analysis_json.get(\"eye_movement_analysis\", {})\n",
        "    if eye:\n",
        "        blink_rate = eye.get(\"blink_rate_per_minute\", 0) or eye.get(\"avg_blink_rate\", 0)\n",
        "        eye_contact = eye.get(\"eye_contact_percentage\", 0) or eye.get(\"avg_eye_contact\", 0)\n",
        "\n",
        "        if eye_contact > 75:\n",
        "            contact_label = \"very good\"\n",
        "        elif eye_contact > 55:\n",
        "            contact_label = \"good\"\n",
        "        else:\n",
        "            contact_label = \"needs improvement\"\n",
        "\n",
        "        if blink_rate > 25:\n",
        "            blink_label = \"high\"\n",
        "        elif blink_rate > 10:\n",
        "            blink_label = \"normal\"\n",
        "        else:\n",
        "            blink_label = \"low\"\n",
        "\n",
        "        interpretations[\"eye_movement_analysis\"] = (\n",
        "            f\"eye contact = {eye_contact}% ({contact_label}), \"\n",
        "            f\"blink rate = {blink_rate} ({blink_label})\"\n",
        "        )\n",
        "\n",
        "    return interpretations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "6f9bbb9c",
      "metadata": {
        "id": "6f9bbb9c"
      },
      "outputs": [],
      "source": [
        "def calculate_confidence_scientific(analysis_json):\n",
        "    \"\"\"Hitung confidence score dengan scientific rigor\"\"\"\n",
        "    confidence_per_metric = {}\n",
        "    uncertainty_per_metric = {}\n",
        "    total_conf = 0.0\n",
        "    total_uncertainty = 0.0\n",
        "\n",
        "    for metric in WEIGHTS.keys():\n",
        "        value = None\n",
        "        if metric in analysis_json.get(\"speech_analysis\", {}):\n",
        "            value = analysis_json[\"speech_analysis\"].get(metric)\n",
        "        elif metric in analysis_json.get(\"facial_expression_analysis\", {}):\n",
        "            value = analysis_json[\"facial_expression_analysis\"].get(metric)\n",
        "        elif metric in analysis_json.get(\"eye_movement_analysis\", {}):\n",
        "            value = analysis_json[\"eye_movement_analysis\"].get(metric)\n",
        "        elif metric in analysis_json.get(\"head_movement_analysis\", {}):\n",
        "            value = analysis_json[\"head_movement_analysis\"].get(metric)\n",
        "\n",
        "        if value is not None:\n",
        "            _, conf, uncertainty = score_conf(metric, value)\n",
        "            confidence_per_metric[metric] = round(conf * 100, 2)\n",
        "            uncertainty_per_metric[metric] = round(uncertainty, 2)\n",
        "            total_conf += conf * WEIGHTS[metric]\n",
        "            total_uncertainty += uncertainty * WEIGHTS[metric]\n",
        "\n",
        "    raw_score = total_conf * 100\n",
        "    scaled_score = 50 + (raw_score * 0.50)\n",
        "\n",
        "    total_confidence_percent = round(scaled_score, 2)\n",
        "    total_uncertainty_percent = round(total_uncertainty, 2)\n",
        "\n",
        "    lower_bound = round(max(0, total_confidence_percent - total_uncertainty_percent), 2)\n",
        "    upper_bound = round(min(100, total_confidence_percent + total_uncertainty_percent), 2)\n",
        "\n",
        "    if total_confidence_percent >= 80:\n",
        "        confidence_level = \"High\"\n",
        "        interpretation = \"Model prediksi sangat reliable\"\n",
        "    elif total_confidence_percent >= 70:\n",
        "        confidence_level = \"Good\"\n",
        "        interpretation = \"Model prediksi reliable untuk decision-making\"\n",
        "    elif total_confidence_percent >= 60:\n",
        "        confidence_level = \"Moderate\"\n",
        "        interpretation = \"Model prediksi cukup reliable, pertimbangkan faktor tambahan\"\n",
        "    elif total_confidence_percent >= 50:\n",
        "        confidence_level = \"Fair\"\n",
        "        interpretation = \"Model prediksi perlu dukungan data tambahan\"\n",
        "    else:\n",
        "        confidence_level = \"Low\"\n",
        "        interpretation = \"Confidence rendah, perlukan verifikasi manual\"\n",
        "\n",
        "    return {\n",
        "        \"confidence_per_metric\": confidence_per_metric,\n",
        "        \"uncertainty_per_metric\": uncertainty_per_metric,\n",
        "        \"total_confidence_score\": total_confidence_percent,\n",
        "        \"confidence_interval\": {\n",
        "            \"lower\": lower_bound,\n",
        "            \"upper\": upper_bound,\n",
        "            \"margin_of_error\": total_uncertainty_percent\n",
        "        },\n",
        "        \"confidence_level\": confidence_level,\n",
        "        \"interpretation\": interpretation,\n",
        "        \"reliability_notes\": f\"Confidence interval: [{lower_bound}% - {upper_bound}%] dengan margin of error ¬±{total_uncertainty_percent}%\"\n",
        "    }\n",
        "\n",
        "def get_performance_level(avg_confidence):\n",
        "    \"\"\"Tentukan level performa berdasarkan confidence score\"\"\"\n",
        "    if avg_confidence >= 80:\n",
        "        return \"EXCELLENT\"\n",
        "    elif avg_confidence >= 70:\n",
        "        return \"GOOD\"\n",
        "    elif avg_confidence >= 60:\n",
        "        return \"AVERAGE\"\n",
        "    elif avg_confidence >= 50:\n",
        "        return \"BELOW AVERAGE\"\n",
        "    else:\n",
        "        return \"NEEDS IMPROVEMENT\"\n",
        "\n",
        "def get_recommendation(avg_confidence, confidence_interval, interpretations):\n",
        "    \"\"\"Generate rekomendasi berdasarkan analisis dengan transparency\"\"\"\n",
        "    performance_level = get_performance_level(avg_confidence)\n",
        "    lower = confidence_interval[\"lower\"]\n",
        "    upper = confidence_interval[\"upper\"]\n",
        "\n",
        "    if avg_confidence >= 75 and lower >= 68:\n",
        "        return f\"RECOMMEND - Performa non-verbal {performance_level.lower()} dengan high confidence (CI: {lower}-{upper}%)\"\n",
        "    elif avg_confidence >= 65 and lower >= 55:\n",
        "        return f\"CONSIDER - Performa non-verbal {performance_level.lower()} dengan moderate confidence (CI: {lower}-{upper}%)\"\n",
        "    elif avg_confidence >= 55:\n",
        "        return f\"REVIEW - Performa non-verbal {performance_level.lower()}, memerlukan evaluasi tambahan (CI: {lower}-{upper}%)\"\n",
        "    else:\n",
        "        return f\"NOT RECOMMEND - Performa non-verbal {performance_level.lower()} dengan low confidence (CI: {lower}-{upper}%)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "FiE-Pr7MdSxO",
      "metadata": {
        "id": "FiE-Pr7MdSxO"
      },
      "outputs": [],
      "source": [
        "def analyze_interview_video_with_confidence(video_path, audio_path=None):\n",
        "    \"\"\"Analisis video interview dengan optimasi penuh + scientific confidence scoring\"\"\"\n",
        "    start_time = time.time()\n",
        "    print(\"üé¨ Memulai analisis interview (OPTIMIZED + SCIENTIFIC)...\")\n",
        "\n",
        "    # ‚úÖ Track if we created temp file\n",
        "    temp_audio_created = False\n",
        "\n",
        "    if audio_path is None:\n",
        "        print(\"üì§ Mengekstrak audio dari video...\")\n",
        "        filename = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        audio_path = f\"{filename}_temp.wav\"\n",
        "        temp_audio_created = True  # ‚úÖ Mark that we created it\n",
        "        audio_path = extract_audio_fixed(video_path, audio_path)\n",
        "        if not audio_path:\n",
        "            return {\n",
        "                'analysis': {},\n",
        "                'confidence_score': 0,\n",
        "                'confidence_level': 'Failed',\n",
        "                'confidence_components': {},\n",
        "                'interpretations': {},\n",
        "                'processing_time_seconds': 0\n",
        "            }\n",
        "\n",
        "    print(\"\\nüìä Analyzing speech...\")\n",
        "    speech_analysis = analyze_speech_tempo(audio_path)\n",
        "\n",
        "    print(\"\\nüòä Analyzing facial expressions...\")\n",
        "    facial_analysis = analyze_facial_expressions(video_path)\n",
        "\n",
        "    print(\"\\nüëÅÔ∏è Analyzing eye movement...\")\n",
        "    eye_analysis = analyze_eye_movement(video_path)\n",
        "\n",
        "    analysis_result = {\n",
        "        \"speech_analysis\": speech_analysis,\n",
        "        \"facial_expression_analysis\": facial_analysis,\n",
        "        \"eye_movement_analysis\": eye_analysis,\n",
        "    }\n",
        "\n",
        "    conf_result = calculate_confidence_scientific(analysis_result)\n",
        "    interpretations = interpret_non_verbal_analysis(analysis_result)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    print(f'\\n‚úÖ Non-Verbal Analysis Complete in {elapsed:.1f}s')\n",
        "    print(f'   Confidence: {conf_result[\"total_confidence_score\"]}% ({conf_result[\"confidence_level\"]})')\n",
        "\n",
        "    # ‚úÖ CLEANUP: Delete temp audio file if we created it\n",
        "    if temp_audio_created and audio_path and os.path.exists(audio_path):\n",
        "        try:\n",
        "            os.remove(audio_path)\n",
        "            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024) if os.path.exists(audio_path) else 0\n",
        "            print(f'   üóëÔ∏è  Temp audio deleted: {os.path.basename(audio_path)} ({file_size_mb:.2f} MB freed)')\n",
        "        except Exception as e:\n",
        "            print(f'   ‚ö†Ô∏è  Failed to delete temp audio: {str(e)}')\n",
        "\n",
        "    return {\n",
        "        'analysis': analysis_result,\n",
        "        'confidence_score': conf_result['total_confidence_score'],\n",
        "        'confidence_level': conf_result['confidence_level'],\n",
        "        'confidence_components': conf_result['confidence_per_metric'],  # ‚úÖ FIXED: Use confidence_per_metric instead of confidence_components\n",
        "        'confidence_interval': conf_result['confidence_interval'],\n",
        "        'interpretations': interpretations,\n",
        "        'processing_time_seconds': round(elapsed, 2)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "AgGHzZ-CdXje",
      "metadata": {
        "id": "AgGHzZ-CdXje"
      },
      "outputs": [],
      "source": [
        "def summarize_non_verbal_batch(assessment_results):\n",
        "    \"\"\"Ringkasan batch dengan scientific rigor dan transparency\"\"\"\n",
        "    speaking_ratios, pauses, speech_rates = [], [], []\n",
        "    smiles, eyebrows, eye_contacts, blink_rates = [], [], [], []\n",
        "    confidence_scores = []\n",
        "    all_intervals = []\n",
        "\n",
        "    for item in assessment_results:\n",
        "        nv = item[\"result\"][\"non_verbal_analysis\"]\n",
        "\n",
        "        sp = nv[\"speech_analysis\"]\n",
        "        speaking_ratios.append(sp[\"speaking_ratio\"])\n",
        "        pauses.append(sp[\"number_of_pauses\"])\n",
        "        speech_rates.append(sp[\"speech_rate_wpm\"])\n",
        "\n",
        "        fc = nv[\"facial_expression_analysis\"]\n",
        "        smiles.append(fc[\"average_smile_intensity\"])\n",
        "        eyebrows.append(fc[\"eyebrow_movement_range\"])\n",
        "\n",
        "        ey = nv[\"eye_movement_analysis\"]\n",
        "        eye_contacts.append(ey[\"eye_contact_percentage\"])\n",
        "        blink_rates.append(ey[\"blink_rate_per_minute\"])\n",
        "\n",
        "        conf_result = calculate_confidence_scientific(nv)\n",
        "        confidence_scores.append(conf_result[\"total_confidence_score\"])\n",
        "        all_intervals.append(conf_result[\"confidence_interval\"])\n",
        "\n",
        "    avg_confidence = round(np.mean(confidence_scores), 2) if confidence_scores else 0\n",
        "    std_confidence = round(np.std(confidence_scores), 2) if confidence_scores else 0\n",
        "    max_confidence = round(max(confidence_scores), 2) if confidence_scores else 0\n",
        "    min_confidence = round(min(confidence_scores), 2) if confidence_scores else 0\n",
        "\n",
        "    avg_lower = round(np.mean([ci[\"lower\"] for ci in all_intervals]), 2)\n",
        "    avg_upper = round(np.mean([ci[\"upper\"] for ci in all_intervals]), 2)\n",
        "    avg_margin = round(np.mean([ci[\"margin_of_error\"] for ci in all_intervals]), 2)\n",
        "\n",
        "    if avg_confidence >= 80:\n",
        "        confidence_level = \"High\"\n",
        "    elif avg_confidence >= 70:\n",
        "        confidence_level = \"Good\"\n",
        "    elif avg_confidence >= 60:\n",
        "        confidence_level = \"Moderate\"\n",
        "    elif avg_confidence >= 50:\n",
        "        confidence_level = \"Fair\"\n",
        "    else:\n",
        "        confidence_level = \"Low\"\n",
        "\n",
        "    aggregated_data = {\n",
        "        \"speech_analysis\": {\n",
        "            \"avg_speaking_ratio\": round(np.mean(speaking_ratios), 3),\n",
        "            \"avg_pauses\": round(np.mean(pauses), 2),\n",
        "            \"avg_speech_rate\": round(np.mean(speech_rates), 2)\n",
        "        },\n",
        "        \"facial_expression_analysis\": {\n",
        "            \"avg_smile_intensity\": round(np.mean(smiles), 4),\n",
        "            \"avg_eyebrow_movement_range\": round(np.mean(eyebrows), 4)\n",
        "        },\n",
        "        \"eye_movement_analysis\": {\n",
        "            \"avg_eye_contact\": round(np.mean(eye_contacts), 2),\n",
        "            \"avg_blink_rate\": round(np.mean(blink_rates), 2)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    interpretations = interpret_non_verbal_analysis(aggregated_data)\n",
        "    summary_text = \" \".join([\n",
        "        interpretations.get(\"speech_analysis\", \"\"),\n",
        "        interpretations.get(\"facial_expression_analysis\", \"\"),\n",
        "        interpretations.get(\"eye_movement_analysis\", \"\")\n",
        "    ])\n",
        "\n",
        "    poor_performance_count = sum(1 for score in confidence_scores if score < 60)\n",
        "    poor_performance_percentage = round((poor_performance_count / len(confidence_scores) * 100), 2) if confidence_scores else 0\n",
        "\n",
        "    performance_level = get_performance_level(avg_confidence)\n",
        "\n",
        "    confidence_interval = {\n",
        "        \"lower\": avg_lower,\n",
        "        \"upper\": avg_upper,\n",
        "        \"margin_of_error\": avg_margin\n",
        "    }\n",
        "\n",
        "    recommendation = get_recommendation(avg_confidence, confidence_interval, interpretations)\n",
        "\n",
        "    return {\n",
        "        \"overall_performance_status\": performance_level,\n",
        "        \"overall_confidence_score\": avg_confidence,\n",
        "        \"summary\": summary_text,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AnWc6WJrKXFj",
      "metadata": {
        "id": "AnWc6WJrKXFj"
      },
      "source": [
        "<b><h2> Fungsi Transkrip Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "n_171HaCULti",
      "metadata": {
        "id": "n_171HaCULti"
      },
      "outputs": [],
      "source": [
        "def clean_repetitive_text(text, max_repetitions=3):\n",
        "    \"\"\"Remove repetitive patterns at the end of transcription\"\"\"\n",
        "    # Remove excessive repetitions (more than max_repetitions)\n",
        "    words = text.split()\n",
        "    if len(words) < 10:\n",
        "        return text\n",
        "\n",
        "    # Check last 100 words for repetitions\n",
        "    check_window = min(100, len(words))\n",
        "    last_words = words[-check_window:]\n",
        "\n",
        "    # Detect if last word repeats excessively\n",
        "    if len(last_words) > max_repetitions:\n",
        "        last_word = last_words[-1]\n",
        "\n",
        "        # Count consecutive repetitions from the end\n",
        "        repetition_count = 0\n",
        "        for word in reversed(last_words):\n",
        "            if word.lower() == last_word.lower():\n",
        "                repetition_count += 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # If repetition exceeds threshold, remove them\n",
        "        if repetition_count > max_repetitions:\n",
        "            # Keep only max_repetitions of the repeated word\n",
        "            words = words[:-repetition_count] + [last_word] * max_repetitions\n",
        "            print(f'   üßπ Cleaned {repetition_count - max_repetitions} repetitive words')\n",
        "\n",
        "    # Remove common hallucination patterns\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    # Pattern: word repeated 5+ times in a row\n",
        "    cleaned_text = re.sub(r'\\b(\\w+)(?:\\s+\\1){4,}\\b', r'\\1', cleaned_text)\n",
        "\n",
        "    return cleaned_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "dd4wVEyHUPYy",
      "metadata": {
        "id": "dd4wVEyHUPYy"
      },
      "outputs": [],
      "source": [
        "def transcribe_video(video_path, language=\"en\"):\n",
        "    \"\"\"Transcribe video using faster-whisper with MAXIMUM ACCURACY settings and weighted confidence\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(video_path):\n",
        "            raise Exception(f\"Video file not found: {video_path}\")\n",
        "\n",
        "        if not os.access(video_path, os.R_OK):\n",
        "            raise Exception(f\"Video file is not readable: {video_path}\")\n",
        "\n",
        "        file_size = os.path.getsize(video_path) / (1024 * 1024)\n",
        "        print(f'üìÅ Video: {os.path.basename(video_path)} ({file_size:.2f} MB)')\n",
        "\n",
        "        # ‚úÖ LANGUAGE SELECTION\n",
        "        if language == \"id\":\n",
        "            whisper_language = \"id\"\n",
        "            initial_prompt = \"This is a professional interview in Indonesian (Bahasa Indonesia).\"\n",
        "            print('üåê Language: Indonesian (Bahasa Indonesia)')\n",
        "        elif language == \"en\":\n",
        "            whisper_language = \"en\"\n",
        "            initial_prompt = \"This is a professional interview in English.\"\n",
        "            print('üåê Language: English')\n",
        "        else:\n",
        "            # Default to English if unknown\n",
        "            whisper_language = \"en\"\n",
        "            initial_prompt = \"This is a professional interview in English.\"\n",
        "            print(f'‚ö†Ô∏è Unknown language code \"{language}\", defaulting to English')\n",
        "\n",
        "        print('üîÑ Starting transcription...')\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Dynamic parameters based on file size\n",
        "        if file_size > 30:\n",
        "            print('   ‚ö° Large file - using balanced mode')\n",
        "            beam_size = 7\n",
        "            best_of = 7\n",
        "        else:\n",
        "            beam_size = 10\n",
        "            best_of = 10\n",
        "\n",
        "        # ‚úÖ Optimized VAD parameters\n",
        "        vad_params = {\n",
        "            \"threshold\": 0.3,\n",
        "            \"min_speech_duration_ms\": 200,\n",
        "            \"max_speech_duration_s\": float('inf'),\n",
        "            \"min_silence_duration_ms\": 1500,\n",
        "            \"speech_pad_ms\": 500\n",
        "        }\n",
        "\n",
        "        # ‚úÖ Transcribe with language parameter\n",
        "        segments, info = whisper_model.transcribe(\n",
        "            video_path,\n",
        "            language=whisper_language,  # ‚úÖ DYNAMIC LANGUAGE\n",
        "            task=\"transcribe\",\n",
        "            beam_size=beam_size,\n",
        "            best_of=best_of,\n",
        "            patience=2.5,\n",
        "            length_penalty=0.8,\n",
        "            repetition_penalty=1.5,\n",
        "            temperature=0.0,\n",
        "            compression_ratio_threshold=2.2,\n",
        "            log_prob_threshold=-0.8,\n",
        "            no_speech_threshold=0.5,\n",
        "            condition_on_previous_text=True,\n",
        "            initial_prompt=initial_prompt,  # ‚úÖ DYNAMIC PROMPT\n",
        "            word_timestamps=True,\n",
        "            vad_filter=True,\n",
        "            vad_parameters=vad_params\n",
        "        )\n",
        "\n",
        "        # Collect segments with confidence scores\n",
        "        print('   üìù Collecting segments...')\n",
        "        transcription_text = \"\"\n",
        "        segments_list = list(segments)\n",
        "\n",
        "        confidence_scores = []\n",
        "        segment_details = []\n",
        "\n",
        "        for segment in tqdm(segments_list, desc=\"   Segments\", unit=\"seg\", ncols=80, leave=False):\n",
        "            transcription_text += segment.text + \" \"\n",
        "\n",
        "            # Calculate confidence from log probability\n",
        "            confidence = segment.avg_logprob\n",
        "            # ‚úÖ FORMULA: konversi log prob (-inf to 0) ke percentage (0-100)\n",
        "            # Transform log_prob dengan sigmoid untuk distribusi lebih baik\n",
        "            def logprob_to_confidence(log_prob):\n",
        "                # Normalize log_prob (biasanya -5 sampai 0)\n",
        "                normalized = (log_prob + 5) / 5  # Scale ke 0-1\n",
        "                # Apply sigmoid untuk smooth curve\n",
        "                sigmoid = 1 / (1 + np.exp(-10 * (normalized - 0.5)))\n",
        "                return round(sigmoid * 100, 2)\n",
        "\n",
        "            confidence_percent = logprob_to_confidence(confidence)\n",
        "            confidence_scores.append(confidence_percent)\n",
        "\n",
        "            segment_details.append({\n",
        "                \"text\": segment.text.strip(),\n",
        "                \"start\": round(segment.start, 2),\n",
        "                \"end\": round(segment.end, 2),\n",
        "                \"duration\": round(segment.end - segment.start, 2),\n",
        "                \"confidence\": confidence_percent\n",
        "            })\n",
        "\n",
        "        transcription_text = transcription_text.strip()\n",
        "\n",
        "        if not transcription_text:\n",
        "            print('   ‚ö†Ô∏è  No speech detected')\n",
        "            return \"[No speech detected in video]\", 0.0\n",
        "\n",
        "        if confidence_scores:\n",
        "            # 1. Calculate weighted confidence by segment duration\n",
        "            segment_durations = [seg.end - seg.start for seg in segments_list]\n",
        "            total_duration = sum(segment_durations)\n",
        "\n",
        "            weighted_confidence = sum(\n",
        "                conf * (duration / total_duration)\n",
        "                for conf, duration in zip(confidence_scores, segment_durations)\n",
        "            )\n",
        "\n",
        "            # 2. Quality-based boost\n",
        "            word_count = len(transcription_text.split())\n",
        "            min_conf = min(confidence_scores)\n",
        "            max_conf = max(confidence_scores)\n",
        "            conf_variance = max_conf - min_conf\n",
        "\n",
        "            avg_confidence = round(sum(confidence_scores) / len(confidence_scores), 2)\n",
        "\n",
        "        # Clean repetitive text\n",
        "        original_length = len(transcription_text)\n",
        "        transcription_text = clean_repetitive_text(transcription_text, max_repetitions=3)\n",
        "\n",
        "        if len(transcription_text) < original_length:\n",
        "            print(f'   üßπ Cleaned: {original_length} ‚Üí {len(transcription_text)} chars')\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        words = transcription_text.split()\n",
        "\n",
        "        # Display results\n",
        "        print(f'   ‚úÖ Completed in {total_time:.1f}s | {len(segments_list)} segments | {len(words)} words')\n",
        "        print(f'   üéØ Transcription Confidence: {avg_confidence}% {\"‚úÖ\" if avg_confidence >= 70 else \"‚ö†Ô∏è\" if avg_confidence >= 50 else \"‚ùå\"}')\n",
        "\n",
        "        if confidence_scores:\n",
        "            min_conf = min(confidence_scores)\n",
        "            max_conf = max(confidence_scores)\n",
        "            print(f'   üìä Confidence Range: {min_conf}% - {max_conf}%')\n",
        "\n",
        "        # Cleanup\n",
        "        gc.collect()\n",
        "\n",
        "        return transcription_text, avg_confidence, min_conf, max_conf\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'   ‚ùå Error: {str(e)}')\n",
        "        gc.collect()\n",
        "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
        "    finally:\n",
        "        # Always cleanup\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CeRNTro8KcBf",
      "metadata": {
        "id": "CeRNTro8KcBf"
      },
      "source": [
        "<b><h2> Fungsi Translate to Indonesia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "BFNzaF6FUUVM",
      "metadata": {
        "id": "BFNzaF6FUUVM"
      },
      "outputs": [],
      "source": [
        "def translate_to_indonesian(text):\n",
        "    \"\"\"Translate English text to Indonesian using DeepL\"\"\"\n",
        "    if not translator:\n",
        "        print('   ‚ö†Ô∏è  Translation skipped (no API key)')\n",
        "        return {\n",
        "            \"translated_text\": \"[Translation not available]\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        max_chunk_size = 5000\n",
        "\n",
        "        if len(text) <= max_chunk_size:\n",
        "            result = translator.translate_text(text, source_lang=\"EN\", target_lang=\"ID\")\n",
        "            translated_text = result.text\n",
        "        else:\n",
        "            sentences = text.split('. ')\n",
        "            chunks = []\n",
        "            current_chunk = \"\"\n",
        "\n",
        "            for sentence in sentences:\n",
        "                if len(current_chunk) + len(sentence) + 2 <= max_chunk_size:\n",
        "                    current_chunk += sentence + \". \"\n",
        "                else:\n",
        "                    if current_chunk:\n",
        "                        chunks.append(current_chunk)\n",
        "                    current_chunk = sentence + \". \"\n",
        "\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk)\n",
        "\n",
        "            translated_chunks = []\n",
        "            for chunk in chunks:\n",
        "                result = translator.translate_text(chunk, source_lang=\"EN\", target_lang=\"ID\")\n",
        "                translated_chunks.append(result.text)\n",
        "\n",
        "            translated_text = \" \".join(translated_chunks)\n",
        "\n",
        "        print(f'   ‚úÖ Translation: {len(text)} ‚Üí {len(translated_text)} chars')\n",
        "\n",
        "        return {\n",
        "            \"translated_text\": translated_text\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'   ‚ùå Translation failed: {str(e)}')\n",
        "        return {\n",
        "            \"translated_text\": f\"[Translation failed: {str(e)}]\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "21bb7087",
      "metadata": {
        "id": "21bb7087"
      },
      "outputs": [],
      "source": [
        "def translate_to_english(text):\n",
        "    \"\"\"Translate Indonesian text to English using DeepL\"\"\"\n",
        "    if not translator:\n",
        "        print('   ‚ö†Ô∏è  Translation skipped (no API key)')\n",
        "        return {\n",
        "            \"translated_text\": \"[Translation not available]\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        max_chunk_size = 5000\n",
        "\n",
        "        if len(text) <= max_chunk_size:\n",
        "            result = translator.translate_text(text, source_lang=\"ID\", target_lang=\"EN-US\")\n",
        "            translated_text = result.text\n",
        "        else:\n",
        "            # Split by sentences for Indonesian\n",
        "            sentences = text.split('. ')\n",
        "            chunks = []\n",
        "            current_chunk = \"\"\n",
        "\n",
        "            for sentence in sentences:\n",
        "                if len(current_chunk) + len(sentence) + 2 <= max_chunk_size:\n",
        "                    current_chunk += sentence + \". \"\n",
        "                else:\n",
        "                    if current_chunk:\n",
        "                        chunks.append(current_chunk)\n",
        "                    current_chunk = sentence + \". \"\n",
        "\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk)\n",
        "\n",
        "            translated_chunks = []\n",
        "            for chunk in chunks:\n",
        "                result = translator.translate_text(chunk, source_lang=\"ID\", target_lang=\"EN-US\")\n",
        "                translated_chunks.append(result.text)\n",
        "\n",
        "            translated_text = \" \".join(translated_chunks)\n",
        "\n",
        "        print(f'   ‚úÖ Translation: {len(text)} ‚Üí {len(translated_text)} chars')\n",
        "\n",
        "        return {\n",
        "            \"translated_text\": translated_text\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'   ‚ùå Translation failed: {str(e)}')\n",
        "        return {\n",
        "            \"translated_text\": f\"[Translation failed: {str(e)}]\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aUwU-2YTKlkS",
      "metadata": {
        "id": "aUwU-2YTKlkS"
      },
      "source": [
        "<b><h2> LLM Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N38Dkix6w4p3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N38Dkix6w4p3",
        "outputId": "b7b60a5c-8e83-4b08-f901-e082a65c75ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Initializing HuggingFace Inference API...\n",
            "‚ÑπÔ∏è  Using meta-llama/Llama-3.1-8B-Instruct via Inference API\n",
            "‚úÖ Inference API initialized successfully\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ HuggingFace API Token\n",
        "# HF_TOKEN = \"token_goes_here\"\n",
        "# os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "\n",
        "# Initialize Inference Client\n",
        "print('üì• Initializing HuggingFace Inference API...')\n",
        "print('‚ÑπÔ∏è  Using meta-llama/Llama-3.1-8B-Instruct via Inference API')\n",
        "\n",
        "client = InferenceClient(api_key=HF_TOKEN)\n",
        "\n",
        "print('‚úÖ Inference API initialized successfully\\n')\n",
        "\n",
        "def evaluate_with_llm(transcription_text: str, question: str, position_id: int):\n",
        "    \"\"\"\n",
        "    Evaluate interview answer using deterministic LLM evaluation with confidence scoring.\n",
        "    NOW WITH LOG PROBABILITIES SUPPORT + BOOST SYSTEM for confidence enhancement.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct evaluation prompt\n",
        "        user_message = f\"\"\"You are an expert interview evaluator about programming and machine learning. You must provide objective, consistent scores based on explicit criteria and formulas.\n",
        "\n",
        "**INTERVIEW QUESTION**: \"{question}\"\n",
        "\n",
        "**CANDIDATE'S ANSWER**: \"{transcription_text}\"\n",
        "\n",
        "**EVALUATION RUBRIC WITH FORMULAS**:\n",
        "\n",
        "1. **KUALITAS JAWABAN (Quality of Answer)** [1-100]:\n",
        "\n",
        "   Base Score Formula:\n",
        "   - If answer addresses question with examples/details: BASE = 85\n",
        "   - If answer addresses question adequately: BASE = 75\n",
        "   - If answer is brief but relevant: BASE = 65\n",
        "   - If answer is unclear/irrelevant: BASE = 45\n",
        "\n",
        "   Adjustments:\n",
        "   - Provides specific examples: +5 to +15\n",
        "   - Shows deep understanding: +5 to +10\n",
        "   - Lacks depth: -10 to -20\n",
        "   - Vague/incomplete: -15 to -25\n",
        "\n",
        "   MINIMUM for acceptable answers: 70\n",
        "\n",
        "2. **KOHERENSI (Coherence)** [1-100]:\n",
        "\n",
        "   Formula:\n",
        "   - Logical flow, well-structured: BASE = 85\n",
        "   - Adequate structure: BASE = 75\n",
        "   - Some inconsistency: BASE = 65\n",
        "   - Disorganized: BASE = 45\n",
        "\n",
        "   Adjustments:\n",
        "   - Clear progression: +5 to +10\n",
        "   - Smooth transitions: +5 to +10\n",
        "   - Contradictory statements: -15 to -25\n",
        "   - Jumps between topics: -10 to -20\n",
        "\n",
        "   MINIMUM for coherent answers: 70\n",
        "\n",
        "3. **RELEVANSI (Relevance)** [1-100]:\n",
        "\n",
        "   Formula:\n",
        "   - Directly answers the question: BASE = 85\n",
        "   - Addresses most aspects: BASE = 75\n",
        "   - Partially relevant: BASE = 65\n",
        "   - Off-topic: BASE = 45\n",
        "\n",
        "   Adjustments:\n",
        "   - Covers all question aspects: +10 to +20\n",
        "   - Provides context: +5 to +10\n",
        "   - Deviates from topic: -15 to -25\n",
        "\n",
        "   MINIMUM for on-topic answers: 70\n",
        "\n",
        "**CALCULATION STEPS**:\n",
        "1. Analyze the answer content and structure\n",
        "2. Calculate base scores using formulas\n",
        "3. Apply adjustments\n",
        "\n",
        "**OUTPUT FORMAT** (JSON only, no explanation):\n",
        "{{\n",
        "  \"kualitas_jawaban\": <integer 1-100>,\n",
        "  \"koherensi\": <integer 1-100>,\n",
        "  \"relevansi\": <integer 1-100>,\n",
        "  \"analysis\": \"<2-3 sentence justification with reasoning>\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "        # Calculate word count for boost system\n",
        "        word_count = len(transcription_text.split())\n",
        "\n",
        "        print(f'‚îÇ ü§ñ LLM Evaluation...')\n",
        "        print(f'‚îÇ üìù Answer length: {len(transcription_text)} chars ({word_count} words)')\n",
        "\n",
        "        # ‚úÖ API Call with logprobs enabled\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a highly objective interview evaluator about programming and machine learning. Always respond with valid JSON only, no markdown.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": user_message\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=600,\n",
        "            temperature=0.1,\n",
        "            top_p=0.9,\n",
        "            logprobs=True,        # ‚úÖ ENABLE LOG PROBABILITIES\n",
        "            top_logprobs=3        # ‚úÖ Get top 3 alternative tokens for each position\n",
        "        )\n",
        "\n",
        "        # Extract response text\n",
        "        response = completion.choices[0].message.content.strip()\n",
        "        response = re.sub(r'^```json\\s*', '', response)\n",
        "        response = re.sub(r'\\s*```$', '', response)\n",
        "\n",
        "        print(f'‚îÇ üì® API Response received ({len(response)} chars)')\n",
        "\n",
        "        # ============================================================\n",
        "        # ‚úÖ EXTRACT LOGPROBS DATA (NEW!)\n",
        "        # ============================================================\n",
        "        logprobs_data = None\n",
        "        raw_token_confidence = None\n",
        "        raw_avg_probability = None\n",
        "\n",
        "        try:\n",
        "            if hasattr(completion.choices[0], 'logprobs') and completion.choices[0].logprobs:\n",
        "                logprobs_obj = completion.choices[0].logprobs\n",
        "\n",
        "                # Check if content exists\n",
        "                if hasattr(logprobs_obj, 'content') and logprobs_obj.content:\n",
        "                    logprobs_data = logprobs_obj.content\n",
        "\n",
        "                    # Calculate average log probability\n",
        "                    token_logprobs = [token.logprob for token in logprobs_data if hasattr(token, 'logprob')]\n",
        "\n",
        "                    if token_logprobs:\n",
        "                        avg_logprob = sum(token_logprobs) / len(token_logprobs)\n",
        "                        # Convert log probability to percentage confidence\n",
        "                        raw_avg_probability = math.exp(avg_logprob)\n",
        "                        raw_token_confidence = round(raw_avg_probability * 100, 2)\n",
        "\n",
        "                        print(f'‚îÇ üéØ Raw Logprobs extracted: {len(token_logprobs)} tokens')\n",
        "                        print(f'‚îÇ üìä Avg log prob: {avg_logprob:.4f}')\n",
        "                        print(f'‚îÇ ‚ú® Raw token confidence: {raw_token_confidence}%')\n",
        "                    else:\n",
        "                        print(f'‚îÇ ‚ö†Ô∏è  Logprobs available but no token data')\n",
        "                else:\n",
        "                    print(f'‚îÇ ‚ö†Ô∏è  Logprobs object has no content')\n",
        "            else:\n",
        "                print(f'‚îÇ ‚ö†Ô∏è  No logprobs in API response (may not be supported)')\n",
        "        except Exception as logprob_error:\n",
        "            print(f'‚îÇ ‚ö†Ô∏è  Logprobs extraction failed: {str(logprob_error)}')\n",
        "            # Continue without logprobs - non-critical feature\n",
        "\n",
        "        # Extract JSON from response\n",
        "        json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response, re.DOTALL)\n",
        "        if json_match:\n",
        "            json_str = json_match.group(0)\n",
        "            evaluation = json_module.loads(json_str)\n",
        "        else:\n",
        "            raise ValueError(\"No valid JSON found in API response\")\n",
        "\n",
        "        # Validate scores\n",
        "        required_keys = ['kualitas_jawaban', 'koherensi', 'relevansi']\n",
        "        for key in required_keys:\n",
        "            if key not in evaluation:\n",
        "                raise ValueError(f\"Missing required key: {key}\")\n",
        "            evaluation[key] = max(1, min(100, int(evaluation[key])))\n",
        "\n",
        "        # ============================================================\n",
        "        # DISPLAY RESULTS\n",
        "        # ============================================================\n",
        "        print(f'‚îÇ üìä LLM Scores:')\n",
        "        print(f'‚îÇ    ‚Ä¢ Quality: {evaluation[\"kualitas_jawaban\"]}/100')\n",
        "        print(f'‚îÇ    ‚Ä¢ Coherence: {evaluation[\"koherensi\"]}/100')\n",
        "        print(f'‚îÇ    ‚Ä¢ Relevance: {evaluation[\"relevansi\"]}/100')\n",
        "\n",
        "        # Calculate total score (using boosted model confidence)\n",
        "        total = round((\n",
        "            evaluation[\"kualitas_jawaban\"] +\n",
        "            evaluation[\"koherensi\"] +\n",
        "            evaluation[\"relevansi\"]\n",
        "        ) / 3)\n",
        "\n",
        "        print(f'‚îÇ ‚úÖ Total Score: {total}/100')\n",
        "\n",
        "        # ‚úÖ Return with logprobs data and boost info\n",
        "        result = {\n",
        "            \"scores\": {\n",
        "                \"kualitas_jawaban\": evaluation[\"kualitas_jawaban\"],\n",
        "                \"koherensi\": evaluation[\"koherensi\"],\n",
        "                \"relevansi\": evaluation[\"relevansi\"],\n",
        "                \"confidence_score\": raw_token_confidence\n",
        "            },\n",
        "            \"total\": total,\n",
        "            \"analysis\": evaluation.get('analysis', 'No analysis provided'),\n",
        "            # üÜï Logprobs data\n",
        "            \"logprobs_confidence\": raw_token_confidence,\n",
        "            \"logprobs_probability\": raw_avg_probability,\n",
        "            \"logprobs_available\": logprobs_data is not None,\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'‚îÇ ‚ö†Ô∏è  LLM evaluation failed: {str(e)}')\n",
        "        print(f'‚îÇ üîÑ Falling back to rule-based assessment...')\n",
        "\n",
        "        # Fallback assessment\n",
        "        word_count = len(transcription_text.split())\n",
        "\n",
        "        # Simple heuristic scoring\n",
        "        if word_count > 100:\n",
        "            quality_score = 75\n",
        "            coherence_score = 70\n",
        "            relevance_score = 70\n",
        "            model_confidence = 60\n",
        "        elif word_count > 50:\n",
        "            quality_score = 65\n",
        "            coherence_score = 65\n",
        "            relevance_score = 65\n",
        "            model_confidence = 55\n",
        "        elif word_count > 20:\n",
        "            quality_score = 55\n",
        "            coherence_score = 55\n",
        "            relevance_score = 55\n",
        "            model_confidence = 50\n",
        "        else:\n",
        "            quality_score = 40\n",
        "            coherence_score = 35\n",
        "            relevance_score = 35\n",
        "            model_confidence = 50\n",
        "\n",
        "        total = round((quality_score + coherence_score + relevance_score) / 3)\n",
        "\n",
        "        return {\n",
        "            \"scores\": {\n",
        "                \"kualitas_jawaban\": quality_score,\n",
        "                \"koherensi\": coherence_score,\n",
        "                \"relevansi\": relevance_score,\n",
        "                \"confidence_score\": model_confidence\n",
        "            },\n",
        "            \"total\": total,\n",
        "            \"analysis\": f\"Fallback rule-based assessment (word count: {word_count}). LLM evaluation unavailable: {str(e)}\",\n",
        "            # Fallback has no logprobs or boost\n",
        "            \"logprobs_confidence\": None,\n",
        "            \"logprobs_probability\": None,\n",
        "            \"logprobs_available\": False,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45eb7184",
      "metadata": {
        "id": "45eb7184"
      },
      "outputs": [],
      "source": [
        "def summarize_llm_analysis_batch(assessment_results):\n",
        "    \"\"\"\n",
        "    Generate overall summary from all assessments\n",
        "\n",
        "    ‚úÖ OPTIMIZED: If only 1 video, reuse existing analysis_llm instead of calling LLM again\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not assessment_results:\n",
        "            return {\n",
        "                \"kesimpulan_llm\": \"Tidak ada hasil penilaian yang tersedia.\",\n",
        "                \"rata_rata_confidence_score\": 0,\n",
        "                \"avg_total_llm\": 0,\n",
        "                \"avg_logprobs_confidence\": None,\n",
        "                \"final_score_llm\": 0\n",
        "            }\n",
        "\n",
        "        # Calculate averages\n",
        "        confidence_scores = []\n",
        "        total_scores = []\n",
        "        logprobs_confidences = []\n",
        "\n",
        "        for result in assessment_results:\n",
        "            assessment = result.get('result', {}).get('penilaian', {})\n",
        "            confidence_scores.append(assessment.get('confidence_score', 0))\n",
        "            total_scores.append(assessment.get('total', 0))\n",
        "\n",
        "            # Extract logprobs confidence if available\n",
        "            lp_conf = assessment.get('logprobs_confidence')\n",
        "            if lp_conf is not None:\n",
        "                logprobs_confidences.append(lp_conf)\n",
        "\n",
        "        avg_confidence = round(sum(confidence_scores) / len(confidence_scores)) if confidence_scores else 0\n",
        "        avg_total = round(sum(total_scores) / len(total_scores)) if total_scores else 0\n",
        "\n",
        "        # Calculate average logprobs confidence\n",
        "        avg_logprobs_confidence = None\n",
        "        if logprobs_confidences:\n",
        "            avg_logprobs_confidence = round(sum(logprobs_confidences) / len(logprobs_confidences), 2)\n",
        "\n",
        "        # Determine final score\n",
        "        projectScore = 100\n",
        "        final_score = projectScore * 0.7 + avg_total * 0.3\n",
        "\n",
        "        # ‚úÖ NEW: If only 1 video, reuse existing analysis instead of calling LLM\n",
        "        if len(assessment_results) == 1:\n",
        "            print(f'\\n{\"=\"*70}')\n",
        "            print(f'üìã Single Video Assessment - Reusing Existing Analysis')\n",
        "            print(f'{\"=\"*70}')\n",
        "            print(f'‚ÑπÔ∏è  Only 1 video detected - skipping LLM summary generation')\n",
        "            print(f'‚úÖ Using existing analysis_llm from video assessment')\n",
        "\n",
        "            # Get existing analysis from the single video\n",
        "            single_assessment = assessment_results[0].get('result', {}).get('penilaian', {})\n",
        "            existing_analysis = single_assessment.get('analisis_llm', '')\n",
        "\n",
        "            # Format as summary\n",
        "            if existing_analysis:\n",
        "                kesimpulan_llm = f\"Assessment Summary: {existing_analysis}\"\n",
        "            else:\n",
        "                # Fallback if no analysis\n",
        "                quality = single_assessment.get('kualitas_jawaban', 0)\n",
        "                coherence = single_assessment.get('koherensi', 0)\n",
        "                relevance = single_assessment.get('relevansi', 0)\n",
        "                total = single_assessment.get('total', 0)\n",
        "\n",
        "                kesimpulan_llm = (\n",
        "                    f\"Candidate demonstrated performance with total score of {total}/100. \"\n",
        "                    f\"Quality: {quality}/100, Coherence: {coherence}/100, Relevance: {relevance}/100.\"\n",
        "                )\n",
        "\n",
        "            print(f'   üìä Score: {avg_total}/100')\n",
        "            print(f'   ‚ú® Analysis reused successfully')\n",
        "            print(f'{\"=\"*70}\\n')\n",
        "\n",
        "            return {\n",
        "                \"kesimpulan_llm\": kesimpulan_llm,\n",
        "                \"rata_rata_confidence_score\": avg_confidence,\n",
        "                \"avg_total_llm\": avg_total,\n",
        "                \"final_score_llm\": final_score,\n",
        "                \"avg_logprobs_confidence\": avg_logprobs_confidence,\n",
        "                \"reused_single_analysis\": True  # ‚úÖ Flag untuk tracking\n",
        "            }\n",
        "\n",
        "        # ‚úÖ Multiple videos: Generate comprehensive LLM summary\n",
        "        print(f'\\n{\"=\"*70}')\n",
        "        print(f'ü§ñ Generating Batch LLM Summary...')\n",
        "        print(f'{\"=\"*70}')\n",
        "        print(f'üìä Processing {len(assessment_results)} video assessments')\n",
        "        print(f'üìà Average Score: {avg_total}/100')\n",
        "        if avg_logprobs_confidence is not None:\n",
        "            print(f'‚ú® Avg Logprobs Confidence: {avg_logprobs_confidence}%')\n",
        "\n",
        "        # Prepare assessment summary for multiple videos\n",
        "        summary_lines = []\n",
        "        for idx, result in enumerate(assessment_results, 1):\n",
        "            assessment = result.get('result', {}).get('penilaian', {})\n",
        "            question = result.get('question', f'Question {idx}')\n",
        "\n",
        "            summary_lines.append(\n",
        "                f\"Video {idx}: Total {assessment.get('total', 0)}/100 \"\n",
        "                f\"(Quality: {assessment.get('kualitas_jawaban', 0)}, \"\n",
        "                f\"Coherence: {assessment.get('koherensi', 0)}, \"\n",
        "                f\"Relevance: {assessment.get('relevansi', 0)})\"\n",
        "            )\n",
        "\n",
        "        assessment_summary = \"\\n\".join(summary_lines)\n",
        "\n",
        "        # Detect language from first result\n",
        "        source_language = assessment_results[0].get('result', {}).get('metadata', {}).get('source_language', 'English')\n",
        "\n",
        "        # Generate LLM summary prompt\n",
        "        user_message = f\"\"\"Based on the following interview assessment results, provide a comprehensive summary in {source_language} (2-3 paragraphs, ~150-200 words).\n",
        "\n",
        "**ASSESSMENT RESULTS**:\n",
        "{assessment_summary}\n",
        "\n",
        "**AVERAGES**:\n",
        "- Average Total Score: {avg_total}/100\n",
        "\n",
        "**INSTRUCTIONS**:\n",
        "1. Summarize the candidate's overall performance across all {len(assessment_results)} video interviews\n",
        "2. Highlight consistent strengths and areas for improvement\n",
        "3. Be objective, constructive, and professional\n",
        "4. Consider both technical competence and communication skills\n",
        "\n",
        "Respond with plain text summary only (no JSON, no markdown formatting).\"\"\"\n",
        "\n",
        "        print(f'ü§ñ Calling LLM to generate comprehensive summary...')\n",
        "\n",
        "        # API Call with logprobs\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert interview analyst. Provide comprehensive, objective assessments. Respond with plain text only, no JSON or markdown.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": user_message\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=500,\n",
        "            temperature=0.3,\n",
        "            top_p=0.9,\n",
        "            logprobs=True,\n",
        "            top_logprobs=3\n",
        "        )\n",
        "\n",
        "        # Extract summary\n",
        "        kesimpulan_llm = completion.choices[0].message.content.strip()\n",
        "        kesimpulan_llm = re.sub(r'^```.*?\\n', '', kesimpulan_llm)\n",
        "        kesimpulan_llm = re.sub(r'\\n```$', '', kesimpulan_llm)\n",
        "\n",
        "        # Extract summary logprobs\n",
        "        summary_logprobs_confidence = None\n",
        "        try:\n",
        "            if hasattr(completion.choices[0], 'logprobs') and completion.choices[0].logprobs:\n",
        "                logprobs_obj = completion.choices[0].logprobs\n",
        "                if hasattr(logprobs_obj, 'content') and logprobs_obj.content:\n",
        "                    token_logprobs = [token.logprob for token in logprobs_obj.content if hasattr(token, 'logprob')]\n",
        "                    if token_logprobs:\n",
        "                        avg_logprob = sum(token_logprobs) / len(token_logprobs)\n",
        "                        summary_logprobs_confidence = round(math.exp(avg_logprob) * 100, 2)\n",
        "                        print(f'‚ú® Summary logprobs confidence: {summary_logprobs_confidence}%')\n",
        "        except Exception as e:\n",
        "            print(f'‚ö†Ô∏è  Summary logprobs extraction failed: {str(e)}')\n",
        "\n",
        "        print(f'‚úÖ LLM Summary generated successfully')\n",
        "        print(f'   Length: {len(kesimpulan_llm)} characters')\n",
        "        print(f'   Words: {len(kesimpulan_llm.split())}')\n",
        "        print(f'{\"=\"*70}\\n')\n",
        "\n",
        "        return {\n",
        "            \"kesimpulan_llm\": kesimpulan_llm,\n",
        "            \"rata_rata_confidence_score\": avg_confidence,\n",
        "            \"avg_total_llm\": avg_total,\n",
        "            \"final_score_llm\": final_score,\n",
        "            \"avg_logprobs_confidence\": avg_logprobs_confidence,\n",
        "            \"summary_logprobs_confidence\": summary_logprobs_confidence,  # ‚úÖ Separate summary confidence\n",
        "            \"reused_single_analysis\": False  # ‚úÖ Flag untuk tracking\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå LLM summary generation failed: {str(e)}')\n",
        "        print(f'üîÑ Using fallback summary...')\n",
        "\n",
        "        # Fallback summary\n",
        "        return {\n",
        "            \"kesimpulan_llm\": f\"Kandidat menunjukkan performa dengan rata-rata skor {avg_total}/100 dari {len(assessment_results)} video interview. \"\n",
        "                             f\"(LLM summary unavailable: {str(e)[:100]})\",\n",
        "            \"rata_rata_confidence_score\": avg_confidence,\n",
        "            \"avg_total_llm\": avg_total,\n",
        "            \"final_score_llm\": final_score,\n",
        "            \"avg_logprobs_confidence\": avg_logprobs_confidence,\n",
        "            \"summary_logprobs_confidence\": None,\n",
        "            \"reused_single_analysis\": False\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa93fb2a",
      "metadata": {
        "id": "fa93fb2a"
      },
      "source": [
        "<b><h2> Google Drive Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "8868ec48",
      "metadata": {
        "id": "8868ec48"
      },
      "outputs": [],
      "source": [
        "# ===== HELPER: Download video from Google Drive =====\n",
        "import gdown\n",
        "import requests\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "def download_video_from_google_drive(video_url, dest_folder):\n",
        "    \"\"\"Download video from Google Drive URL\"\"\"\n",
        "    try:\n",
        "        # Extract file ID from Google Drive URL\n",
        "        if 'drive.google.com' in video_url:\n",
        "            # Format 1: https://drive.google.com/file/d/FILE_ID/view?usp=...\n",
        "            if '/file/d/' in video_url:\n",
        "                file_id = video_url.split('/file/d/')[1].split('/')[0]\n",
        "            # Format 2: https://drive.google.com/open?id=FILE_ID\n",
        "            elif 'id=' in video_url:\n",
        "                parsed = urlparse(video_url)\n",
        "                file_id = parse_qs(parsed.query)['id'][0]\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported Google Drive URL format\")\n",
        "\n",
        "            # Generate download URL\n",
        "            download_url = f\"https://drive.google.com/uc?id={file_id}&export=download\"\n",
        "\n",
        "            # Generate safe filename\n",
        "            safe_name = f\"{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}.mp4\"\n",
        "            dest_path = os.path.join(dest_folder, safe_name)\n",
        "\n",
        "            print(f\"      üì• Downloading from Google Drive (ID: {file_id[:20]}...)\")\n",
        "\n",
        "            # Download with gdown\n",
        "            gdown.download(download_url, dest_path, quiet=False)\n",
        "\n",
        "            # Verify file exists and has content\n",
        "            if not os.path.exists(dest_path) or os.path.getsize(dest_path) == 0:\n",
        "                raise ValueError(\"Downloaded file is empty or doesn't exist\")\n",
        "\n",
        "            file_size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
        "            print(f\"      ‚úÖ Downloaded: {safe_name} ({file_size_mb:.2f} MB)\")\n",
        "\n",
        "            return safe_name, dest_path\n",
        "\n",
        "        else:\n",
        "            # Direct URL download (fallback)\n",
        "            safe_name = f\"{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}.mp4\"\n",
        "            dest_path = os.path.join(dest_folder, safe_name)\n",
        "\n",
        "            print(f\"      üì• Downloading from direct URL\")\n",
        "            response = requests.get(video_url, stream=True, timeout=300)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            with open(dest_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "\n",
        "            file_size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
        "            print(f\"      ‚úÖ Downloaded: {safe_name} ({file_size_mb:.2f} MB)\")\n",
        "\n",
        "            return safe_name, dest_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ùå Download failed: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "a408e436",
      "metadata": {
        "id": "a408e436"
      },
      "outputs": [],
      "source": [
        "# ===== BACKGROUND THREAD: Download and Process Videos =====\n",
        "def download_and_process_videos(session_id, candidate_name, interviews, language, base_url):\n",
        "    \"\"\"\n",
        "    Background thread: Download videos from Google Drive URLs, then process identically to /upload endpoint.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîΩ [Thread-{session_id[:8]}] Starting video downloads...\")\n",
        "\n",
        "    try:\n",
        "        uploaded_videos = []\n",
        "\n",
        "        # PHASE 1: Download all videos\n",
        "        print(f'\\nüì• Downloading {len(interviews)} video(s) from Google Drive...')\n",
        "        for idx, interview in enumerate(interviews, 1):\n",
        "            try:\n",
        "                # Update download progress\n",
        "                with processing_lock:\n",
        "                    processing_status[session_id]['message'] = f'Downloading video {idx}/{len(interviews)}...'\n",
        "                    processing_status[session_id]['progress'] = f'{idx}/{len(interviews)}'\n",
        "\n",
        "                # Extract fields from interview\n",
        "                position_id = interview.get('positionId', idx)\n",
        "                question = interview.get('question', '')\n",
        "                is_video_exist = interview.get('isVideoExist', False)\n",
        "                video_url = interview.get('recordedVideoUrl', '')\n",
        "\n",
        "                print(f'\\n   üìπ Video {idx}/{len(interviews)}:')\n",
        "                print(f'      Position ID: {position_id}')\n",
        "                print(f'      Question: {question[:60]}{\"...\" if len(question) > 60 else \"\"}')\n",
        "                print(f'      Video exists: {is_video_exist}')\n",
        "                print(f'      URL: {video_url[:80]}{\"...\" if len(video_url) > 80 else \"\"}')\n",
        "\n",
        "                # Validate\n",
        "                if not question:\n",
        "                    print(f'      ‚ö†Ô∏è Missing question, skipping')\n",
        "                    uploaded_videos.append({\n",
        "                        'positionId': position_id,\n",
        "                        'question': '',\n",
        "                        'isVideoExist': False,\n",
        "                        'recordedVideoUrl': None,\n",
        "                        'error': 'Missing question field'\n",
        "                    })\n",
        "                    continue\n",
        "\n",
        "                if not is_video_exist or not video_url:\n",
        "                    print(f'      ‚ö†Ô∏è No video URL, skipping')\n",
        "                    uploaded_videos.append({\n",
        "                        'positionId': position_id,\n",
        "                        'question': question,\n",
        "                        'isVideoExist': False,\n",
        "                        'recordedVideoUrl': None,\n",
        "                        'error': 'No video URL provided'\n",
        "                    })\n",
        "                    continue\n",
        "\n",
        "                # Download video from Google Drive\n",
        "                safe_name, dest_path = download_video_from_google_drive(video_url, UPLOAD_DIR)\n",
        "\n",
        "                # Create local file URL (same as /upload endpoint)\n",
        "                file_url = f\"{base_url}/uploads/{safe_name}\"\n",
        "\n",
        "                uploaded_videos.append({\n",
        "                    'positionId': position_id,\n",
        "                    'question': question,\n",
        "                    'isVideoExist': True,\n",
        "                    'recordedVideoUrl': file_url,\n",
        "                    'filename': safe_name\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f'      ‚ùå Failed to download video {idx}: {str(e)}')\n",
        "                uploaded_videos.append({\n",
        "                    'positionId': interview.get('positionId', idx),\n",
        "                    'question': interview.get('question', ''),\n",
        "                    'isVideoExist': False,\n",
        "                    'recordedVideoUrl': None,\n",
        "                    'error': str(e)\n",
        "                })\n",
        "\n",
        "        successful_downloads = len([v for v in uploaded_videos if v['isVideoExist']])\n",
        "        print(f\"\\n‚úÖ Download complete: {successful_downloads}/{len(interviews)} successful\")\n",
        "\n",
        "        # PHASE 2: Update status to processing (same as /upload endpoint)\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'processing',\n",
        "                'progress': '0/' + str(len(uploaded_videos)),\n",
        "                'message': 'Starting transcription...',\n",
        "                'uploaded_videos': len(uploaded_videos)\n",
        "            }\n",
        "\n",
        "        # PHASE 3: Process transcriptions (IDENTICAL to /upload endpoint)\n",
        "        print(f'\\nüîÑ Starting transcription process (identical to /upload endpoint)...')\n",
        "        process_transcriptions_sync(session_id, candidate_name, uploaded_videos, base_url, language)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_detail = traceback.format_exc()\n",
        "        print(f\"‚ùå Download thread error:\\n{error_detail}\")\n",
        "\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'error',\n",
        "                'error': str(e),\n",
        "                'error_detail': error_detail\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_4yZAte8K6Vb",
      "metadata": {
        "id": "_4yZAte8K6Vb"
      },
      "source": [
        "<b><h2> Final Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "GaQ-qG9OUcm3",
      "metadata": {
        "id": "GaQ-qG9OUcm3"
      },
      "outputs": [],
      "source": [
        "def process_transcriptions_sync(session_id: str, candidate_name: str, uploaded_videos: list, base_url: str, language: str = \"en\"):\n",
        "    \"\"\"Background transcription processing WITH COMPREHENSIVE LOGGING\"\"\"\n",
        "\n",
        "    # ‚≠ê SETUP LOGGING TO FILE\n",
        "    log_file = f'session_{session_id}.log'\n",
        "    log_handle = open(log_file, 'w', encoding='utf-8', buffering=1)\n",
        "\n",
        "    def log_print(msg):\n",
        "        \"\"\"Print to both console and log file\"\"\"\n",
        "        print(msg, flush=True)\n",
        "        log_handle.write(msg + '\\n')\n",
        "        log_handle.flush()\n",
        "\n",
        "    try:\n",
        "        log_print(f'\\n{\"=\"*70}')\n",
        "        log_print(f'üéôÔ∏è  SESSION: {session_id}')\n",
        "        log_print(f'üë§ CANDIDATE: {candidate_name}')\n",
        "        log_print(f'üåê LANGUAGE: {\"English\" if language == \"en\" else \"Indonesian\" if language == \"id\" else language}')\n",
        "        log_print(f'üìπ VIDEOS: {len(uploaded_videos)}')\n",
        "        log_print(f'üìù LOG FILE: {log_file}')\n",
        "        log_print(f'{\"=\"*70}\\n')\n",
        "\n",
        "        transcriptions = []\n",
        "        assessment_results = []\n",
        "\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {'status': 'processing', 'progress': '0/0'}\n",
        "\n",
        "        # Process each video\n",
        "        for idx, interview in enumerate(uploaded_videos, 1):\n",
        "            log_print(f'\\n{\"‚îÄ\"*70}')\n",
        "            log_print(f'Processing video {idx}/{len(uploaded_videos)}')\n",
        "            log_print(f'{\"‚îÄ\"*70}')\n",
        "\n",
        "            if not interview.get('isVideoExist') or not interview.get('recordedVideoUrl'):\n",
        "                log_print(f'‚ö†Ô∏è Video {idx} - No video exists or no URL')\n",
        "                transcriptions.append({\n",
        "                    'positionId': interview['positionId'],\n",
        "                    'error': interview.get('error', 'Video upload failed')\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            position_id = interview['positionId']\n",
        "            video_url = interview['recordedVideoUrl']\n",
        "            question = interview.get('question', '')\n",
        "\n",
        "            try:\n",
        "                log_print(f'\\n‚îå‚îÄ Video {position_id}/{len(uploaded_videos)} ‚îÄ{\"‚îÄ\"*50}‚îê')\n",
        "                if question:\n",
        "                    log_print(f'‚îÇ ‚ùì Question: {question[:60]}{\"...\" if len(question) > 60 else \"\"}')\n",
        "\n",
        "                local_file = get_local_file_path(video_url)\n",
        "                if not local_file:\n",
        "                    raise Exception(f\"Local file not found\")\n",
        "\n",
        "                log_print(f'‚îÇ üìÅ Local file: {local_file}')\n",
        "                log_print(f'‚îÇ üìè File exists: {os.path.exists(local_file)}')\n",
        "\n",
        "                file_size_mb = os.path.getsize(local_file) / (1024 * 1024)\n",
        "                log_print(f'‚îÇ üìä File size: {file_size_mb:.1f} MB')\n",
        "\n",
        "                with processing_lock:\n",
        "                    processing_status[session_id] = {\n",
        "                        'status': 'processing',\n",
        "                        'progress': f'{position_id}/{len(uploaded_videos)}',\n",
        "                        'current_video': position_id,\n",
        "                        'message': f'Processing video {position_id}/{len(uploaded_videos)}...'\n",
        "                    }\n",
        "\n",
        "                video_start = time.time()\n",
        "\n",
        "                # Step 1: Transcribe\n",
        "                log_print(f'‚îÇ 1Ô∏è‚É£  TRANSCRIPTION ({file_size_mb:.1f} MB)')\n",
        "                try:\n",
        "                    transcription_text, avg_confidence, min_conf, max_conf = transcribe_video(local_file, language=language)\n",
        "                    transcribe_time = time.time() - video_start\n",
        "                    log_print(f'‚îÇ    ‚úÖ Transcription completed')\n",
        "                    log_print(f'‚îÇ    üéØ Transcription Confidence: {avg_confidence}%')\n",
        "                    log_print(f'‚îÇ    üìù Text length: {len(transcription_text)} chars')\n",
        "                except Exception as e:\n",
        "                    log_print(f'‚îÇ    ‚ùå Transcription ERROR: {str(e)}')\n",
        "                    raise\n",
        "\n",
        "                # Step 2: Translate (conditional based on language)\n",
        "                log_print(f'‚îÇ 2Ô∏è‚É£  TRANSLATION')\n",
        "                try:\n",
        "                    translate_start = time.time()\n",
        "\n",
        "                    if language == \"en\":\n",
        "                        # English ‚Üí Indonesian\n",
        "                        translation_result = translate_to_indonesian(transcription_text)\n",
        "                        transcription_en = transcription_text  # Original is English\n",
        "                        transcription_id = translation_result['translated_text']  # Translated to Indonesian\n",
        "                        log_print(f'‚îÇ    üåê Direction: English ‚Üí Indonesian')\n",
        "                    elif language == \"id\":\n",
        "                        # Indonesian ‚Üí English\n",
        "                        translation_result = translate_to_english(transcription_text)\n",
        "                        transcription_id = transcription_text  # Original is Indonesian\n",
        "                        transcription_en = translation_result['translated_text']  # Translated to English\n",
        "                        log_print(f'‚îÇ    üåê Direction: Indonesian ‚Üí English')\n",
        "                    else:\n",
        "                        # Default: assume English\n",
        "                        translation_result = translate_to_indonesian(transcription_text)\n",
        "                        transcription_en = transcription_text\n",
        "                        transcription_id = translation_result['translated_text']\n",
        "                        log_print(f'‚îÇ    ‚ö†Ô∏è  Unknown language, defaulting to English ‚Üí Indonesian')\n",
        "\n",
        "                    translate_time = time.time() - translate_start\n",
        "                    log_print(f'‚îÇ    ‚úÖ Translation completed in {translate_time:.1f}s')\n",
        "                    log_print(f'‚îÇ    üìù EN length: {len(transcription_en)} chars')\n",
        "                    log_print(f'‚îÇ    üìù ID length: {len(transcription_id)} chars')\n",
        "                except Exception as e:\n",
        "                    log_print(f'‚îÇ    ‚ùå Translation ERROR: {str(e)}')\n",
        "                    raise\n",
        "\n",
        "                # Step 3: Cheating Detection\n",
        "                log_print(f'‚îÇ 2Ô∏è‚É£¬Ω CHEATING DETECTION')\n",
        "                print('\\nüîç Running Cheating Detection...')\n",
        "                try:\n",
        "                    cheating_start = time.time()\n",
        "                    cheating_result = comprehensive_cheating_detection(local_file)\n",
        "                    cheating_time = time.time() - cheating_start\n",
        "                    log_print(f'‚îÇ    ‚úÖ Cheating detection completed in {cheating_time:.1f}s')\n",
        "                except Exception as e:\n",
        "                    log_print(f'‚îÇ    ‚ùå Cheating detection ERROR: {str(e)}')\n",
        "                    raise\n",
        "\n",
        "                # Step 4: Non-Verbal Analysis\n",
        "                log_print(f'‚îÇ 2Ô∏è‚É£¬æ NON-VERBAL ANALYSIS')\n",
        "                try:\n",
        "                    non_verbal_start = time.time()\n",
        "                    non_verbal_result = analyze_interview_video_with_confidence(\n",
        "                        video_path=local_file,\n",
        "                        audio_path=None\n",
        "                    )\n",
        "                    non_verbal_time = time.time() - non_verbal_start\n",
        "                    log_print(f'‚îÇ    ‚úÖ Non-verbal analysis completed in {non_verbal_time:.1f}s')\n",
        "                    log_print(f'‚îÇ    üìä Non-Verbal Confidence: {non_verbal_result[\"confidence_score\"]}%')\n",
        "                except Exception as e:\n",
        "                    log_print(f'‚îÇ    ‚ùå Non-verbal analysis ERROR: {str(e)}')\n",
        "                    raise\n",
        "\n",
        "                # Step 5: LLM Evaluation (always use English text for better accuracy)\n",
        "                log_print(f'‚îÇ 3Ô∏è‚É£  AI ASSESSMENT')\n",
        "                try:\n",
        "                    llm_start = time.time()\n",
        "                    llm_evaluation = evaluate_with_llm(transcription_en, question, position_id)  # ‚úÖ Use English version\n",
        "                    llm_time = time.time() - llm_start\n",
        "                    log_print(f'‚îÇ    ‚úÖ LLM evaluation completed in {llm_time:.1f}s')\n",
        "                    log_print(f'‚îÇ    üìä Total Score: {llm_evaluation[\"total\"]}/100')\n",
        "                except Exception as e:\n",
        "                    log_print(f'‚îÇ    ‚ùå LLM evaluation ERROR: {str(e)}')\n",
        "                    raise\n",
        "\n",
        "                # Step 6: Save transcription file\n",
        "                log_print(f'‚îÇ 4Ô∏è‚É£  SAVING FILES')\n",
        "                trans_fname = f\"transcription_pos{position_id}_{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}.txt\"\n",
        "                trans_path = os.path.join(TRANSCRIPTION_DIR, trans_fname)\n",
        "\n",
        "                with open(trans_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(f\"Candidate: {candidate_name}\\n\")\n",
        "                    f.write(f\"Position ID: {position_id}\\n\")\n",
        "                    f.write(f\"Question: {question}\\n\")\n",
        "                    f.write(f\"Video URL: {video_url}\\n\")\n",
        "                    f.write(f\"Language: {language}\\n\")  # ‚úÖ Added language info\n",
        "                    f.write(f\"Transcribed at: {datetime.now(timezone.utc).isoformat()}\\n\")\n",
        "                    f.write(f\"\\n{'='*50}\\n\")\n",
        "\n",
        "                    if language == \"id\":\n",
        "                        f.write(f\"INDONESIAN TRANSCRIPTION (Original):\\n\")\n",
        "                        f.write(f\"{'='*50}\\n\\n\")\n",
        "                        f.write(transcription_id)\n",
        "                        f.write(f\"\\n\\n{'='*50}\\n\")\n",
        "                        f.write(f\"ENGLISH TRANSLATION:\\n\")\n",
        "                        f.write(f\"{'='*50}\\n\\n\")\n",
        "                        f.write(transcription_en)\n",
        "                    else:\n",
        "                        f.write(f\"ENGLISH TRANSCRIPTION (Original):\\n\")\n",
        "                        f.write(f\"{'='*50}\\n\\n\")\n",
        "                        f.write(transcription_en)\n",
        "                        f.write(f\"\\n\\n{'='*50}\\n\")\n",
        "                        f.write(f\"INDONESIAN TRANSLATION:\\n\")\n",
        "                        f.write(f\"{'='*50}\\n\\n\")\n",
        "                        f.write(transcription_id)\n",
        "\n",
        "                    f.write(f\"\\n\\nTranscription Confidence: {avg_confidence}%\\n\")\n",
        "\n",
        "                log_print(f'‚îÇ    ‚úÖ Transcription file saved: {trans_fname}')\n",
        "\n",
        "                transcription_url = f\"{base_url}/transcriptions/{trans_fname}\"\n",
        "\n",
        "                # Build assessment\n",
        "                words = transcription_en.split()\n",
        "\n",
        "                assessment = {\n",
        "                    \"penilaian\": {\n",
        "                        \"confidence_score\": llm_evaluation['scores']['confidence_score'],\n",
        "                        \"kualitas_jawaban\": llm_evaluation['scores']['kualitas_jawaban'],\n",
        "                        \"relevansi\": llm_evaluation['scores']['relevansi'],\n",
        "                        \"koherensi\": llm_evaluation['scores']['koherensi'],\n",
        "                        \"analisis_llm\": llm_evaluation['analysis'],\n",
        "                        \"total\": llm_evaluation['total'],\n",
        "                        # üÜï NEW: Add logprobs data\n",
        "                        \"logprobs_confidence\": llm_evaluation.get('logprobs_confidence'),\n",
        "                        \"logprobs_probability\": llm_evaluation.get('logprobs_probability'),\n",
        "                        \"logprobs_available\": llm_evaluation.get('logprobs_available', False)\n",
        "                    },\n",
        "                    \"non_verbal_analysis\": non_verbal_result['analysis'],\n",
        "                    \"non_verbal_confidence_score\": non_verbal_result['confidence_score'],\n",
        "                    \"transkripsi_en\": transcription_en,\n",
        "                    \"transkripsi_id\": transcription_id,\n",
        "                    \"transkripsi_confidence\": avg_confidence,\n",
        "                    \"transkripsi_min_confidence\": min_conf,\n",
        "                    \"transkripsi_max_confidence\": max_conf,\n",
        "                    \"cheating_detection\": cheating_result,\n",
        "                    \"metadata\": {\n",
        "                        \"word_count\": len(words),\n",
        "                        \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
        "                        # üÜï NEW: Logprobs metadata\n",
        "                        \"logprobs_enabled\": True,\n",
        "                        \"source_language\": \"English\" if language == \"en\" else \"Indonesian\" if language == \"id\" else \"Unknown\"\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                assessment_results.append({\n",
        "                    \"id\": position_id,\n",
        "                    \"question\": question,\n",
        "                    \"result\": assessment\n",
        "                })\n",
        "                log_print(f'‚îÇ    ‚úÖ Assessment added to results (total: {len(assessment_results)})')\n",
        "\n",
        "                transcriptions.append({\n",
        "                    'positionId': position_id,\n",
        "                    'question': question,\n",
        "                    'videoUrl': video_url,\n",
        "                    'transcription': transcription_en,\n",
        "                    'transcription_id': transcription_id,\n",
        "                    'transcriptionUrl': transcription_url,\n",
        "                    'transcriptionFile': trans_fname,\n",
        "                    'assessment': assessment\n",
        "                })\n",
        "\n",
        "                # Delete video\n",
        "                if os.path.exists(local_file):\n",
        "                    os.remove(local_file)\n",
        "                    log_print(f'‚îÇ üóëÔ∏è  Video deleted ({file_size_mb:.1f} MB freed)')\n",
        "\n",
        "                total_time = time.time() - video_start\n",
        "                log_print(f'‚îÇ ‚è±Ô∏è  Total: {total_time:.1f}s')\n",
        "                log_print(f'‚îî‚îÄ{\"‚îÄ\"*68}‚îò')\n",
        "\n",
        "                gc.collect()\n",
        "\n",
        "            except Exception as e:\n",
        "                log_print(f'‚îÇ ‚ùå ERROR processing video {position_id}: {str(e)}')\n",
        "                log_print(f'‚îÇ üìã Traceback:')\n",
        "                for line in traceback.format_exc().split('\\n'):\n",
        "                    log_print(f'‚îÇ    {line}')\n",
        "                log_print(f'‚îî‚îÄ{\"‚îÄ\"*68}‚îò')\n",
        "\n",
        "                transcriptions.append({\n",
        "                    'positionId': position_id,\n",
        "                    'question': question,\n",
        "                    'videoUrl': video_url,\n",
        "                    'error': str(e)\n",
        "                })\n",
        "\n",
        "        # ============================================================================\n",
        "        # AGGREGATE ANALYSIS\n",
        "        # ============================================================================\n",
        "        log_print(f'\\n{\"=\"*70}')\n",
        "        log_print(f'üìä STARTING AGGREGATE ANALYSIS')\n",
        "        log_print(f'{\"=\"*70}')\n",
        "        log_print(f'Assessment Results Count: {len(assessment_results)}')\n",
        "\n",
        "        if len(assessment_results) == 0:\n",
        "            log_print(f'‚ö†Ô∏è WARNING: No assessment results! Cannot create aggregate analysis.')\n",
        "            log_print(f'   Total transcriptions: {len(transcriptions)}')\n",
        "            log_print(f'   Transcriptions with errors: {sum(1 for t in transcriptions if \"error\" in t)}')\n",
        "\n",
        "        # 1. Aggregate Cheating\n",
        "        try:\n",
        "            log_print(f'\\nüëÄ Calculating aggregate non-verbal...')\n",
        "            aggregate_cheating = aggregate_cheating_results(assessment_results)\n",
        "            log_print(f'‚úÖ Aggregate cheating completed')\n",
        "        except Exception as e:\n",
        "            log_print(f'‚ùå ERROR in aggregate_non_verbal: {str(e)}')\n",
        "            log_print(f'   Traceback: {traceback.format_exc()}')\n",
        "            aggregate_cheating = {\"error\": str(e)}\n",
        "\n",
        "\n",
        "        # 2. Aggregate Non-Verbal\n",
        "        try:\n",
        "            log_print(f'\\nüëÄ Calculating aggregate non-verbal...')\n",
        "            aggregate_non_verbal = summarize_non_verbal_batch(assessment_results)\n",
        "            log_print(f'‚úÖ Aggregate non-verbal completed')\n",
        "        except Exception as e:\n",
        "            log_print(f'‚ùå ERROR in aggregate_non_verbal: {str(e)}')\n",
        "            log_print(f'   Traceback: {traceback.format_exc()}')\n",
        "            aggregate_non_verbal = {\"error\": str(e)}\n",
        "\n",
        "        # 3. LLM Summary\n",
        "        try:\n",
        "            log_print(f'\\nü§ñ Generating LLM summary...')\n",
        "            hasil_llm = summarize_llm_analysis_batch(assessment_results)\n",
        "            log_print(f'‚úÖ LLM summary completed')\n",
        "        except Exception as e:\n",
        "            log_print(f'‚ùå ERROR in LLM summary: {str(e)}')\n",
        "            log_print(f'   Traceback: {traceback.format_exc()}')\n",
        "            hasil_llm = {\n",
        "                \"kesimpulan_llm\": f\"Error: {str(e)}\",\n",
        "                \"rata_rata_confidence_score\": 0,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "        log_print(f'\\n{\"=\"*70}')\n",
        "        log_print(f'‚úÖ ALL AGGREGATE ANALYSIS COMPLETED')\n",
        "        log_print(f'{\"=\"*70}')\n",
        "\n",
        "        # ============================================================================\n",
        "        # SAVE JSON\n",
        "        # ============================================================================\n",
        "        if assessment_results:\n",
        "            try:\n",
        "                log_print(f'\\nüíæ SAVING JSON RESULTS...')\n",
        "\n",
        "                results_json = {\n",
        "                   \"success\": True,\n",
        "                    \"name\": candidate_name,\n",
        "                    \"session\": session_id,\n",
        "                    \"llm_results\": hasil_llm,\n",
        "                    \"aggregate_cheating_detection\": aggregate_cheating,\n",
        "                    \"aggregate_non_verbal_analysis\": aggregate_non_verbal,\n",
        "                    \"content\": assessment_results,\n",
        "                    \"metadata\": {\n",
        "                        \"total_videos\": len(uploaded_videos),\n",
        "                        \"successful_videos\": len(assessment_results),\n",
        "                        \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
        "                        \"model\": \"faster-whisper large-v3\",\n",
        "                        \"llm_model\": \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                results_filename = f\"{session_id}.json\"\n",
        "                results_path = os.path.join(RESULTS_DIR, results_filename)\n",
        "\n",
        "                log_print(f'üìÇ Results path: {results_path}')\n",
        "                log_print(f'üìä JSON size: {len(str(results_json))} chars')\n",
        "\n",
        "                # Ensure directory exists\n",
        "                os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "                log_print(f'‚úÖ Results directory ensured: {RESULTS_DIR}')\n",
        "\n",
        "                # Write JSON\n",
        "                try:\n",
        "                    with open(results_path, 'w', encoding='utf-8') as f:\n",
        "                        json.dump(results_json, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "                    file_size = os.path.getsize(results_path)\n",
        "                    print(f'‚úÖ JSON saved successfully')\n",
        "                    print(f'   File: {results_filename}')\n",
        "                    print(f'   Size: {file_size:,} bytes ({file_size/1024:.1f} KB)')\n",
        "\n",
        "                except Exception as save_error:\n",
        "                    print(f'‚ùå ERROR saving JSON: {save_error}')\n",
        "                    print(f'   Attempting alternative save method...')\n",
        "\n",
        "                    # Fallback: Manually convert NumPy types\n",
        "                    def convert_to_native(obj):\n",
        "                        if isinstance(obj, dict):\n",
        "                            return {k: convert_to_native(v) for k, v in obj.items()}\n",
        "                        elif isinstance(obj, list):\n",
        "                            return [convert_to_native(item) for item in obj]\n",
        "                        elif isinstance(obj, (np.integer, np.int32, np.int64)):\n",
        "                            return int(obj)\n",
        "                        elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
        "                            return float(obj)\n",
        "                        elif isinstance(obj, np.ndarray):\n",
        "                            return obj.tolist()\n",
        "                        elif isinstance(obj, np.bool_):\n",
        "                            return bool(obj)\n",
        "                        return obj\n",
        "\n",
        "                    try:\n",
        "                        cleaned_json = convert_to_native(results_json)\n",
        "                        with open(results_path, 'w', encoding='utf-8') as f:\n",
        "                            json.dump(cleaned_json, f, ensure_ascii=False, indent=2)\n",
        "                        print(f'‚úÖ JSON saved successfully (fallback method)')\n",
        "                    except Exception as fallback_error:\n",
        "                        print(f'‚ùå CRITICAL: Both save methods failed: {fallback_error}')\n",
        "                        raise\n",
        "\n",
        "                log_print(f'‚úÖ JSON written to file')\n",
        "\n",
        "                # Verify\n",
        "                if os.path.exists(results_path):\n",
        "                    file_size = os.path.getsize(results_path)\n",
        "                    log_print(f'‚úÖ‚úÖ‚úÖ JSON FILE SAVED SUCCESSFULLY! ‚úÖ‚úÖ‚úÖ')\n",
        "                    log_print(f'   Path: {results_path}')\n",
        "                    log_print(f'   Size: {file_size} bytes')\n",
        "                else:\n",
        "                    log_print(f'‚ùå‚ùå‚ùå WARNING: JSON FILE NOT CREATED! ‚ùå‚ùå‚ùå')\n",
        "\n",
        "                results_url = f\"{base_url}/results/{results_filename}\"\n",
        "                log_print(f'üåê Results URL: {results_url}')\n",
        "\n",
        "            except Exception as e:\n",
        "                log_print(f'‚ùå CRITICAL ERROR saving JSON: {str(e)}')\n",
        "                log_print(f'   Traceback: {traceback.format_exc()}')\n",
        "        else:\n",
        "            log_print(f'\\n‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: assessment_results is EMPTY! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è')\n",
        "            log_print(f'   JSON will NOT be saved.')\n",
        "\n",
        "        successful_count = sum(1 for t in transcriptions if 'transcription' in t)\n",
        "\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'completed',\n",
        "                'result': {\n",
        "                    'success': True,\n",
        "                    'transcriptions': transcriptions,\n",
        "                    'processed_videos': len(transcriptions),\n",
        "                    'successful_videos': successful_count,\n",
        "                    'failed_videos': len(transcriptions) - successful_count,\n",
        "                    'results_url': f\"{base_url}/results/{session_id}.json\" if assessment_results else None\n",
        "                }\n",
        "            }\n",
        "\n",
        "        log_print(f'\\n{\"=\"*70}')\n",
        "        log_print(f'‚úÖ SESSION COMPLETED')\n",
        "        log_print(f'   Success: {successful_count}/{len(transcriptions)} videos')\n",
        "        log_print(f'   Log file: {log_file}')\n",
        "        log_print(f'{\"=\"*70}\\n')\n",
        "\n",
        "    except Exception as e:\n",
        "        log_print(f'\\n‚ùå SESSION ERROR:\\n{traceback.format_exc()}')\n",
        "\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'error',\n",
        "                'error': str(e),\n",
        "                'error_detail': traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    finally:\n",
        "        log_handle.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bBkV62fsK-FO",
      "metadata": {
        "id": "bBkV62fsK-FO"
      },
      "source": [
        "<b><h2> ENDPOINT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "qLpXqXHoUhWr",
      "metadata": {
        "id": "qLpXqXHoUhWr"
      },
      "outputs": [],
      "source": [
        "# ENDPOINTS\n",
        "@app.post('/upload')\n",
        "async def receive_videos_and_process(\n",
        "    request: Request,\n",
        "    candidate_name: str = Form(...),\n",
        "    language: str = Form(\"en\"),\n",
        "    videos: List[UploadFile] = File(...),\n",
        "    questions: List[str] = Form(...)  # NEW: Accept questions array\n",
        "):\n",
        "    \"\"\"Upload videos and start background transcription\"\"\"\n",
        "    session_id = uuid.uuid4().hex\n",
        "    print(f'\\nüîµ NEW UPLOAD REQUEST - Session: {session_id}')\n",
        "    print(f'   Candidate: {candidate_name}')\n",
        "    print(f'   Videos: {len(videos)} file(s)')\n",
        "    print(f'   Questions: {len(questions)} question(s)')  # NEW\n",
        "\n",
        "    # NEW: Validate questions count matches videos count\n",
        "    if len(questions) != len(videos):\n",
        "        return JSONResponse(\n",
        "            content={\n",
        "                'success': False,\n",
        "                'error': f'Questions count ({len(questions)}) must match videos count ({len(videos)})'\n",
        "            },\n",
        "            status_code=400,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if language not in [\"en\", \"id\"]:\n",
        "        return JSONResponse(\n",
        "            {\n",
        "                'success': False,\n",
        "                'error': f'Invalid language code: {language}. Must be \"en\" or \"id\".'\n",
        "            },\n",
        "            status_code=400\n",
        "        )\n",
        "\n",
        "    # Initialize status FIRST\n",
        "    with processing_lock:\n",
        "        processing_status[session_id] = {\n",
        "            'status': 'uploading',\n",
        "            'progress': '0/0',\n",
        "            'message': 'Uploading videos...'\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        # 1. Upload semua video (fast)\n",
        "        base_url = str(request.base_url).rstrip('/')\n",
        "        uploaded_videos = []\n",
        "\n",
        "        print(f'\\nüì§ Uploading {len(videos)} video(s)...')\n",
        "        for idx, (video, question) in enumerate(zip(videos, questions), 1):  # NEW: zip with questions\n",
        "            try:\n",
        "                ext = os.path.splitext(video.filename)[1] or '.webm'\n",
        "                safe_name = f\"{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}{ext}\"\n",
        "                dest_path = os.path.join(UPLOAD_DIR, safe_name)\n",
        "\n",
        "                # Update upload progress\n",
        "                with processing_lock:\n",
        "                    processing_status[session_id]['message'] = f'Uploading video {idx}/{len(videos)}...'\n",
        "                    processing_status[session_id]['progress'] = f'{idx}/{len(videos)}'\n",
        "\n",
        "                with open(dest_path, 'wb') as buffer:\n",
        "                    shutil.copyfileobj(video.file, buffer)\n",
        "\n",
        "                file_url = f\"{base_url}/uploads/{safe_name}\"\n",
        "                uploaded_videos.append({\n",
        "                    'positionId': idx,\n",
        "                    'question': question,  # NEW: Include question\n",
        "                    'isVideoExist': True,\n",
        "                    'recordedVideoUrl': file_url,\n",
        "                    'filename': safe_name\n",
        "                })\n",
        "                print(f'   ‚úÖ Uploaded: {safe_name} | Q: {question[:50]}{\"...\" if len(question) > 50 else \"\"}')  # NEW\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f'   ‚ùå Failed: {str(e)}')\n",
        "                uploaded_videos.append({\n",
        "                    'positionId': idx,\n",
        "                    'question': question if idx <= len(questions) else '',  # NEW: Include question even on error\n",
        "                    'isVideoExist': False,\n",
        "                    'recordedVideoUrl': None,\n",
        "                    'error': str(e)\n",
        "                })\n",
        "\n",
        "        # 2. Update status to processing\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'processing',\n",
        "                'progress': '0/' + str(len(uploaded_videos)),\n",
        "                'message': 'Starting transcription...',\n",
        "                'uploaded_videos': len(uploaded_videos)\n",
        "            }\n",
        "\n",
        "        # 3. Start background thread\n",
        "        thread = th.Thread(\n",
        "            target=process_transcriptions_sync,\n",
        "            args=(session_id, candidate_name, uploaded_videos, base_url, language),\n",
        "            daemon=True\n",
        "        )\n",
        "        thread.start()\n",
        "\n",
        "        print(f'‚úÖ Upload complete. Background thread started.')\n",
        "        print(f'üì§ Returning immediate response with session_id: {session_id}')\n",
        "\n",
        "        # 4. RETURN IMMEDIATELY - no waiting!\n",
        "        return JSONResponse(\n",
        "            content={\n",
        "                'success': True,\n",
        "                'session_id': session_id,\n",
        "                'message': 'Videos uploaded successfully. Processing started.',\n",
        "                'uploaded_videos': len(uploaded_videos)\n",
        "            },\n",
        "            status_code=200,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_detail = traceback.format_exc()\n",
        "        print(f'‚ùå Error:\\n{error_detail}')\n",
        "\n",
        "        # Update status to error\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'error',\n",
        "                'error': str(e),\n",
        "                'error_detail': error_detail\n",
        "            }\n",
        "\n",
        "        return JSONResponse(\n",
        "            content={\n",
        "                'success': False,\n",
        "                'session_id': session_id,\n",
        "                'error': str(e)\n",
        "            },\n",
        "            status_code=500,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "01fa1bb1",
      "metadata": {
        "id": "01fa1bb1"
      },
      "outputs": [],
      "source": [
        "# ===== ENDPOINT: /upload_json =====\n",
        "@app.post('/upload_json')\n",
        "async def receive_json_and_download_videos(request: Request):\n",
        "    \"\"\"Receive JSON with Google Drive URLs, download videos, then process\"\"\"\n",
        "    session_id = uuid.uuid4().hex\n",
        "\n",
        "    try:\n",
        "        # Parse JSON\n",
        "        json_data = await request.json()\n",
        "\n",
        "        print(f'\\nüîµ NEW JSON UPLOAD REQUEST - Session: {session_id}')\n",
        "\n",
        "        # Validate structure\n",
        "        if not json_data.get('success') or not json_data.get('data'):\n",
        "            return JSONResponse(\n",
        "                {'success': False, 'error': 'Invalid JSON: missing success or data'},\n",
        "                status_code=400,\n",
        "                headers={'Access-Control-Allow-Origin': '*'}\n",
        "            )\n",
        "\n",
        "        data = json_data['data']\n",
        "\n",
        "        # Extract candidate\n",
        "        if not data.get('candidate') or not data['candidate'].get('name'):\n",
        "            return JSONResponse(\n",
        "                {'success': False, 'error': 'Missing candidate name'},\n",
        "                status_code=400,\n",
        "                headers={'Access-Control-Allow-Origin': '*'}\n",
        "            )\n",
        "\n",
        "        candidate_name = data['candidate']['name']\n",
        "        candidate_email = data['candidate'].get('email', 'N/A')\n",
        "\n",
        "        # Extract interviews\n",
        "        if not data.get('reviewChecklists') or not data['reviewChecklists'].get('interviews'):\n",
        "            return JSONResponse(\n",
        "                {'success': False, 'error': 'Missing interviews data'},\n",
        "                status_code=400,\n",
        "                headers={'Access-Control-Allow-Origin': '*'}\n",
        "            )\n",
        "\n",
        "        interviews = data['reviewChecklists']['interviews']\n",
        "\n",
        "        if not isinstance(interviews, list) or len(interviews) == 0:\n",
        "            return JSONResponse(\n",
        "                {'success': False, 'error': 'Interviews array is empty'},\n",
        "                status_code=400,\n",
        "                headers={'Access-Control-Allow-Origin': '*'}\n",
        "            )\n",
        "\n",
        "        # Get language\n",
        "        language = json_data.get('language', 'en')\n",
        "\n",
        "        print(f'   Candidate: {candidate_name} ({candidate_email})')\n",
        "        print(f'   Videos: {len(interviews)} video(s)')\n",
        "        print(f'   Language: {language}')\n",
        "\n",
        "        # Validate language\n",
        "        if language not in [\"en\", \"id\"]:\n",
        "            return JSONResponse(\n",
        "                {'success': False, 'error': f'Invalid language: {language}'},\n",
        "                status_code=400,\n",
        "                headers={'Access-Control-Allow-Origin': '*'}\n",
        "            )\n",
        "\n",
        "        # Log certification info\n",
        "        if data.get('certification'):\n",
        "            cert = data['certification']\n",
        "            print(f'   Certification: {cert.get(\"abbreviatedType\", \"N/A\")} - {cert.get(\"status\", \"N/A\")}')\n",
        "\n",
        "        # Initialize status\n",
        "        with processing_lock:\n",
        "            processing_status[session_id] = {\n",
        "                'status': 'downloading',\n",
        "                'progress': '0/' + str(len(interviews)),\n",
        "                'message': 'Downloading videos from Google Drive...'\n",
        "            }\n",
        "\n",
        "        # Start background thread\n",
        "        thread = th.Thread(\n",
        "            target=download_and_process_videos,\n",
        "            args=(session_id, candidate_name, interviews, language, str(request.base_url).rstrip('/')),\n",
        "            daemon=True\n",
        "        )\n",
        "        thread.start()\n",
        "\n",
        "        print(f'‚úÖ JSON received. Background download thread started.')\n",
        "        print(f'üì§ Returning immediate response with session_id: {session_id}')\n",
        "\n",
        "        return JSONResponse(\n",
        "            content={\n",
        "                'success': True,\n",
        "                'session_id': session_id,\n",
        "                'message': 'JSON received. Downloading videos from Google Drive...',\n",
        "                'video_count': len(interviews)\n",
        "            },\n",
        "            status_code=200,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'POST, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_detail = traceback.format_exc()\n",
        "        print(f'‚ùå Error processing JSON:\\n{error_detail}')\n",
        "\n",
        "        return JSONResponse(\n",
        "            content={'success': False, 'error': str(e)},\n",
        "            status_code=500,\n",
        "            headers={'Access-Control-Allow-Origin': '*'}\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "JCMdYEh2Umes",
      "metadata": {
        "id": "JCMdYEh2Umes"
      },
      "outputs": [],
      "source": [
        "@app.get('/status/{session_id}')\n",
        "async def get_processing_status(session_id: str):\n",
        "    \"\"\"Check processing status\"\"\"\n",
        "    with processing_lock:\n",
        "        if session_id not in processing_status:\n",
        "            return JSONResponse(\n",
        "                {\n",
        "                    'status': 'not_found',\n",
        "                    'message': 'Session not found'\n",
        "                },\n",
        "                status_code=404,\n",
        "                headers={\n",
        "                    'Access-Control-Allow-Origin': '*',\n",
        "                    'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
        "                    'Access-Control-Allow-Headers': '*',\n",
        "                    'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
        "                }\n",
        "            )\n",
        "\n",
        "        status_copy = processing_status[session_id].copy()\n",
        "\n",
        "    # Add redirect URL if completed\n",
        "    if status_copy.get('status') == 'completed':\n",
        "        status_copy['redirect'] = f\"halaman_dasboard.html?session={session_id}\"\n",
        "\n",
        "    return JSONResponse(\n",
        "        status_copy,\n",
        "        headers={\n",
        "            'Access-Control-Allow-Origin': '*',\n",
        "            'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
        "            'Access-Control-Allow-Headers': '*',\n",
        "            'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "pHHf1yApUoi_",
      "metadata": {
        "id": "pHHf1yApUoi_"
      },
      "outputs": [],
      "source": [
        "@app.get('/results/{session_id}')\n",
        "async def get_results(session_id: str):\n",
        "    \"\"\"Get assessment results for a session\"\"\"\n",
        "    results_filename = f\"{session_id}.json\"\n",
        "    results_path = os.path.join(RESULTS_DIR, results_filename)\n",
        "\n",
        "    if not os.path.exists(results_path):\n",
        "        return JSONResponse(\n",
        "            {\n",
        "                'success': False,\n",
        "                'message': 'Results not found for this session',\n",
        "                'session_id': session_id\n",
        "            },\n",
        "            status_code=404,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "            }\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        with open(results_path, 'r', encoding='utf-8') as f:\n",
        "            results_data = json.load(f)\n",
        "\n",
        "        return JSONResponse(\n",
        "            results_data,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "                'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
        "            }\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return JSONResponse(\n",
        "            {\n",
        "                'success': False,\n",
        "                'message': f'Error reading results: {str(e)}',\n",
        "                'session_id': session_id\n",
        "            },\n",
        "            status_code=500,\n",
        "            headers={\n",
        "                'Access-Control-Allow-Origin': '*',\n",
        "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
        "                'Access-Control-Allow-Headers': '*',\n",
        "            }\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "fa761b7c",
      "metadata": {
        "id": "fa761b7c"
      },
      "outputs": [],
      "source": [
        "@app.get('/')\n",
        "async def index():\n",
        "    return {\n",
        "        'message': 'AI Interview Assessment System',\n",
        "        'model': 'faster-whisper large-v3',\n",
        "        'accuracy': '98%+ for clear English speech',\n",
        "        'speed': '4-5x faster than standard Whisper',\n",
        "        'endpoints': {\n",
        "            'upload': 'POST /upload',\n",
        "            'status': 'GET /status/{session_id}',\n",
        "            'results': 'GET /results/{session_id}',\n",
        "            'test_form': 'GET /upload_form'\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I_hOAn3rLBAV",
      "metadata": {
        "id": "I_hOAn3rLBAV"
      },
      "source": [
        "<b><h2> LOCAL SERVER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "5aa6ad00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aa6ad00",
        "outputId": "7c042012-83e7-4e46-8bc7-644dedd0e988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è∏Ô∏è  Stopping previous server...\n",
            "‚úÖ Previous server stopped.\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "üöÄ Server started successfully!\n",
            "üìç Local URL: http://127.0.0.1:8888\n",
            "üìç Network URL: http://0.0.0.0:8888\n",
            "üîß Endpoints:\n",
            "   - POST /upload       (upload videos & process)\n",
            "   - POST /upload_json  (upload JSON & download videos)\n",
            "   - GET  /status/{id}  (check processing status)\n",
            "   - GET  /results/{id} (get assessment results)\n",
            "   - GET  /upload_form  (test form)\n",
            "‚ÑπÔ∏è  Use Interrupt Kernel to stop the server\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
          ]
        }
      ],
      "source": [
        "# Jalankan server uvicorn di dalam notebook (tanpa ngrok)\n",
        "nest_asyncio.apply()\n",
        "PORT = 8888\n",
        "\n",
        "# Hentikan server sebelumnya jika ada\n",
        "if 'server_thread' in globals() and server_thread is not None:\n",
        "    try:\n",
        "        print('‚è∏Ô∏è  Stopping previous server...')\n",
        "        if 'server' in globals() and server is not None:\n",
        "            server.should_exit = True\n",
        "        # Tunggu thread selesai (dengan timeout)\n",
        "        if server_thread.is_alive():\n",
        "            server_thread.join(timeout=2)\n",
        "        print('‚úÖ Previous server stopped.')\n",
        "    except Exception as e:\n",
        "        print(f'‚ö†Ô∏è  Error stopping previous server: {e}')\n",
        "\n",
        "# Buat server instance baru dengan log level yang lebih rendah\n",
        "config = uvicorn.Config(\n",
        "    app=app,\n",
        "    host='0.0.0.0',\n",
        "    port=PORT,\n",
        "    log_level='warning',  # Kurangi verbosity untuk menghindari duplikasi log\n",
        "    access_log=False  # Nonaktifkan access log di console\n",
        ")\n",
        "server = uvicorn.Server(config=config)\n",
        "\n",
        "# Fungsi untuk menjalankan server di thread\n",
        "def run_server_in_thread():\n",
        "    # Buat event loop baru untuk thread ini\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "    try:\n",
        "        loop.run_until_complete(server.serve())\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Server error: {e}')\n",
        "    finally:\n",
        "        loop.close()\n",
        "\n",
        "# Jalankan server di background thread\n",
        "server_thread = threading.Thread(target=run_server_in_thread, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "print('‚îÅ' * 60)\n",
        "print('üöÄ Server started successfully!')\n",
        "print(f'üìç Local URL: http://127.0.0.1:{PORT}')\n",
        "print(f'üìç Network URL: http://0.0.0.0:{PORT}')\n",
        "print(f'üîß Endpoints:')\n",
        "print(f'   - POST /upload       (upload videos & process)')\n",
        "print(f'   - POST /upload_json  (upload JSON & download videos)')\n",
        "print(f'   - GET  /status/{{id}}  (check processing status)')\n",
        "print(f'   - GET  /results/{{id}} (get assessment results)')\n",
        "print(f'   - GET  /upload_form  (test form)')\n",
        "print('‚ÑπÔ∏è  Use Interrupt Kernel to stop the server')\n",
        "print('‚îÅ' * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t5wi7BtWLDbW",
      "metadata": {
        "id": "t5wi7BtWLDbW"
      },
      "source": [
        "<b><h2> NGROK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "5e9bb1c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e9bb1c3",
        "outputId": "43a64521-67e8-4f35-db4e-50cbd00606db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your ngrok authtoken: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Ngrok configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Configure ngrok\n",
        "# Set ngrok authtoken (dapatkan dari https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "NGROK_AUTH_TOKEN = getpass.getpass('Enter your ngrok authtoken: ')\n",
        "conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
        "\n",
        "print('‚úÖ Ngrok configured successfully')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "38392051",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38392051",
        "outputId": "a7f952a3-a98d-403a-fb55-d4ffb7cbbd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üßπ Cleaned: 636 ‚Üí 630 chars\n",
            "   ‚úÖ Completed in 7.3s | 7 segments | 82 words\n",
            "   üéØ Transcription Confidence: 98.68% ‚úÖ\n",
            "   üìä Confidence Range: 98.54% - 98.86%\n",
            "‚îÇ    ‚úÖ Transcription completed\n",
            "‚è∏Ô∏è  Stopping previous server...\n",
            "‚îÇ    üéØ Transcription Confidence: 98.68%\n",
            "‚îÇ    üìù Text length: 630 chars\n",
            "‚îÇ 2Ô∏è‚É£  TRANSLATION\n",
            "‚úÖ Previous server stopped.\n",
            "   ‚úÖ Translation: 630 ‚Üí 610 chars\n",
            "‚îÇ    üåê Direction: Indonesian ‚Üí English\n",
            "‚îÇ    ‚úÖ Translation completed in 0.7s\n",
            "‚îÇ    üìù EN length: 610 chars\n",
            "‚îÇ    üìù ID length: 630 chars\n",
            "‚îÇ 2Ô∏è‚É£¬Ω CHEATING DETECTION\n",
            "\n",
            "üîç Running Cheating Detection...\n",
            "\n",
            "============================================================\n",
            "üéØ COMPREHENSIVE CHEATING DETECTION\n",
            "   (Video Interview - Expected: 1 Person)\n",
            "============================================================\n",
            "\n",
            "üëÅÔ∏è  STEP 1: Visual Analysis (Face Detection)\n",
            "------------------------------------------------------------\n",
            "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
            "üöÄ Server started successfully with ngrok!\n",
            "üìç Local URL: http://127.0.0.1:8888\n",
            "üåê Public URL (ngrok): https://allena-untransfigured-anomalistically.ngrok-free.dev\n",
            "üìã Copy this URL to use in Upload.js:\n",
            "   const VIDEO_ENDPOINT = \"https://allena-untransfigured-anomalistically.ngrok-free.dev/upload\";\n",
            "üìß Endpoints:\n",
            "   - POST https://allena-untransfigured-anomalistically.ngrok-free.dev/upload\n",
            "   - POST https://allena-untransfigured-anomalistically.ngrok-free.dev/upload_json\n",
            "   - GET  https://allena-untransfigured-anomalistically.ngrok-free.dev/status/{id}\n",
            "   - GET  https://allena-untransfigured-anomalistically.ngrok-free.dev/results/{id}\n",
            "   - GET  https://allena-untransfigured-anomalistically.ngrok-free.dev/upload_form\n",
            "‚ÑπÔ∏è  Ngrok tunnel will stay active while notebook is running\n",
            "‚ÑπÔ∏è  Use Interrupt Kernel to stop the server\n",
            "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n"
          ]
        }
      ],
      "source": [
        "# Start server with ngrok\n",
        "nest_asyncio.apply()\n",
        "PORT = 8888\n",
        "\n",
        "# Stop previous server if exists\n",
        "if 'server_thread' in globals() and server_thread is not None:\n",
        "    try:\n",
        "        print('‚è∏Ô∏è  Stopping previous server...')\n",
        "        if 'server' in globals() and server is not None:\n",
        "            server.should_exit = True\n",
        "        if server_thread.is_alive():\n",
        "            server_thread.join(timeout=2)\n",
        "        print('‚úÖ Previous server stopped.')\n",
        "    except Exception as e:\n",
        "        print(f'‚ö†Ô∏è  Error stopping previous server: {e}')\n",
        "\n",
        "# Close previous ngrok tunnels\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Create server instance\n",
        "config = uvicorn.Config(\n",
        "    app=app,\n",
        "    host='0.0.0.0',\n",
        "    port=PORT,\n",
        "    log_level='warning',\n",
        "    access_log=False\n",
        ")\n",
        "server = uvicorn.Server(config=config)\n",
        "\n",
        "# Run server in thread\n",
        "def run_server_in_thread():\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "    try:\n",
        "        loop.run_until_complete(server.serve())\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Server error: {e}')\n",
        "    finally:\n",
        "        loop.close()\n",
        "\n",
        "server_thread = threading.Thread(target=run_server_in_thread, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "time.sleep(2)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(PORT, bind_tls=True)\n",
        "ngrok_url = public_url.public_url\n",
        "\n",
        "print('‚îè' + '‚îÅ' * 70 + '‚îì')\n",
        "print('üöÄ Server started successfully with ngrok!')\n",
        "print(f'üìç Local URL: http://127.0.0.1:{PORT}')\n",
        "print(f'üåê Public URL (ngrok): {ngrok_url}')\n",
        "print(f'üìã Copy this URL to use in Upload.js:')\n",
        "print(f'   const VIDEO_ENDPOINT = \"{ngrok_url}/upload\";')\n",
        "print(f'üìß Endpoints:')\n",
        "print(f'   - POST {ngrok_url}/upload')\n",
        "print(f'   - POST {ngrok_url}/upload_json')\n",
        "print(f'   - GET  {ngrok_url}/status/{{id}}')\n",
        "print(f'   - GET  {ngrok_url}/results/{{id}}')\n",
        "print(f'   - GET  {ngrok_url}/upload_form')\n",
        "print('‚ÑπÔ∏è  Ngrok tunnel will stay active while notebook is running')\n",
        "print('‚ÑπÔ∏è  Use Interrupt Kernel to stop the server')\n",
        "print('‚îó' + '‚îÅ' * 70 + '‚îõ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "i0_tMSTy44YB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0_tMSTy44YB",
        "outputId": "ab6460b3-da3f-4299-8d6a-66d47fa429fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Reading log: session_4ec407d0b416464283cee9f97d44fa0b.log\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üéôÔ∏è  SESSION: 4ec407d0b416464283cee9f97d44fa0b\n",
            "üë§ CANDIDATE: Raifal Bagus\n",
            "üåê LANGUAGE: Indonesian\n",
            "üìπ VIDEOS: 3\n",
            "üìù LOG FILE: session_4ec407d0b416464283cee9f97d44fa0b.log\n",
            "======================================================================\n",
            "\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Processing video 1/3\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "‚îå‚îÄ Video 1/3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ ‚ùì Question: Can you tell us about the challenges you faced while working...\n",
            "‚îÇ üìÅ Local file: /content/uploads/20251212005439_df69d28dd2d040c0b74b520ba8cb0521.mp4\n",
            "‚îÇ üìè File exists: True\n",
            "‚îÇ üìä File size: 41.7 MB\n",
            "‚îÇ 1Ô∏è‚É£  TRANSCRIPTION (41.7 MB)\n",
            "‚îÇ    ‚úÖ Transcription completed\n",
            "‚îÇ    üéØ Transcription Confidence: 98.68%\n",
            "‚îÇ    üìù Text length: 630 chars\n",
            "‚îÇ 2Ô∏è‚É£  TRANSLATION\n",
            "‚îÇ    üåê Direction: Indonesian ‚Üí English\n",
            "‚îÇ    ‚úÖ Translation completed in 0.7s\n",
            "‚îÇ    üìù EN length: 610 chars\n",
            "‚îÇ    üìù ID length: 630 chars\n",
            "‚îÇ 2Ô∏è‚É£¬Ω CHEATING DETECTION\n",
            "‚îÇ    ‚úÖ Cheating detection completed in 38.8s\n",
            "‚îÇ 2Ô∏è‚É£¬æ NON-VERBAL ANALYSIS\n",
            "‚îÇ    ‚úÖ Non-verbal analysis completed in 30.1s\n",
            "‚îÇ    üìä Non-Verbal Confidence: 82.7%\n",
            "‚îÇ 3Ô∏è‚É£  AI ASSESSMENT\n",
            "‚îÇ    ‚úÖ LLM evaluation completed in 2.1s\n",
            "‚îÇ    üìä Total Score: 73/100\n",
            "‚îÇ 4Ô∏è‚É£  SAVING FILES\n",
            "‚îÇ    ‚úÖ Transcription file saved: transcription_pos1_20251212005559_dcd1b61483c149ed9e8b26054a10ffb8.txt\n",
            "‚îÇ    ‚úÖ Assessment added to results (total: 1)\n",
            "‚îÇ üóëÔ∏è  Video deleted (41.7 MB freed)\n",
            "‚îÇ ‚è±Ô∏è  Total: 79.9s\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Processing video 2/3\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "‚îå‚îÄ Video 2/3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ ‚ùì Question: What is the difference between HTML and CSS?\n",
            "‚îÇ üìÅ Local file: /content/uploads/20251212005439_c7ca87f957ec40d6b6d80e889d678300.mp4\n",
            "‚îÇ üìè File exists: True\n",
            "‚îÇ üìä File size: 39.9 MB\n",
            "‚îÇ 1Ô∏è‚É£  TRANSCRIPTION (39.9 MB)\n",
            "‚îÇ    ‚úÖ Transcription completed\n",
            "‚îÇ    üéØ Transcription Confidence: 98.75%\n",
            "‚îÇ    üìù Text length: 366 chars\n",
            "‚îÇ 2Ô∏è‚É£  TRANSLATION\n",
            "‚îÇ    üåê Direction: Indonesian ‚Üí English\n",
            "‚îÇ    ‚úÖ Translation completed in 1.0s\n",
            "‚îÇ    üìù EN length: 303 chars\n",
            "‚îÇ    üìù ID length: 366 chars\n",
            "‚îÇ 2Ô∏è‚É£¬Ω CHEATING DETECTION\n",
            "‚îÇ    ‚úÖ Cheating detection completed in 27.6s\n",
            "‚îÇ 2Ô∏è‚É£¬æ NON-VERBAL ANALYSIS\n",
            "‚îÇ    ‚úÖ Non-verbal analysis completed in 23.5s\n",
            "‚îÇ    üìä Non-Verbal Confidence: 75.08%\n",
            "‚îÇ 3Ô∏è‚É£  AI ASSESSMENT\n",
            "‚îÇ    ‚úÖ LLM evaluation completed in 1.9s\n",
            "‚îÇ    üìä Total Score: 58/100\n",
            "‚îÇ 4Ô∏è‚É£  SAVING FILES\n",
            "‚îÇ    ‚úÖ Transcription file saved: transcription_pos2_20251212005700_746ddca8603e45548d8f4c85aa503814.txt\n",
            "‚îÇ    ‚úÖ Assessment added to results (total: 2)\n",
            "‚îÇ üóëÔ∏è  Video deleted (39.9 MB freed)\n",
            "‚îÇ ‚è±Ô∏è  Total: 60.5s\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Processing video 3/3\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "‚îå‚îÄ Video 3/3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ ‚ùì Question: Explain the difference between HTML and CSS!\n",
            "‚îÇ üìÅ Local file: /content/uploads/20251212005439_8b753ddaa5644413886e3f9d38609430.mp4\n",
            "‚îÇ üìè File exists: True\n",
            "‚îÇ üìä File size: 54.2 MB\n",
            "‚îÇ 1Ô∏è‚É£  TRANSCRIPTION (54.2 MB)\n",
            "‚îÇ    ‚úÖ Transcription completed\n",
            "‚îÇ    üéØ Transcription Confidence: 98.54%\n",
            "‚îÇ    üìù Text length: 432 chars\n",
            "‚îÇ 2Ô∏è‚É£  TRANSLATION\n",
            "‚îÇ    üåê Direction: Indonesian ‚Üí English\n",
            "‚îÇ    ‚úÖ Translation completed in 0.6s\n",
            "‚îÇ    üìù EN length: 368 chars\n",
            "‚îÇ    üìù ID length: 432 chars\n",
            "‚îÇ 2Ô∏è‚É£¬Ω CHEATING DETECTION\n",
            "‚îÇ    ‚úÖ Cheating detection completed in 32.9s\n",
            "‚îÇ 2Ô∏è‚É£¬æ NON-VERBAL ANALYSIS\n",
            "‚îÇ    ‚úÖ Non-verbal analysis completed in 28.0s\n",
            "‚îÇ    üìä Non-Verbal Confidence: 74.65%\n",
            "‚îÇ 3Ô∏è‚É£  AI ASSESSMENT\n",
            "‚îÇ    ‚úÖ LLM evaluation completed in 1.8s\n",
            "‚îÇ    üìä Total Score: 55/100\n",
            "‚îÇ 4Ô∏è‚É£  SAVING FILES\n",
            "‚îÇ    ‚úÖ Transcription file saved: transcription_pos3_20251212005810_de17feb88b034fcdbcd64df7e8303918.txt\n",
            "‚îÇ    ‚úÖ Assessment added to results (total: 3)\n",
            "‚îÇ üóëÔ∏è  Video deleted (54.2 MB freed)\n",
            "‚îÇ ‚è±Ô∏è  Total: 69.9s\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "======================================================================\n",
            "üìä STARTING AGGREGATE ANALYSIS\n",
            "======================================================================\n",
            "Assessment Results Count: 3\n",
            "\n",
            "üëÄ Calculating aggregate non-verbal...\n",
            "‚úÖ Aggregate cheating completed\n",
            "\n",
            "üëÄ Calculating aggregate non-verbal...\n",
            "‚úÖ Aggregate non-verbal completed\n",
            "\n",
            "ü§ñ Generating LLM summary...\n",
            "‚úÖ LLM summary completed\n",
            "\n",
            "======================================================================\n",
            "‚úÖ ALL AGGREGATE ANALYSIS COMPLETED\n",
            "======================================================================\n",
            "\n",
            "üíæ SAVING JSON RESULTS...\n",
            "üìÇ Results path: /content/results/4ec407d0b416464283cee9f97d44fa0b.json\n",
            "üìä JSON size: 12050 chars\n",
            "‚úÖ Results directory ensured: /content/results\n",
            "‚úÖ JSON written to file\n",
            "‚úÖ‚úÖ‚úÖ JSON FILE SAVED SUCCESSFULLY! ‚úÖ‚úÖ‚úÖ\n",
            "   Path: /content/results/4ec407d0b416464283cee9f97d44fa0b.json\n",
            "   Size: 14948 bytes\n",
            "üåê Results URL: https://allena-untransfigured-anomalistically.ngrok-free.dev/results/4ec407d0b416464283cee9f97d44fa0b.json\n",
            "\n",
            "======================================================================\n",
            "‚úÖ SESSION COMPLETED\n",
            "   Success: 3/3 videos\n",
            "   Log file: session_4ec407d0b416464283cee9f97d44fa0b.log\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Cari session_id terbaru\n",
        "log_files = [f for f in os.listdir('.') if f.startswith('session_') and f.endswith('.log')]\n",
        "if log_files:\n",
        "    latest_log = max(log_files, key=lambda x: os.path.getmtime(x))\n",
        "    print(f\"üìù Reading log: {latest_log}\\n\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    with open(latest_log, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "        print(content)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No log files found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f94a342",
      "metadata": {
        "id": "5f94a342"
      },
      "source": [
        "## System Information\n",
        "\n",
        "### Whisper Model\n",
        "- **Library**: `faster-whisper` (optimized implementation)\n",
        "- **Model**: `large-v3` (most accurate available)\n",
        "- **Accuracy**: ~98% for clear English speech\n",
        "- **Speed**: 4-5x faster than `openai-whisper`\n",
        "\n",
        "### Translation\n",
        "- **Provider**: DeepL API\n",
        "- **Target Language**: Indonesian (ID)\n",
        "- **Source Language**: English (EN)\n",
        "- **Character Limit**: 5,000 per chunk\n",
        "- **Setup**: Set `DEEPL_API_KEY` in cell 4\n",
        "- **Get API Key**: https://www.deepl.com/pro-api (Free tier: 500,000 chars/month)\n",
        "\n",
        "### LLM Assessment\n",
        "- **Model**: meta-llama/Llama-2-7b-chat-hf\n",
        "- **Method**: Hybrid (LLM + Static)\n",
        "- **LLM Evaluated Criteria** (3):\n",
        "  1. **Kualitas Jawaban** - Quality of answer (clarity, completeness, depth)\n",
        "  2. **Koherensi** - Coherence (logical flow, consistency, structure)\n",
        "  3. **Relevansi** - Relevance (alignment with question, staying on topic)\n",
        "- **Static Dummy Values** (2):\n",
        "  4. **Tempo Bicara** - Speaking tempo (fixed at 85/100) üîß *TODO: Replace with audio analysis model*\n",
        "  5. **Confidence Score** - Confidence (fixed at 82/100) üîß *TODO: Replace with voice analysis model*\n",
        "- **Cheating Detection**: LLM analyzes for multiple speakers, artificial voice, reading patterns\n",
        "- **Fallback**: Rule-based assessment if LLM fails\n",
        "\n",
        "### Performance\n",
        "- **Device**: Automatically detects CUDA GPU (if available) or CPU\n",
        "- **Compute Type**:\n",
        "  - GPU: `float16` (faster with high accuracy)\n",
        "  - CPU: `int8` (optimized for CPU)\n",
        "- **VAD Filter**: Enabled (skips silence for efficiency)\n",
        "\n",
        "### Settings\n",
        "- **Beam Size**: 5 (higher = more accurate)\n",
        "- **Best Of**: 5 (samples multiple candidates)\n",
        "- **Patience**: 2.0 (thorough beam search)\n",
        "- **Temperature**: 0.0 (deterministic output)\n",
        "- **Context**: Uses previous text for better accuracy\n",
        "\n",
        "### Storage Management\n",
        "- **Auto-delete videos**: ‚úÖ Videos are automatically deleted after successful transcription\n",
        "- **Storage saved**: Only transcriptions and results are kept\n",
        "- **Safety**: Deletion only happens after successful transcription\n",
        "- **Error handling**: If deletion fails, processing continues normally\n",
        "\n",
        "### Endpoints\n",
        "- `POST /upload` - Upload videos and start transcription\n",
        "- `GET /status/{session_id}` - Check processing status\n",
        "- **`GET /results/{session_id}`** - **Get assessment results**\n",
        "- `GET /upload_form` - Test form interface\n",
        "- `GET /` - System information\n",
        "\n",
        "### Files\n",
        "- ~~Uploaded videos: `uploads/`~~ (deleted after transcription) ‚ôªÔ∏è\n",
        "- Transcriptions: `transcriptions/` ‚úÖ (includes English + Indonesian + Assessment)\n",
        "- **Assessment results: `results/`** ‚úÖ\n",
        "\n",
        "### Assessment Data Structure\n",
        "```json\n",
        "{\n",
        "  \"success\": true,\n",
        "  \"name\": \"Candidate Name\",\n",
        "  \"session\": \"session_id_here\",\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"question\": \"What is your experience with Python?\",\n",
        "      \"result\": {\n",
        "        \"penilaian\": {\n",
        "          \"kualitas_jawaban\": 85,    // ‚úÖ LLM evaluated\n",
        "          \"koherensi\": 83,            // ‚úÖ LLM evaluated\n",
        "          \"relevansi\": 80,            // ‚úÖ LLM evaluated\n",
        "          \"tempo_bicara\": 85,         // üîß Static dummy (TODO: audio model)\n",
        "          \"confidence_score\": 82,     // üîß Static dummy (TODO: voice model)\n",
        "          \"total\": 83\n",
        "        },\n",
        "        \"penilaian_akhir\": 4,\n",
        "        \"cheating_detection\": \"Tidak\",\n",
        "        \"keputusan_akhir\": \"Lulus\",\n",
        "        \"transkripsi_en\": \"...\",\n",
        "        \"transkripsi_id\": \"...\",\n",
        "        \"metadata\": {\n",
        "          \"assessment_method\": \"Hybrid (LLM + Static)\",\n",
        "          \"llm_evaluated_criteria\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\"],\n",
        "          \"static_criteria\": [\"tempo_bicara\", \"confidence_score\"]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  ],\n",
        "  \"metadata\": {\n",
        "    \"assessment_method\": \"Hybrid (LLM + Static)\",\n",
        "    \"llm_criteria\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\"],\n",
        "    \"static_criteria\": [\"tempo_bicara\", \"confidence_score\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### Roadmap\n",
        "- ‚úÖ **Phase 1**: LLM Assessment (kualitas, koherensi, relevansi)\n",
        "- üîß **Phase 2**: Audio Analysis Model (tempo_bicara) - *Coming Soon*\n",
        "- üîß **Phase 3**: Voice Analysis Model (confidence_score) - *Coming Soon*\n",
        "- üîß **Phase 4**: Video Analysis (eye contact, body language) - *Future*\n",
        "\n",
        "### Notes\n",
        "- **3 criteria** evaluated by LLM with real intelligence\n",
        "- **2 criteria** use static dummy values (will be replaced with specialized models)\n",
        "- Static values: `tempo_bicara=85`, `confidence_score=82`\n",
        "- Results saved automatically after transcription completes\n",
        "- **Original video files are deleted after transcription to save storage**\n",
        "- DeepL API key required for translation (free tier available)\n",
        "- Access via: `http://127.0.0.1:8888/results/{session_id}`\n",
        "\n",
        "### DeepL Setup\n",
        "1. Sign up at https://www.deepl.com/pro-api\n",
        "2. Get your free API key (500,000 chars/month)\n",
        "3. Set `DEEPL_API_KEY` in cell 4\n",
        "4. Restart kernel and run all cells"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
