{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa1df42",
   "metadata": {},
   "source": [
    "# FastAPI upload server (payload_video.ipynb)\n",
    "\n",
    "Notebook ini menyediakan server FastAPI yang menerima upload video (multipart) di `/upload` dan menerima JSON payload di `/upload`.\n",
    "\n",
    "Langkah eksekusi:\n",
    "1. Jalankan cell instalasi dependensi\n",
    "2. Jalankan cell setup direktori\n",
    "3. Jalankan cell definisi server\n",
    "4. Jalankan cell start server (ngrok akan dicoba jika tersedia)\n",
    "\n",
    "Hasil: file yang diupload akan disimpan di folder `uploads/` dan payload JSON yang dikirim ke `/upload` akan disimpan di `received_payloads/`. Video akan diproses dengan Whisper untuk speech-to-text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2da1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All packages installed successfully\n",
      "‚ÑπÔ∏è  Using faster-whisper (4-5x faster than openai-whisper)\n",
      "‚ÑπÔ∏è  Using DeepL for Indonesian translation\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (jalankan sekali)\n",
    "!pip install --quiet fastapi uvicorn nest-asyncio pyngrok python-multipart\n",
    "!pip install --quiet faster-whisper\n",
    "!pip install --quiet tqdm\n",
    "!pip install --quiet imageio-ffmpeg\n",
    "!pip install --quiet deepl\n",
    "\n",
    "print('\\n‚úÖ All packages installed successfully')\n",
    "print('‚ÑπÔ∏è  Using faster-whisper (4-5x faster than openai-whisper)')\n",
    "print('‚ÑπÔ∏è  Using DeepL for Indonesian translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5359c402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directories:\n",
      "   Upload: d:\\Coding\\Interview_Assesment_System-main\\uploads\n",
      "   Transcription: d:\\Coding\\Interview_Assesment_System-main\\transcriptions\n",
      "   Results: d:\\Coding\\Interview_Assesment_System-main\\results\n",
      "\n",
      "üéØ Device Configuration:\n",
      "   Device: CPU\n",
      "   Compute Type: int8\n",
      "   Note: Using CPU (GPU recommended for faster processing)\n",
      "\n",
      "üåê Translation Configuration:\n",
      "   DeepL API: Configured\n",
      "\n",
      "üéØ Device Configuration:\n",
      "   Device: CPU\n",
      "   Compute Type: int8\n",
      "   Note: Using CPU (GPU recommended for faster processing)\n",
      "\n",
      "üåê Translation Configuration:\n",
      "   DeepL API: Configured\n"
     ]
    }
   ],
   "source": [
    "# Siapkan direktori untuk upload dan transcription\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Setup directories\n",
    "ROOT_DIR = os.getcwd()\n",
    "UPLOAD_DIR = os.path.join(ROOT_DIR, 'uploads')\n",
    "TRANSCRIPTION_DIR = os.path.join(ROOT_DIR, 'transcriptions')\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, 'results')  # NEW: hasil assessment\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "os.makedirs(TRANSCRIPTION_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print('üìÅ Directories:')\n",
    "print(f'   Upload: {UPLOAD_DIR}')\n",
    "print(f'   Transcription: {TRANSCRIPTION_DIR}')\n",
    "print(f'   Results: {RESULTS_DIR}')\n",
    "\n",
    "# Check for GPU\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "\n",
    "print(f'\\nüéØ Device Configuration:')\n",
    "print(f'   Device: {device.upper()}')\n",
    "print(f'   Compute Type: {compute_type}')\n",
    "if device == \"cuda\":\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('   Note: Using CPU (GPU recommended for faster processing)')\n",
    "\n",
    "# DeepL Configuration\n",
    "DEEPL_API_KEY = \"02a88edf-4fcb-4786-ba3d-a137fb143760:fx\"\n",
    "\n",
    "print('\\nüåê Translation Configuration:')\n",
    "print(f'   DeepL API: {\"Configured\" if DEEPL_API_KEY != \"YOUR_DEEPL_API_KEY_HERE\" else \"‚ö†Ô∏è  NOT CONFIGURED - Set DEEPL_API_KEY\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa761b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daffa\\AppData\\Roaming\\Python\\Python313\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "C:\\Users\\Daffa\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Daffa\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Loading Whisper model...\n",
      "‚ÑπÔ∏è  Using faster-whisper \"large-v3\" model\n",
      "   This is the MOST ACCURATE model available\n",
      "   Speed: 4-5x faster than openai-whisper\n",
      "   Accuracy: ~98% for clear English speech\n",
      "   First run will download ~3GB model...\n",
      "\n",
      "üéØ Configuration:\n",
      "   Device: CPU\n",
      "   Compute Type: int8\n",
      "‚úÖ Whisper model loaded successfully\n",
      "\n",
      "‚úÖ DeepL translator initialized successfully\n",
      "\n",
      "‚úÖ Whisper model loaded successfully\n",
      "\n",
      "‚úÖ DeepL translator initialized successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException, BackgroundTasks\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse, HTMLResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "import uuid, shutil, json, os, sys\n",
    "from datetime import datetime, timezone\n",
    "import urllib.request\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import time\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import subprocess\n",
    "from typing import List\n",
    "import random\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "import deepl\n",
    "import requests\n",
    "\n",
    "app = FastAPI(title='AI Interview Assessment System')\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=['*'],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=['*'],\n",
    "    allow_headers=['*'],\n",
    "    expose_headers=['*'],\n",
    "    max_age=3600,\n",
    ")\n",
    "\n",
    "# Mount static folders\n",
    "app.mount('/uploads', StaticFiles(directory=UPLOAD_DIR), name='uploads')\n",
    "app.mount('/transcriptions', StaticFiles(directory=TRANSCRIPTION_DIR), name='transcriptions')\n",
    "app.mount('/results', StaticFiles(directory=RESULTS_DIR), name='results')\n",
    "\n",
    "# Load faster-whisper model with BEST ACCURACY settings\n",
    "print('\\nüì• Loading Whisper model...')\n",
    "print('‚ÑπÔ∏è  Using faster-whisper \"large-v3\" model')\n",
    "print('   This is the MOST ACCURATE model available')\n",
    "print('   Speed: 4-5x faster than openai-whisper')\n",
    "print('   Accuracy: ~98% for clear English speech')\n",
    "print('   First run will download ~3GB model...\\n')\n",
    "\n",
    "# Detect device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "\n",
    "print(f'üéØ Configuration:')\n",
    "print(f'   Device: {device.upper()}')\n",
    "print(f'   Compute Type: {compute_type}')\n",
    "\n",
    "# Load model with best accuracy settings\n",
    "whisper_model = WhisperModel(\n",
    "    \"large-v3\",\n",
    "    device=device,\n",
    "    compute_type=compute_type,\n",
    "    cpu_threads=4,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "print('‚úÖ Whisper model loaded successfully\\n')\n",
    "\n",
    "# Initialize DeepL translator\n",
    "translator = None\n",
    "if DEEPL_API_KEY and DEEPL_API_KEY != \"YOUR_DEEPL_API_KEY_HERE\":\n",
    "    try:\n",
    "        translator = deepl.Translator(DEEPL_API_KEY)\n",
    "        print('‚úÖ DeepL translator initialized successfully\\n')\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  DeepL initialization failed: {e}')\n",
    "        print('   Translation to Indonesian will be skipped\\n')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  DeepL API key not configured')\n",
    "    print('   Translation to Indonesian will be skipped\\n')\n",
    "\n",
    "# Background processing\n",
    "import threading\n",
    "import threading as th\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "processing_status = {}\n",
    "processing_lock = th.Lock()\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "\n",
    "def get_local_file_path(url):\n",
    "    \"\"\"Extract local file path from URL if it's a local upload\"\"\"\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        if '/uploads/' in parsed.path:\n",
    "            filename = parsed.path.split('/uploads/')[-1]\n",
    "            local_path = os.path.join(UPLOAD_DIR, filename)\n",
    "            if os.path.exists(local_path):\n",
    "                return local_path\n",
    "    except Exception as e:\n",
    "        print(f'Error parsing URL: {e}')\n",
    "    return None\n",
    "\n",
    "def download_video_from_url(url, position_id):\n",
    "    \"\"\"Download video from external URL (Google Drive, etc)\"\"\"\n",
    "    try:\n",
    "        print(f'   üì• Downloading video from URL...')\n",
    "        \n",
    "        # Handle Google Drive links\n",
    "        if 'drive.google.com' in url:\n",
    "            # Extract file ID from Google Drive URL\n",
    "            if '/file/d/' in url:\n",
    "                file_id = url.split('/file/d/')[1].split('/')[0]\n",
    "            elif 'id=' in url:\n",
    "                file_id = parse_qs(urlparse(url).query).get('id', [None])[0]\n",
    "            else:\n",
    "                raise Exception(\"Cannot extract file ID from Google Drive URL\")\n",
    "            \n",
    "            # Use Google Drive direct download URL\n",
    "            download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "            \n",
    "            print(f'   üîó Google Drive file ID: {file_id}')\n",
    "        else:\n",
    "            download_url = url\n",
    "        \n",
    "        # Download with progress\n",
    "        response = requests.get(download_url, stream=True, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Determine file extension\n",
    "        content_type = response.headers.get('Content-Type', '')\n",
    "        if 'video/mp4' in content_type:\n",
    "            ext = '.mp4'\n",
    "        elif 'video/webm' in content_type:\n",
    "            ext = '.webm'\n",
    "        elif 'video/quicktime' in content_type:\n",
    "            ext = '.mov'\n",
    "        else:\n",
    "            ext = '.mp4'  # Default\n",
    "        \n",
    "        # Save to temp file\n",
    "        temp_filename = f\"download_pos{position_id}_{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}{ext}\"\n",
    "        temp_path = os.path.join(UPLOAD_DIR, temp_filename)\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(temp_path, 'wb') as f:\n",
    "            if total_size:\n",
    "                downloaded = 0\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        percent = (downloaded / total_size) * 100\n",
    "                        if downloaded % (1024 * 1024) == 0:  # Every 1MB\n",
    "                            print(f'      Downloaded: {downloaded / (1024*1024):.1f}MB / {total_size / (1024*1024):.1f}MB ({percent:.1f}%)')\n",
    "            else:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        \n",
    "        file_size_mb = os.path.getsize(temp_path) / (1024 * 1024)\n",
    "        print(f'   ‚úÖ Download complete: {file_size_mb:.2f} MB')\n",
    "        \n",
    "        return temp_path\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        raise Exception(\"Download timeout - file terlalu besar atau koneksi lambat\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Download failed: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Download error: {str(e)}\")\n",
    "\n",
    "def get_video_file(video_url, position_id, is_external=False):\n",
    "    \"\"\"\n",
    "    Unified function to get video file path\n",
    "    - If local upload: extract from URL\n",
    "    - If external: download from internet\n",
    "    \"\"\"\n",
    "    if is_external:\n",
    "        # Download from external URL\n",
    "        return download_video_from_url(video_url, position_id)\n",
    "    else:\n",
    "        # Get local file path\n",
    "        local_file = get_local_file_path(video_url)\n",
    "        if not local_file:\n",
    "            raise Exception(f\"Local file not found for URL: {video_url}\")\n",
    "        return local_file\n",
    "\n",
    "def transcribe_video(video_path):\n",
    "    \"\"\"Transcribe video using faster-whisper with MAXIMUM ACCURACY settings\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(video_path):\n",
    "            raise Exception(f\"Video file not found: {video_path}\")\n",
    "        \n",
    "        if not os.access(video_path, os.R_OK):\n",
    "            raise Exception(f\"Video file is not readable: {video_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(video_path) / (1024 * 1024)\n",
    "        print(f'üìÅ Video: {os.path.basename(video_path)} ({file_size:.2f} MB)')\n",
    "        \n",
    "        print('üîÑ Starting transcription...')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Dynamic parameters based on file size\n",
    "        if file_size > 30:\n",
    "            print('   ‚ö° Large file - using balanced mode')\n",
    "            beam_size = 3\n",
    "            best_of = 3\n",
    "        else:\n",
    "            beam_size = 5\n",
    "            best_of = 5\n",
    "        \n",
    "        # Transcribe\n",
    "        segments, info = whisper_model.transcribe(\n",
    "            video_path,\n",
    "            language=\"en\",\n",
    "            task=\"transcribe\",\n",
    "            beam_size=beam_size,\n",
    "            best_of=best_of,\n",
    "            patience=2.0,\n",
    "            length_penalty=1.0,\n",
    "            repetition_penalty=1.0,\n",
    "            temperature=0.0,\n",
    "            compression_ratio_threshold=2.4,\n",
    "            log_prob_threshold=-1.0,\n",
    "            no_speech_threshold=0.6,\n",
    "            condition_on_previous_text=True,\n",
    "            initial_prompt=\"This is a professional interview conversation in clear English. The speaker is answering interview questions.\",\n",
    "            vad_filter=True,\n",
    "            vad_parameters=dict(\n",
    "                threshold=0.5,\n",
    "                min_speech_duration_ms=250,\n",
    "                max_speech_duration_s=float('inf'),\n",
    "                min_silence_duration_ms=2000,\n",
    "                speech_pad_ms=400\n",
    "            ),\n",
    "            word_timestamps=False,\n",
    "            hallucination_silence_threshold=None\n",
    "        )\n",
    "        \n",
    "        # Collect segments with progress bar\n",
    "        print('   üìù Collecting segments...')\n",
    "        transcription_text = \"\"\n",
    "        segments_list = list(segments)  # Convert generator to list first\n",
    "        \n",
    "        # Progress bar for segment collection\n",
    "        for segment in tqdm(segments_list, desc=\"   Segments\", unit=\"seg\", ncols=80, leave=False):\n",
    "            transcription_text += segment.text + \" \"\n",
    "        \n",
    "        transcription_text = transcription_text.strip()\n",
    "        \n",
    "        if not transcription_text:\n",
    "            print('   ‚ö†Ô∏è  No speech detected')\n",
    "            return \"[No speech detected in video]\"\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        words = transcription_text.split()\n",
    "        \n",
    "        print(f'   ‚úÖ Completed in {total_time:.1f}s | {len(segments_list)} segments | {len(words)} words')\n",
    "        \n",
    "        # Cleanup\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        \n",
    "        return transcription_text\n",
    "            \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f'   ‚ùå Error: {str(e)}')\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
    "\n",
    "def translate_to_indonesian(text):\n",
    "    \"\"\"Translate English text to Indonesian using DeepL\"\"\"\n",
    "    if not translator:\n",
    "        print('   ‚ö†Ô∏è  Translation skipped (no API key)')\n",
    "        return \"[Translation not available]\"\n",
    "    \n",
    "    try:\n",
    "        max_chunk_size = 5000\n",
    "        \n",
    "        if len(text) <= max_chunk_size:\n",
    "            result = translator.translate_text(text, source_lang=\"EN\", target_lang=\"ID\")\n",
    "            translated_text = result.text\n",
    "        else:\n",
    "            sentences = text.split('. ')\n",
    "            translated_sentences = []\n",
    "            current_chunk = \"\"\n",
    "            \n",
    "            # Progress bar for translation chunks\n",
    "            for sentence in tqdm(sentences, desc=\"   Translation\", unit=\"sent\", ncols=80, leave=False):\n",
    "                if len(current_chunk) + len(sentence) < max_chunk_size:\n",
    "                    current_chunk += sentence + \". \"\n",
    "                else:\n",
    "                    if current_chunk:\n",
    "                        result = translator.translate_text(current_chunk.strip(), source_lang=\"EN\", target_lang=\"ID\")\n",
    "                        translated_sentences.append(result.text)\n",
    "                    current_chunk = sentence + \". \"\n",
    "            \n",
    "            if current_chunk:\n",
    "                result = translator.translate_text(current_chunk.strip(), source_lang=\"EN\", target_lang=\"ID\")\n",
    "                translated_sentences.append(result.text)\n",
    "            \n",
    "            translated_text = \" \".join(translated_sentences)\n",
    "        \n",
    "        print(f'   ‚úÖ Translation: {len(text)} ‚Üí {len(translated_text)} chars')\n",
    "        return translated_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'   ‚ùå Translation failed: {str(e)}')\n",
    "        return f\"[Translation failed: {str(e)}]\"\n",
    "\n",
    "def generate_dummy_assessment(transcription_text, position_id, transcription_id=None):\n",
    "    \"\"\"Generate dummy assessment data untuk testing\"\"\"\n",
    "    words = transcription_text.split()\n",
    "    word_count = len(words)\n",
    "    char_count = len(transcription_text)\n",
    "    \n",
    "    confidence_score = random.randint(85, 98)\n",
    "    kualitas_jawaban = random.randint(80, 100)\n",
    "    relevansi = random.randint(75, 95)\n",
    "    koherensi = random.randint(70, 90)\n",
    "    tempo_bicara = random.randint(80, 100)\n",
    "    \n",
    "    total = round((confidence_score + kualitas_jawaban + relevansi + koherensi + tempo_bicara) / 5)\n",
    "    \n",
    "    if total >= 90:\n",
    "        penilaian_akhir = 5\n",
    "    elif total >= 80:\n",
    "        penilaian_akhir = 4\n",
    "    elif total >= 70:\n",
    "        penilaian_akhir = 3\n",
    "    elif total >= 60:\n",
    "        penilaian_akhir = 2\n",
    "    else:\n",
    "        penilaian_akhir = 1\n",
    "    \n",
    "    has_cheating = random.choice([True, False, False, False])\n",
    "    \n",
    "    if has_cheating:\n",
    "        cheating_detection = \"Ya\"\n",
    "        alasan_cheating = random.choice([\n",
    "            \"Terdeteksi adanya manipulasi suara\",\n",
    "            \"Terdeteksi multiple speakers\",\n",
    "            \"Pola jawaban tidak konsisten\",\n",
    "            \"Kecepatan bicara tidak natural\"\n",
    "        ])\n",
    "    else:\n",
    "        cheating_detection = \"Tidak\"\n",
    "        alasan_cheating = \"Tidak ada indikasi kecurangan\"\n",
    "    \n",
    "    analisis_options = [\n",
    "        \"Lancar dan tidak mencurigakan\",\n",
    "        \"Sedikit gugup namun natural\",\n",
    "        \"Sangat percaya diri\",\n",
    "        \"Tempo bicara konsisten\",\n",
    "        \"Artikulasi jelas\"\n",
    "    ]\n",
    "    analisis_non_verbal = random.choice(analisis_options)\n",
    "    \n",
    "    if penilaian_akhir >= 4 and not has_cheating:\n",
    "        keputusan_akhir = \"Lulus\"\n",
    "    elif penilaian_akhir >= 3 and not has_cheating:\n",
    "        keputusan_akhir = \"Pertimbangan\"\n",
    "    else:\n",
    "        keputusan_akhir = \"Tidak Lulus\"\n",
    "    \n",
    "    return {\n",
    "        \"penilaian\": {\n",
    "            \"confidence_score\": confidence_score,\n",
    "            \"kualitas_jawaban\": kualitas_jawaban,\n",
    "            \"relevansi\": relevansi,\n",
    "            \"koherensi\": koherensi,\n",
    "            \"tempo_bicara\": tempo_bicara,\n",
    "            \"total\": total\n",
    "        },\n",
    "        \"penilaian_akhir\": penilaian_akhir,\n",
    "        \"cheating_detection\": cheating_detection,\n",
    "        \"alasan_cheating\": alasan_cheating,\n",
    "        \"analisis_non_verbal\": analisis_non_verbal,\n",
    "        \"keputusan_akhir\": keputusan_akhir,\n",
    "        \"transkripsi_en\": transcription_text,\n",
    "        \"transkripsi_id\": transcription_id,\n",
    "        \"metadata\": {\n",
    "            \"word_count\": word_count,\n",
    "            \"char_count\": char_count,\n",
    "            \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"translation_available\": transcription_id is not None  # NEW\n",
    "        }\n",
    "    }\n",
    "\n",
    "# UNIFIED PROCESSING FUNCTION\n",
    "def process_videos_unified(session_id: str, candidate_name: str, uploaded_videos: list, base_url: str):\n",
    "    \"\"\"\n",
    "    UNIFIED background processing for videos\n",
    "    Handles both local uploads and external URLs automatically\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Detect source type\n",
    "        is_external = any(v.get('isExternal', False) for v in uploaded_videos)\n",
    "        source_type = \"EXTERNAL URLs\" if is_external else \"LOCAL UPLOADS\"\n",
    "        \n",
    "        print(f'\\n{\"=\"*70}')\n",
    "        print(f'üéôÔ∏è  SESSION: {session_id} ({source_type})')\n",
    "        print(f'üë§ CANDIDATE: {candidate_name}')\n",
    "        print(f'üìπ VIDEOS: {len(uploaded_videos)}')\n",
    "        print(f'{\"=\"*70}\\n')\n",
    "        \n",
    "        transcriptions = []\n",
    "        assessment_results = []\n",
    "        \n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {'status': 'processing', 'progress': '0/0'}\n",
    "        \n",
    "        # Process each video with overall progress bar\n",
    "        for idx, interview in enumerate(tqdm(uploaded_videos, desc=\"üé¨ Overall Progress\", unit=\"video\", ncols=80), 1):\n",
    "            if not interview.get('isVideoExist') or not interview.get('recordedVideoUrl'):\n",
    "                transcriptions.append({\n",
    "                    'positionId': interview['positionId'],\n",
    "                    'error': interview.get('error', 'Video not available')\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            position_id = interview['positionId']\n",
    "            video_url = interview['recordedVideoUrl']\n",
    "            is_external_video = interview.get('isExternal', False)\n",
    "            \n",
    "            try:\n",
    "                print(f'\\n‚îå‚îÄ Video {position_id}/{len(uploaded_videos)} ‚îÄ{\"‚îÄ\"*50}‚îê')\n",
    "                \n",
    "                with processing_lock:\n",
    "                    processing_status[session_id] = {\n",
    "                        'status': 'processing',\n",
    "                        'progress': f'{position_id}/{len(uploaded_videos)}',\n",
    "                        'current_video': position_id,\n",
    "                        'message': f'Processing video {position_id}/{len(uploaded_videos)}...'\n",
    "                    }\n",
    "                \n",
    "                video_start = time.time()\n",
    "                \n",
    "                # Step 0: Get video file (download if external, or get local path)\n",
    "                if is_external_video:\n",
    "                    print(f'‚îÇ 0Ô∏è‚É£  DOWNLOAD FROM URL')\n",
    "                    print(f'‚îÇ    URL: {video_url[:60]}...')\n",
    "                    with processing_lock:\n",
    "                        processing_status[session_id]['message'] = f'Downloading video {position_id}...'\n",
    "                \n",
    "                local_file = get_video_file(video_url, position_id, is_external_video)\n",
    "                file_size_mb = os.path.getsize(local_file) / (1024 * 1024)\n",
    "                \n",
    "                # Step 1: Transcribe\n",
    "                print(f'‚îÇ 1Ô∏è‚É£  TRANSCRIPTION ({file_size_mb:.1f} MB)')\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id]['message'] = f'Transcribing video {position_id}...'\n",
    "                \n",
    "                transcription_text = transcribe_video(local_file)\n",
    "                transcribe_time = time.time() - video_start\n",
    "                \n",
    "                # Step 2: Translate\n",
    "                print(f'‚îÇ 2Ô∏è‚É£  TRANSLATION')\n",
    "                translate_start = time.time()\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id]['message'] = f'Translating video {position_id}...'\n",
    "                \n",
    "                transcription_id = translate_to_indonesian(transcription_text)\n",
    "                translate_time = time.time() - translate_start\n",
    "                \n",
    "                # Step 3: Save\n",
    "                print(f'‚îÇ 3Ô∏è‚É£  SAVING FILES')\n",
    "                trans_fname = f\"transcription_pos{position_id}_{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}.txt\"\n",
    "                trans_path = os.path.join(TRANSCRIPTION_DIR, trans_fname)\n",
    "                \n",
    "                with open(trans_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(f\"Candidate: {candidate_name}\\n\")\n",
    "                    f.write(f\"Position ID: {position_id}\\n\")\n",
    "                    f.write(f\"Video URL: {video_url}\\n\")\n",
    "                    f.write(f\"Source: {'External URL (downloaded)' if is_external_video else 'Local upload'}\\n\")\n",
    "                    f.write(f\"Transcribed at: {datetime.now(timezone.utc).isoformat()}\\n\")\n",
    "                    f.write(f\"Model: faster-whisper large-v3\\n\")\n",
    "                    f.write(f\"Processing time: {transcribe_time:.1f}s\\n\")\n",
    "                    f.write(f\"\\n{'='*50}\\n\")\n",
    "                    f.write(f\"ENGLISH TRANSCRIPTION:\\n\")\n",
    "                    f.write(f\"{'='*50}\\n\\n\")\n",
    "                    f.write(transcription_text)\n",
    "                    f.write(f\"\\n\\n{'='*50}\\n\")\n",
    "                    f.write(f\"INDONESIAN TRANSLATION (DeepL):\\n\")\n",
    "                    f.write(f\"{'='*50}\\n\\n\")\n",
    "                    f.write(transcription_id)\n",
    "                \n",
    "                transcription_url = f\"{base_url}/transcriptions/{trans_fname}\"\n",
    "                \n",
    "                # Generate assessment\n",
    "                assessment = generate_dummy_assessment(transcription_text, position_id, transcription_id)\n",
    "                \n",
    "                assessment_results.append({\n",
    "                    \"id\": position_id,\n",
    "                    \"result\": assessment\n",
    "                })\n",
    "                \n",
    "                transcriptions.append({\n",
    "                    'positionId': position_id,\n",
    "                    'videoUrl': video_url,\n",
    "                    'transcription': transcription_text,\n",
    "                    'transcription_id': transcription_id,\n",
    "                    'transcriptionUrl': transcription_url,\n",
    "                    'transcriptionFile': trans_fname,\n",
    "                    'assessment': assessment\n",
    "                })\n",
    "                \n",
    "                # Delete video file (both downloaded and uploaded)\n",
    "                if os.path.exists(local_file):\n",
    "                    os.remove(local_file)\n",
    "                    action = \"Downloaded video\" if is_external_video else \"Video\"\n",
    "                    print(f'‚îÇ üóëÔ∏è  {action} deleted ({file_size_mb:.1f} MB freed)')\n",
    "                \n",
    "                total_time = time.time() - video_start\n",
    "                print(f'‚îÇ ‚è±Ô∏è  Total: {total_time:.1f}s (Transcribe: {transcribe_time:.1f}s | Translate: {translate_time:.1f}s)')\n",
    "                print(f'‚îÇ üìä Assessment: {assessment[\"keputusan_akhir\"]} ({assessment[\"penilaian_akhir\"]}/5)')\n",
    "                print(f'‚îî‚îÄ{\"‚îÄ\"*68}‚îò')\n",
    "                \n",
    "                # Cleanup\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'‚îÇ ‚ùå ERROR: {str(e)}')\n",
    "                print(f'‚îî‚îÄ{\"‚îÄ\"*68}‚îò')\n",
    "                \n",
    "                transcriptions.append({\n",
    "                    'positionId': position_id,\n",
    "                    'videoUrl': video_url,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "                \n",
    "                # Clean up failed download/upload\n",
    "                try:\n",
    "                    if 'local_file' in locals() and os.path.exists(local_file):\n",
    "                        os.remove(local_file)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Save final results\n",
    "        if assessment_results:\n",
    "            results_json = {\n",
    "                \"success\": True,\n",
    "                \"name\": candidate_name,\n",
    "                \"session\": session_id,\n",
    "                \"content\": assessment_results,\n",
    "                \"metadata\": {\n",
    "                    \"total_videos\": len(uploaded_videos),\n",
    "                    \"successful_videos\": len(assessment_results),\n",
    "                    \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
    "                    \"model\": \"faster-whisper large-v3\",\n",
    "                    \"videos_deleted\": True,\n",
    "                    \"source\": \"external_urls\" if is_external else \"local_uploads\",\n",
    "                    \"translation_provider\": \"DeepL\",\n",
    "                    \"translation_language\": \"Indonesian (ID)\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            results_filename = f\"{session_id}.json\"\n",
    "            results_path = os.path.join(RESULTS_DIR, results_filename)\n",
    "            \n",
    "            with open(results_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results_json, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            results_url = f\"{base_url}/results/{results_filename}\"\n",
    "            print(f'\\nüíæ Results saved: {results_url}')\n",
    "        \n",
    "        successful_count = sum(1 for t in transcriptions if 'transcription' in t)\n",
    "        \n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'completed',\n",
    "                'result': {\n",
    "                    'success': True,\n",
    "                    'transcriptions': transcriptions,\n",
    "                    'processed_videos': len(transcriptions),\n",
    "                    'successful_videos': successful_count,\n",
    "                    'failed_videos': len(transcriptions) - successful_count,\n",
    "                    'results_url': f\"{base_url}/results/{session_id}.json\" if assessment_results else None\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        print(f'\\n{\"=\"*70}')\n",
    "        print(f'‚úÖ SESSION COMPLETED ({source_type})')\n",
    "        print(f'   Success: {successful_count}/{len(transcriptions)} videos')\n",
    "        print(f'{\"=\"*70}\\n')\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f'\\n‚ùå SESSION ERROR:\\n{traceback.format_exc()}')\n",
    "        \n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'error_detail': traceback.format_exc()\n",
    "            }\n",
    "\n",
    "# ENDPOINTS\n",
    "\n",
    "@app.post('/upload')\n",
    "async def receive_videos_and_process(\n",
    "    request: Request,\n",
    "    candidate_name: str = Form(...),\n",
    "    videos: List[UploadFile] = File(...)\n",
    "):\n",
    "    \"\"\"Upload videos and start background transcription\"\"\"\n",
    "    session_id = uuid.uuid4().hex\n",
    "    print(f'\\nüîµ NEW UPLOAD REQUEST - Session: {session_id}')\n",
    "    print(f'   Candidate: {candidate_name}')\n",
    "    print(f'   Videos: {len(videos)} file(s)')\n",
    "    \n",
    "    # Initialize status FIRST\n",
    "    with processing_lock:\n",
    "        processing_status[session_id] = {\n",
    "            'status': 'uploading',\n",
    "            'progress': '0/0',\n",
    "            'message': 'Uploading videos...'\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # 1. Upload semua video (fast)\n",
    "        base_url = str(request.base_url).rstrip('/')\n",
    "        uploaded_videos = []\n",
    "        \n",
    "        print(f'\\nüì§ Uploading {len(videos)} video(s)...')\n",
    "        for idx, video in enumerate(videos, 1):\n",
    "            try:\n",
    "                ext = os.path.splitext(video.filename)[1] or '.webm'\n",
    "                safe_name = f\"{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}{ext}\"\n",
    "                dest_path = os.path.join(UPLOAD_DIR, safe_name)\n",
    "                \n",
    "                # Update upload progress\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id]['message'] = f'Uploading video {idx}/{len(videos)}...'\n",
    "                    processing_status[session_id]['progress'] = f'{idx}/{len(videos)}'\n",
    "                \n",
    "                with open(dest_path, 'wb') as buffer:\n",
    "                    shutil.copyfileobj(video.file, buffer)\n",
    "                \n",
    "                file_url = f\"{base_url}/uploads/{safe_name}\"\n",
    "                uploaded_videos.append({\n",
    "                    'positionId': idx,\n",
    "                    'isVideoExist': True,\n",
    "                    'recordedVideoUrl': file_url,\n",
    "                    'filename': safe_name\n",
    "                })\n",
    "                print(f'   ‚úÖ Uploaded: {safe_name}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'   ‚ùå Failed: {str(e)}')\n",
    "                uploaded_videos.append({\n",
    "                    'positionId': idx,\n",
    "                    'isVideoExist': False,\n",
    "                    'recordedVideoUrl': None,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        # 2. Update status to processing\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'processing',\n",
    "                'progress': '0/' + str(len(uploaded_videos)),\n",
    "                'message': 'Starting transcription...',\n",
    "                'uploaded_videos': len(uploaded_videos)\n",
    "            }\n",
    "        \n",
    "        # 3. Start background thread\n",
    "        thread = th.Thread(\n",
    "            target=process_videos_unified,  # CHANGED: use unified function\n",
    "            args=(session_id, candidate_name, uploaded_videos, base_url),\n",
    "            daemon=True\n",
    "        )\n",
    "        thread.start()\n",
    "        \n",
    "        print(f'‚úÖ Upload complete. Background thread started.')\n",
    "        print(f'üì§ Returning immediate response with session_id: {session_id}')\n",
    "        \n",
    "        # 4. RETURN IMMEDIATELY - no waiting!\n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': True,\n",
    "                'session_id': session_id,\n",
    "                'message': 'Videos uploaded successfully. Processing started.',\n",
    "                'uploaded_videos': len(uploaded_videos)\n",
    "            },\n",
    "            status_code=200,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_detail = traceback.format_exc()\n",
    "        print(f'‚ùå Error:\\n{error_detail}')\n",
    "        \n",
    "        # Update status to error\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'error_detail': error_detail\n",
    "            }\n",
    "        \n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': False,\n",
    "                'session_id': session_id,\n",
    "                'error': str(e)\n",
    "            },\n",
    "            status_code=500,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "\n",
    "@app.post('/upload_json')\n",
    "async def receive_json_and_process(\n",
    "    request: Request,\n",
    "    background_tasks: BackgroundTasks\n",
    "):\n",
    "    \"\"\"Receive JSON payload with external video URLs and process\"\"\"\n",
    "    session_id = uuid.uuid4().hex\n",
    "    \n",
    "    try:\n",
    "        # Parse JSON body\n",
    "        json_data = await request.json()\n",
    "        \n",
    "        print(f'\\nüîµ NEW JSON UPLOAD - Session: {session_id}')\n",
    "        \n",
    "        # Validate structure\n",
    "        if not json_data.get('success'):\n",
    "            raise HTTPException(status_code=400, detail=\"Invalid JSON: success flag missing\")\n",
    "        \n",
    "        data = json_data.get('data', {})\n",
    "        candidate = data.get('candidate', {})\n",
    "        candidate_name = candidate.get('name')\n",
    "        \n",
    "        if not candidate_name:\n",
    "            raise HTTPException(status_code=400, detail=\"Invalid JSON: candidate name missing\")\n",
    "        \n",
    "        review_checklists = data.get('reviewChecklists', {})\n",
    "        interviews = review_checklists.get('interviews', [])\n",
    "        \n",
    "        if not interviews or not isinstance(interviews, list):\n",
    "            raise HTTPException(status_code=400, detail=\"Invalid JSON: interviews array missing\")\n",
    "        \n",
    "        print(f'   Candidate: {candidate_name}')\n",
    "        print(f'   Videos: {len(interviews)} file(s)')\n",
    "        \n",
    "        # Initialize status\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'processing',\n",
    "                'progress': '0/0',\n",
    "                'message': 'Starting video download and processing...'\n",
    "            }\n",
    "        \n",
    "        # Prepare video list for processing\n",
    "        base_url = str(request.base_url).rstrip('/')\n",
    "        uploaded_videos = []\n",
    "        \n",
    "        for interview in interviews:\n",
    "            position_id = interview.get('positionId')\n",
    "            video_url = interview.get('recordedVideoUrl')\n",
    "            is_exist = interview.get('isVideoExist', False)\n",
    "            \n",
    "            if not is_exist or not video_url:\n",
    "                uploaded_videos.append({\n",
    "                    'positionId': position_id,\n",
    "                    'isVideoExist': False,\n",
    "                    'recordedVideoUrl': None,\n",
    "                    'error': 'Video not available or URL missing'\n",
    "                })\n",
    "            else:\n",
    "                uploaded_videos.append({\n",
    "                    'positionId': position_id,\n",
    "                    'isVideoExist': True,\n",
    "                    'recordedVideoUrl': video_url,\n",
    "                    'isExternal': True  # Mark as external URL\n",
    "                })\n",
    "        \n",
    "        # Start background processing using UNIFIED function\n",
    "        thread = th.Thread(\n",
    "            target=process_videos_unified,  # CHANGED: use unified function\n",
    "            args=(session_id, candidate_name, uploaded_videos, base_url),\n",
    "            daemon=True\n",
    "        )\n",
    "        thread.start()\n",
    "        \n",
    "        print(f'‚úÖ JSON received. Background download & processing started.')\n",
    "        print(f'üì§ Returning immediate response with session_id: {session_id}')\n",
    "        \n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': True,\n",
    "                'session_id': session_id,\n",
    "                'message': 'JSON received. Video download and processing started.',\n",
    "                'videos_to_process': len(uploaded_videos)\n",
    "            },\n",
    "            status_code=200,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    except HTTPException as he:\n",
    "        raise he\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_detail = traceback.format_exc()\n",
    "        print(f'‚ùå JSON processing error:\\n{error_detail}')\n",
    "        \n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'error_detail': error_detail\n",
    "            }\n",
    "        \n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': False,\n",
    "                'session_id': session_id,\n",
    "                'error': str(e)\n",
    "            },\n",
    "            status_code=500,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "\n",
    "@app.get('/status/{session_id}')\n",
    "async def get_processing_status(session_id: str):\n",
    "    \"\"\"Check processing status\"\"\"\n",
    "    with processing_lock:\n",
    "        if session_id not in processing_status:\n",
    "            return JSONResponse(\n",
    "                {\n",
    "                    'status': 'not_found',\n",
    "                    'message': 'Session not found'\n",
    "                }, \n",
    "                status_code=404,\n",
    "                headers={\n",
    "                    'Access-Control-Allow-Origin': '*',\n",
    "                    'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                    'Access-Control-Allow-Headers': '*',\n",
    "                    'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        status_copy = processing_status[session_id].copy()\n",
    "    \n",
    "    # Add redirect URL if completed\n",
    "    if status_copy.get('status') == 'completed':\n",
    "        status_copy['redirect'] = f\"halaman_dasboard.html?session={session_id}\"\n",
    "    \n",
    "    return JSONResponse(\n",
    "        status_copy,\n",
    "        headers={\n",
    "            'Access-Control-Allow-Origin': '*',\n",
    "            'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "            'Access-Control-Allow-Headers': '*',\n",
    "            'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "        }\n",
    "    )\n",
    "\n",
    "@app.get('/results/{session_id}')\n",
    "async def get_results(session_id: str):\n",
    "    \"\"\"Get assessment results for a session\"\"\"\n",
    "    results_filename = f\"{session_id}.json\"\n",
    "    results_path = os.path.join(RESULTS_DIR, results_filename)\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        return JSONResponse(\n",
    "            {\n",
    "                'success': False,\n",
    "                'message': 'Results not found for this session',\n",
    "                'session_id': session_id\n",
    "            },\n",
    "            status_code=404,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        with open(results_path, 'r', encoding='utf-8') as f:\n",
    "            results_data = json.load(f)\n",
    "        \n",
    "        return JSONResponse(\n",
    "            results_data,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "                'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return JSONResponse(\n",
    "            {\n",
    "                'success': False,\n",
    "                'message': f'Error reading results: {str(e)}',\n",
    "                'session_id': session_id\n",
    "            },\n",
    "            status_code=500,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "\n",
    "@app.get('/')\n",
    "async def index():\n",
    "    return {\n",
    "        'message': 'AI Interview Assessment System',\n",
    "        'model': 'faster-whisper large-v3',\n",
    "        'accuracy': '98%+ for clear English speech',\n",
    "        'speed': '4-5x faster than standard Whisper',\n",
    "        'endpoints': {\n",
    "            'upload': 'POST /upload',\n",
    "            'status': 'GET /status/{session_id}',\n",
    "            'results': 'GET /results/{session_id}',\n",
    "            'test_form': 'GET /upload_form'\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get('/upload_form')\n",
    "async def upload_form():\n",
    "    html = '''\n",
    "    <html>\n",
    "      <head><meta charset=\"utf-8\"><title>Upload Videos - AI Interview System</title></head>\n",
    "      <body style=\"font-family: Arial, sans-serif; padding: 20px;\">\n",
    "        <h2>üéôÔ∏è AI Interview Assessment System</h2>\n",
    "        <p><strong>Model:</strong> faster-whisper large-v3 (Maximum Accuracy)</p>\n",
    "        <p><strong>Accuracy:</strong> ~98% for clear English speech</p>\n",
    "        <p><strong>Speed:</strong> 4-5x faster than standard Whisper</p>\n",
    "        <hr>\n",
    "        <h3>Upload Interview Videos</h3>\n",
    "        <form action=\"/upload\" enctype=\"multipart/form-data\" method=\"post\">\n",
    "          <label>Candidate Name: <input name=\"candidate_name\" type=\"text\" required style=\"padding: 5px; width: 300px;\" /></label><br><br>\n",
    "          <label>Select Videos: <input name=\"videos\" type=\"file\" accept=\"video/*\" multiple required /></label><br><br>\n",
    "          <button type=\"submit\" style=\"padding: 10px 20px; background: #007bff; color: white; border: none; cursor: pointer;\">Upload & Transcribe</button>\n",
    "        </form>\n",
    "        <p style=\"color: #666; font-size: 14px;\">Tip: Clear audio will result in better transcription accuracy.</p>\n",
    "      </body>\n",
    "    </html>\n",
    "    '''\n",
    "    return HTMLResponse(content=html, status_code=200)\n",
    "\n",
    "print('‚úÖ FastAPI app defined successfully')\n",
    "print('‚ÑπÔ∏è  Run next cell to start the server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan server uvicorn di dalam notebook (tanpa ngrok)\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import threading\n",
    "\n",
    "nest_asyncio.apply()\n",
    "PORT = 8888\n",
    "\n",
    "# Hentikan server sebelumnya jika ada\n",
    "if 'server_thread' in globals() and server_thread is not None:\n",
    "    try:\n",
    "        print('‚è∏Ô∏è  Stopping previous server...')\n",
    "        if 'server' in globals() and server is not None:\n",
    "            server.should_exit = True\n",
    "        # Tunggu thread selesai (dengan timeout)\n",
    "        if server_thread.is_alive():\n",
    "            server_thread.join(timeout=2)\n",
    "        print('‚úÖ Previous server stopped.')\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  Error stopping previous server: {e}')\n",
    "\n",
    "# Buat server instance baru dengan log level yang lebih rendah\n",
    "config = uvicorn.Config(\n",
    "    app=app, \n",
    "    host='0.0.0.0', \n",
    "    port=PORT, \n",
    "    log_level='warning',  # Kurangi verbosity untuk menghindari duplikasi log\n",
    "    access_log=False  # Nonaktifkan access log di console\n",
    ")\n",
    "server = uvicorn.Server(config=config)\n",
    "\n",
    "# Fungsi untuk menjalankan server di thread\n",
    "def run_server_in_thread():\n",
    "    import asyncio\n",
    "    # Buat event loop baru untuk thread ini\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        loop.run_until_complete(server.serve())\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Server error: {e}')\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "# Jalankan server di background thread\n",
    "server_thread = threading.Thread(target=run_server_in_thread, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "print('‚îÅ' * 60)\n",
    "print('üöÄ Server started successfully!')\n",
    "print(f'üìç Local URL: http://127.0.0.1:{PORT}')\n",
    "print(f'üìç Network URL: http://0.0.0.0:{PORT}')\n",
    "print(f'üîß Endpoints:')\n",
    "print(f'   - POST /upload       (upload videos & process)')\n",
    "print(f'   - POST /upload_json  (upload JSON & download videos)')\n",
    "print(f'   - GET  /status/{{id}}  (check processing status)')\n",
    "print(f'   - GET  /results/{{id}} (get assessment results)')\n",
    "print(f'   - GET  /upload_form  (test form)')\n",
    "print('‚ÑπÔ∏è  Use Interrupt Kernel to stop the server')\n",
    "print('‚îÅ' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f94a342",
   "metadata": {},
   "source": [
    "## System Information\n",
    "\n",
    "### Whisper Model\n",
    "- **Library**: `faster-whisper` (optimized implementation)\n",
    "- **Model**: `large-v3` (most accurate available)\n",
    "- **Accuracy**: ~98% for clear English speech\n",
    "- **Speed**: 4-5x faster than `openai-whisper`\n",
    "\n",
    "### Translation\n",
    "- **Provider**: DeepL API\n",
    "- **Target Language**: Indonesian (ID)\n",
    "- **Source Language**: English (EN)\n",
    "- **Character Limit**: 5,000 per chunk\n",
    "- **Setup**: Set `DEEPL_API_KEY` in cell 3\n",
    "- **Get API Key**: https://www.deepl.com/pro-api (Free tier: 500,000 chars/month)\n",
    "\n",
    "### Performance\n",
    "- **Device**: Automatically detects CUDA GPU (if available) or CPU\n",
    "- **Compute Type**: \n",
    "  - GPU: `float16` (faster with high accuracy)\n",
    "  - CPU: `int8` (optimized for CPU)\n",
    "- **VAD Filter**: Enabled (skips silence for efficiency)\n",
    "\n",
    "### Settings\n",
    "- **Beam Size**: 5 (higher = more accurate)\n",
    "- **Best Of**: 5 (samples multiple candidates)\n",
    "- **Patience**: 2.0 (thorough beam search)\n",
    "- **Temperature**: 0.0 (deterministic output)\n",
    "- **Context**: Uses previous text for better accuracy\n",
    "\n",
    "### Storage Management\n",
    "- **Auto-delete videos**: ‚úÖ Videos are automatically deleted after successful transcription\n",
    "- **Storage saved**: Only transcriptions and results are kept\n",
    "- **Safety**: Deletion only happens after successful transcription\n",
    "- **Error handling**: If deletion fails, processing continues normally\n",
    "\n",
    "### Endpoints\n",
    "- `POST /upload` - Upload videos and start transcription\n",
    "- `GET /status/{session_id}` - Check processing status\n",
    "- **`GET /results/{session_id}`** - **Get assessment results**\n",
    "- `GET /upload_form` - Test form interface\n",
    "- `GET /` - System information\n",
    "\n",
    "### Files\n",
    "- ~~Uploaded videos: `uploads/`~~ (deleted after transcription) ‚ôªÔ∏è\n",
    "- Transcriptions: `transcriptions/` ‚úÖ (includes English + Indonesian)\n",
    "- **Assessment results: `results/`** ‚úÖ\n",
    "\n",
    "### Assessment Data Structure\n",
    "```json\n",
    "{\n",
    "  \"success\": true,\n",
    "  \"name\": \"Candidate Name\",\n",
    "  \"session\": \"session_id_here\",\n",
    "  \"content\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"result\": {\n",
    "        \"penilaian\": { ... },\n",
    "        \"penilaian_akhir\": 5,\n",
    "        \"cheating_detection\": \"Tidak\",\n",
    "        \"alasan_cheating\": \"Tidak ada indikasi kecurangan\",\n",
    "        \"analisis_non_verbal\": \"Lancar dan tidak mencurigakan\",\n",
    "        \"keputusan_akhir\": \"Lulus\",\n",
    "        \"transkripsi\": \"Full English transcription...\",\n",
    "        \"transkripsi_id\": \"Transkripsi lengkap dalam Bahasa Indonesia...\",\n",
    "        \"metadata\": {\n",
    "          \"word_count\": 150,\n",
    "          \"char_count\": 800,\n",
    "          \"processed_at\": \"2024-01-01T12:00:00Z\",\n",
    "          \"translation_available\": true\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"total_videos\": 5,\n",
    "    \"successful_videos\": 5,\n",
    "    \"processed_at\": \"2024-01-01T12:00:00Z\",\n",
    "    \"model\": \"faster-whisper large-v3\",\n",
    "    \"videos_deleted\": true,\n",
    "    \"translation_provider\": \"DeepL\",\n",
    "    \"translation_language\": \"Indonesian (ID)\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Notes\n",
    "- Assessment scores are currently **dummy data** for testing\n",
    "- Replace `generate_dummy_assessment()` with real AI analysis later\n",
    "- Results are saved automatically after transcription completes\n",
    "- **Original video files are deleted after transcription to save storage**\n",
    "- **English transcription + Indonesian translation included**\n",
    "- DeepL API key required for translation (free tier available)\n",
    "- Access via: `http://127.0.0.1:8888/results/{session_id}`\n",
    "\n",
    "### DeepL Setup\n",
    "1. Sign up at https://www.deepl.com/pro-api\n",
    "2. Get your free API key (500,000 chars/month)\n",
    "3. Set `DEEPL_API_KEY` in cell 3\n",
    "4. Restart kernel and run all cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
